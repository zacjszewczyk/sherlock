2025-09-29 15:30:36 INFO     __main__ :: Run initialized at: 20250929T153036Z | Logging to: logs/refiner_20250929T153036Z.log
2025-09-29 15:30:36 INFO     __main__ :: Loading Gemini API key
2025-09-29 15:30:36 INFO     __main__ :: Loading Sage API key
2025-09-29 15:30:36 INFO     __main__ :: Loading configuration
2025-09-29 15:30:36 INFO     __main__ :: Successfully loaded configuration from 'config/refine.yml'.
2025-09-29 15:30:36 INFO     __main__ :: Building technique dictionary
2025-09-29 15:30:36 INFO     src.attack_retriever :: Processing matrix: ics
2025-09-29 15:30:36 INFO     src.attack_retriever :: Using cached version of 'ics' matrix from 'ics-attack.json'.
2025-09-29 15:30:36 INFO     src.attack_retriever :: Built dictionary with 83 unique techniques across 1 matrices.
2025-09-29 15:30:36 INFO     __main__ :: Will attempt to refine plans for up to 83 techniques (existing files only).
2025-09-29 15:30:36 INFO     __main__ :: Running in multi-core mode with 8 workers.
2025-09-29 15:30:36 INFO     __main__ :: [T0803] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [T0831] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [T0836] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [T0887] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [T0800] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [T0881] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [T0821] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [T0829] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:30:36 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:30:36 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:30:36 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:30:36 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:30:36 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:30:36 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:30:36 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:30:36 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:04 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:04 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:04 INFO     __main__ :: [T0831] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:04 INFO     __main__ :: T0831: ok
2025-09-29 15:31:04 INFO     __main__ :: [T0814] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:04 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:04 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:10 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:10 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:10 INFO     __main__ :: [T0829] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:10 INFO     __main__ :: T0829: ok
2025-09-29 15:31:10 INFO     __main__ :: [T0805] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:10 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:10 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:11 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:11 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:11 INFO     __main__ :: [T0803] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:11 INFO     __main__ :: T0803: ok
2025-09-29 15:31:11 INFO     __main__ :: [T0894] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:11 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:11 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:11 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:11 INFO     __main__ :: [T0821] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:11 INFO     __main__ :: T0821: ok
2025-09-29 15:31:11 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:11 INFO     __main__ :: [T0807] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:11 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:11 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:12 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:12 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:12 INFO     __main__ :: [T0800] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:12 INFO     __main__ :: T0800: ok
2025-09-29 15:31:13 INFO     __main__ :: [T0861] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:13 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:13 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:21 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:21 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:21 INFO     __main__ :: [T0881] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:21 INFO     __main__ :: T0881: ok
2025-09-29 15:31:21 INFO     __main__ :: [T0816] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:21 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:21 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:22 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:22 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:22 INFO     __main__ :: [T0836] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:22 INFO     __main__ :: T0836: ok
2025-09-29 15:31:23 INFO     __main__ :: [T0863] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:23 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:23 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:39 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:39 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:39 INFO     __main__ :: [T0805] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:39 INFO     __main__ :: T0805: ok
2025-09-29 15:31:39 INFO     __main__ :: [T0860] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:39 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:39 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:42 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:42 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:42 INFO     __main__ :: [T0887] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:42 INFO     __main__ :: T0887: ok
2025-09-29 15:31:42 INFO     __main__ :: [T0858] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:42 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:42 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:44 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:44 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:44 INFO     __main__ :: [T0814] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:44 INFO     __main__ :: T0814: ok
2025-09-29 15:31:45 INFO     __main__ :: [T0878] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:45 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:45 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:53 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:53 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:53 INFO     __main__ :: [T0894] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:53 INFO     __main__ :: T0894: ok
2025-09-29 15:31:54 INFO     __main__ :: [T0868] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:54 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:54 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:54 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:54 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:54 INFO     __main__ :: [T0807] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:54 INFO     __main__ :: T0807: ok
2025-09-29 15:31:54 INFO     __main__ :: [T0837] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:54 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:54 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:55 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:55 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:55 INFO     __main__ :: [T0863] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:55 INFO     __main__ :: T0863: ok
2025-09-29 15:31:55 INFO     __main__ :: [T0801] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:55 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:55 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:56 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:31:56 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:31:56 INFO     __main__ :: [T0861] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:56 INFO     __main__ :: T0861: ok
2025-09-29 15:31:56 INFO     __main__ :: [T0853] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:56 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:31:56 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:31:56 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:31:56 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 3.435739905s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}. Falling back to AskSage.
2025-09-29 15:31:56 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:32:04 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:32:04 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:32:04 INFO     __main__ :: [T0860] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:04 INFO     __main__ :: T0860: ok
2025-09-29 15:32:04 INFO     __main__ :: [T0888] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:04 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:04 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:32:11 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:32:11 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:32:11 INFO     __main__ :: [T0816] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:11 INFO     __main__ :: T0816: ok
2025-09-29 15:32:11 INFO     __main__ :: [T0845] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:11 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:11 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:32:25 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:32:25 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:32:25 INFO     __main__ :: [T0837] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:25 INFO     __main__ :: T0837: ok
2025-09-29 15:32:25 INFO     __main__ :: [T0819] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:25 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:25 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:32:27 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:32:27 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:32:27 INFO     __main__ :: [T0868] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:27 INFO     __main__ :: T0868: ok
2025-09-29 15:32:27 INFO     __main__ :: [T0811] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:27 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:27 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:32:32 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:32:32 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:32:32 INFO     __main__ :: [T0858] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:32 INFO     __main__ :: T0858: ok
2025-09-29 15:32:32 INFO     __main__ :: [T0864] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:32 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:32 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:32:36 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:32:36 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:32:36 INFO     __main__ :: [T0888] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:36 INFO     __main__ :: T0888: ok
2025-09-29 15:32:36 INFO     __main__ :: [T0835] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:36 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:36 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:32:40 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:32:40 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:32:40 INFO     __main__ :: [T0878] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:40 INFO     __main__ :: T0878: ok
2025-09-29 15:32:40 INFO     __main__ :: [T0842] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:40 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:40 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:32:42 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:32:42 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:32:42 INFO     __main__ :: [T0801] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:42 INFO     __main__ :: T0801: ok
2025-09-29 15:32:42 INFO     __main__ :: [T0851] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:42 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:42 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:32:51 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:32:51 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:32:51 INFO     __main__ :: [T0845] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:51 INFO     __main__ :: T0845: ok
2025-09-29 15:32:51 INFO     __main__ :: [T0802] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:51 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:32:51 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:07 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:33:07 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:33:07 INFO     __main__ :: [T0835] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:07 INFO     __main__ :: T0835: ok
2025-09-29 15:33:07 INFO     __main__ :: [T0804] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:07 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:07 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:11 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:33:11 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:33:11 INFO     __main__ :: [T0842] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:11 INFO     __main__ :: T0842: ok
2025-09-29 15:33:11 INFO     __main__ :: [T0855] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:11 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:11 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:15 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:33:15 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:33:15 INFO     __main__ :: [T0819] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:15 INFO     __main__ :: T0819: ok
2025-09-29 15:33:15 INFO     __main__ :: [T0809] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:19 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:33:19 INFO     __main__ :: [T0853] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:33:19 INFO     __main__ :: [T0853] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:33:19 INFO     __main__ :: T0853: ok
2025-09-29 15:33:20 INFO     __main__ :: [T0832] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:20 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:20 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:21 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:33:21 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:33:21 INFO     __main__ :: [T0864] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:21 INFO     __main__ :: T0864: ok
2025-09-29 15:33:21 INFO     __main__ :: [T0872] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:21 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:21 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:25 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:33:25 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:33:25 INFO     __main__ :: [T0851] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:25 INFO     __main__ :: T0851: ok
2025-09-29 15:33:25 INFO     __main__ :: [T0877] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:25 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:26 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:26 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:33:26 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:33:26 INFO     __main__ :: [T0802] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:26 INFO     __main__ :: T0802: ok
2025-09-29 15:33:27 INFO     __main__ :: [T0815] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:27 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:27 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:33 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:33:33 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:33:33 INFO     __main__ :: [T0811] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:33 INFO     __main__ :: T0811: ok
2025-09-29 15:33:33 INFO     __main__ :: [T0871] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:33 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:33 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:41 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:33:41 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:33:41 INFO     __main__ :: [T0804] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:41 INFO     __main__ :: T0804: ok
2025-09-29 15:33:41 INFO     __main__ :: [T0862] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:41 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:41 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:46 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:33:46 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:33:46 INFO     __main__ :: [T0855] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:46 INFO     __main__ :: T0855: ok
2025-09-29 15:33:46 INFO     __main__ :: [T0880] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:46 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:46 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:33:58 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:33:58 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:33:58 INFO     __main__ :: [T0871] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:58 INFO     __main__ :: T0871: ok
2025-09-29 15:33:58 INFO     __main__ :: [T0828] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:58 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:33:58 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:06 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:06 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:06 INFO     __main__ :: [T0862] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:06 INFO     __main__ :: T0862: ok
2025-09-29 15:34:06 INFO     __main__ :: [T0865] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:06 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:06 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:10 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:10 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:10 INFO     __main__ :: [T0809] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:10 INFO     __main__ :: T0809: ok
2025-09-29 15:34:10 INFO     __main__ :: [T0895] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:10 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:10 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:10 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:10 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:10 INFO     __main__ :: [T0877] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:10 INFO     __main__ :: T0877: ok
2025-09-29 15:34:10 INFO     __main__ :: [T0817] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:10 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:10 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:11 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:34:11 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 48.937756789s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '48s'}]}}. Falling back to AskSage.
2025-09-29 15:34:11 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:34:13 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:13 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:13 INFO     __main__ :: [T0880] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:13 INFO     __main__ :: T0880: ok
2025-09-29 15:34:13 INFO     __main__ :: [T0879] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:13 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:13 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:15 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:15 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:15 INFO     __main__ :: [T0815] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:15 INFO     __main__ :: T0815: ok
2025-09-29 15:34:15 INFO     __main__ :: [T0856] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:24 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:24 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:24 INFO     __main__ :: [T0872] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:24 INFO     __main__ :: T0872: ok
2025-09-29 15:34:25 INFO     __main__ :: [T0866] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:25 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:25 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:30 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:30 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:30 INFO     __main__ :: [T0832] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:30 INFO     __main__ :: T0832: ok
2025-09-29 15:34:30 INFO     __main__ :: [T0812] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:30 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:30 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:36 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:36 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:36 INFO     __main__ :: [T0828] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:36 INFO     __main__ :: T0828: ok
2025-09-29 15:34:36 INFO     __main__ :: [T0822] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:36 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:36 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:47 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:47 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:47 INFO     __main__ :: [T0865] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:47 INFO     __main__ :: T0865: ok
2025-09-29 15:34:47 INFO     __main__ :: [T0806] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:47 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:47 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:54 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:54 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:54 INFO     __main__ :: [T0879] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:54 INFO     __main__ :: T0879: ok
2025-09-29 15:34:54 INFO     __main__ :: [T0830] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:54 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:54 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:57 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:57 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:57 INFO     __main__ :: [T0856] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:57 INFO     __main__ :: T0856: ok
2025-09-29 15:34:57 INFO     __main__ :: [T0820] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:57 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:57 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:34:59 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:34:59 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:34:59 INFO     __main__ :: [T0895] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:34:59 INFO     __main__ :: T0895: ok
2025-09-29 15:35:00 INFO     __main__ :: [T0827] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:00 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:00 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:35:13 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:35:13 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:35:13 INFO     __main__ :: [T0812] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:13 INFO     __main__ :: T0812: ok
2025-09-29 15:35:13 INFO     __main__ :: [T0874] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:13 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:13 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:35:18 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:35:18 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:35:18 INFO     __main__ :: [T0822] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:18 INFO     __main__ :: T0822: ok
2025-09-29 15:35:19 INFO     __main__ :: [T0823] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:19 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:19 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:35:24 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:35:24 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:35:24 INFO     __main__ :: [T0866] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:24 INFO     __main__ :: T0866: ok
2025-09-29 15:35:24 INFO     __main__ :: [T0848] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:24 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:24 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:35:25 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:35:25 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:35:25 INFO     __main__ :: [T0806] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:25 INFO     __main__ :: T0806: ok
2025-09-29 15:35:25 INFO     __main__ :: [T0834] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:25 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:25 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:35:32 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:35:32 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:35:32 INFO     __main__ :: [T0830] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:32 INFO     __main__ :: T0830: ok
2025-09-29 15:35:32 INFO     __main__ :: [T0826] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:32 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:32 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:35:43 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:35:43 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:35:43 INFO     __main__ :: [T0820] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:43 INFO     __main__ :: T0820: ok
2025-09-29 15:35:43 INFO     __main__ :: [T0882] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:43 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:43 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:35:47 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:35:47 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:35:47 INFO     __main__ :: [T0827] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:47 INFO     __main__ :: T0827: ok
2025-09-29 15:35:47 INFO     __main__ :: [T0857] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:47 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:47 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:35:52 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:35:52 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:35:52 INFO     __main__ :: [T0823] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:52 INFO     __main__ :: T0823: ok
2025-09-29 15:35:52 INFO     __main__ :: [T0849] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:52 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:52 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:35:52 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:35:52 INFO     __main__ :: [T0817] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:35:52 INFO     __main__ :: [T0817] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:35:52 INFO     __main__ :: T0817: ok
2025-09-29 15:35:53 INFO     __main__ :: [T0843] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:53 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:35:53 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:03 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:03 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:03 INFO     __main__ :: [T0834] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:03 INFO     __main__ :: T0834: ok
2025-09-29 15:36:03 INFO     __main__ :: [T0847] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:03 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:03 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:07 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:07 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:07 INFO     __main__ :: [T0848] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:07 INFO     __main__ :: T0848: ok
2025-09-29 15:36:07 INFO     __main__ :: [T0852] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:07 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:07 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:09 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:09 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:09 INFO     __main__ :: [T0874] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:09 INFO     __main__ :: T0874: ok
2025-09-29 15:36:09 INFO     __main__ :: [T0891] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:09 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:09 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:09 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:36:09 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 50.572338131s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '50s'}]}}. Falling back to AskSage.
2025-09-29 15:36:09 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:36:15 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:15 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:15 INFO     __main__ :: [T0826] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:15 INFO     __main__ :: T0826: ok
2025-09-29 15:36:15 INFO     __main__ :: [T0859] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:17 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:17 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:17 INFO     __main__ :: [T0882] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:17 INFO     __main__ :: T0882: ok
2025-09-29 15:36:17 INFO     __main__ :: [T0890] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:17 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:17 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:17 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:36:17 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\nPlease retry in 42.064004238s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}. Falling back to AskSage.
2025-09-29 15:36:17 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:36:19 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:19 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:19 INFO     __main__ :: [T0843] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:19 INFO     __main__ :: T0843: ok
2025-09-29 15:36:19 INFO     __main__ :: [T0846] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:19 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:19 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:23 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:23 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:23 INFO     __main__ :: [T0849] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:23 INFO     __main__ :: T0849: ok
2025-09-29 15:36:23 INFO     __main__ :: [T0884] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:23 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:23 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:27 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:27 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:27 INFO     __main__ :: [T0857] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:27 INFO     __main__ :: T0857: ok
2025-09-29 15:36:27 INFO     __main__ :: [T0869] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:27 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:27 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:28 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:36:28 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\nPlease retry in 31.917516793s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '250'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '31s'}]}}. Falling back to AskSage.
2025-09-29 15:36:28 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:36:31 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:31 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:31 INFO     __main__ :: [T0847] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:31 INFO     __main__ :: T0847: ok
2025-09-29 15:36:31 INFO     __main__ :: [T0886] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:31 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:31 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:32 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:36:32 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\nPlease retry in 27.932872205s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '250'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}. Falling back to AskSage.
2025-09-29 15:36:32 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:36:43 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:43 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:43 INFO     __main__ :: [T0852] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:43 INFO     __main__ :: T0852: ok
2025-09-29 15:36:43 INFO     __main__ :: [T0813] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:43 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:43 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:48 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:36:48 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:36:48 INFO     __main__ :: [T0859] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:48 INFO     __main__ :: T0859: ok
2025-09-29 15:36:48 INFO     __main__ :: [T0838] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:48 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:36:48 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:36:49 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:36:49 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\nPlease retry in 10.772696792s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}. Falling back to AskSage.
2025-09-29 15:36:49 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:37:05 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:37:05 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:37:05 INFO     __main__ :: [T0846] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:05 INFO     __main__ :: T0846: ok
2025-09-29 15:37:05 INFO     __main__ :: [T0885] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:05 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:05 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:37:06 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:37:06 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\nPlease retry in 53.963721788s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}. Falling back to AskSage.
2025-09-29 15:37:06 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:37:22 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:37:22 INFO     __main__ :: [T0891] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:37:22 INFO     __main__ :: [T0891] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:37:22 INFO     __main__ :: T0891: ok
2025-09-29 15:37:22 INFO     __main__ :: [T0873] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:22 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:22 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:37:23 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:37:23 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\nPlease retry in 37.031655712s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '37s'}]}}. Falling back to AskSage.
2025-09-29 15:37:23 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:37:24 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:37:24 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:37:24 INFO     __main__ :: [T0813] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:24 INFO     __main__ :: T0813: ok
2025-09-29 15:37:24 INFO     __main__ :: [T0840] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:24 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:24 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:37:24 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:37:24 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\nPlease retry in 35.529767803s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '250'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}. Falling back to AskSage.
2025-09-29 15:37:24 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:37:33 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:37:33 INFO     __main__ :: [T0890] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:37:33 INFO     __main__ :: [T0890] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:37:33 INFO     __main__ :: T0890: ok
2025-09-29 15:37:33 INFO     __main__ :: [T0867] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:33 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:33 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:37:34 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:37:34 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:37:34 INFO     __main__ :: [T0884] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:34 INFO     __main__ :: T0884: ok
2025-09-29 15:37:34 INFO     __main__ :: [T0839] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:34 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:34 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:37:43 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:37:43 INFO     __main__ :: [T0869] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:37:43 INFO     __main__ :: [T0869] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:37:43 INFO     __main__ :: T0869: ok
2025-09-29 15:37:43 INFO     __main__ :: [T0883] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:43 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:43 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:37:48 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:37:48 INFO     __main__ :: [T0838] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:37:48 INFO     __main__ :: [T0838] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:37:48 INFO     __main__ :: T0838: ok
2025-09-29 15:37:48 INFO     __main__ :: [T0893] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:48 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:48 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:37:55 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:37:55 INFO     __main__ :: [T0886] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:37:55 INFO     __main__ :: [T0886] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:37:55 INFO     __main__ :: T0886: ok
2025-09-29 15:37:55 INFO     __main__ :: [T0892] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:55 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:55 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:37:57 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:37:57 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:37:57 INFO     __main__ :: [T0867] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:57 INFO     __main__ :: T0867: ok
2025-09-29 15:37:58 INFO     __main__ :: [T0889] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:58 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:37:58 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:37:58 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:37:58 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250\nPlease retry in 1.707687042s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '250'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}. Falling back to AskSage.
2025-09-29 15:37:58 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:38:03 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:38:03 INFO     __main__ :: [T0885] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:38:03 INFO     __main__ :: [T0885] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:38:03 INFO     __main__ :: T0885: ok
2025-09-29 15:38:11 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:38:11 INFO     __main__ :: [T0840] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:38:11 INFO     __main__ :: [T0840] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:38:11 INFO     __main__ :: T0840: ok
2025-09-29 15:38:18 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:38:18 INFO     __main__ :: [T0873] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:38:18 INFO     __main__ :: [T0873] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:38:18 INFO     __main__ :: T0873: ok
2025-09-29 15:38:27 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:38:27 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:38:27 INFO     __main__ :: [T0883] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:38:27 INFO     __main__ :: T0883: ok
2025-09-29 15:38:31 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:38:31 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:38:31 INFO     __main__ :: [T0892] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:38:31 INFO     __main__ :: T0892: ok
2025-09-29 15:38:33 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:38:33 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:38:33 INFO     __main__ :: [T0839] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:38:33 INFO     __main__ :: T0839: ok
2025-09-29 15:38:39 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:38:39 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:38:39 INFO     __main__ :: [T0893] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:38:39 INFO     __main__ :: T0893: ok
2025-09-29 15:38:52 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:38:52 INFO     __main__ :: [T0889] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:38:52 INFO     __main__ :: [T0889] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:38:52 INFO     __main__ :: T0889: ok
2025-09-29 15:38:52 INFO     __main__ :: Refinement complete. Refined: 83 | Skipped: 0 | Missing: 0 | Failed: 0
2025-09-29 15:38:52 INFO     __main__ :: Script finished successfully.
