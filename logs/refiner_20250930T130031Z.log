2025-09-30 13:00:31 INFO     __main__ :: Run initialized at: 20250930T130031Z | Logging to: logs/refiner_20250930T130031Z.log
2025-09-30 13:00:31 INFO     __main__ :: Loading Gemini API key
2025-09-30 13:00:31 INFO     __main__ :: Loading Sage API key
2025-09-30 13:00:31 INFO     __main__ :: Loading configuration
2025-09-30 13:00:31 INFO     __main__ :: Successfully loaded configuration from 'config/refine.yml'.
2025-09-30 13:00:31 INFO     __main__ :: Building technique dictionary
2025-09-30 13:00:31 INFO     src.attack_retriever :: Processing matrix: enterprise
2025-09-30 13:00:31 INFO     src.attack_retriever :: Using cached version of 'enterprise' matrix from 'enterprise-attack.json'.
2025-09-30 13:00:37 INFO     src.attack_retriever :: Built dictionary with 679 unique techniques across 1 matrices.
2025-09-30 13:00:37 INFO     __main__ :: Will attempt to refine plans for up to 679 techniques (existing files only).
2025-09-30 13:00:37 INFO     __main__ :: [MAIN pid=69485 proc=MainProcess] Running in multi-core mode with 8 workers.
2025-09-30 13:00:37 INFO     __main__ :: [T1560.001] [pid=69499 proc=ForkProcess-4] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [LLM] [pid=69499 proc=ForkProcess-4] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [T1113] [pid=69502 proc=ForkProcess-7] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [LLM] [pid=69502 proc=ForkProcess-7] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [T1205.002] [pid=69498 proc=ForkProcess-3] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [T1053.005] [pid=69497 proc=ForkProcess-2] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [LLM] [pid=69498 proc=ForkProcess-3] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [T1027.011] [pid=69503 proc=ForkProcess-8] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [LLM] [pid=69497 proc=ForkProcess-2] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [LLM] [pid=69503 proc=ForkProcess-8] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [T1047] [pid=69501 proc=ForkProcess-6] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [LLM] [pid=69501 proc=ForkProcess-6] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [T1055.011] [pid=69496 proc=ForkProcess-1] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [LLM] [pid=69496 proc=ForkProcess-1] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [T1021.005] [pid=69500 proc=ForkProcess-5] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     __main__ :: [LLM] [pid=69500 proc=ForkProcess-5] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:37 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:37 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:37 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:37 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:37 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:37 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:37 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:37 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:38 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2025-09-30 13:00:38 WARNING  __main__ :: [LLM] [pid=69502 proc=ForkProcess-7] Gemini error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}. Retrying in 1.0s ...
2025-09-30 13:00:39 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2025-09-30 13:00:39 WARNING  __main__ :: [LLM] [pid=69503 proc=ForkProcess-8] Gemini error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}. Retrying in 1.0s ...
2025-09-30 13:00:39 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2025-09-30 13:00:39 WARNING  __main__ :: [LLM] [pid=69498 proc=ForkProcess-3] Gemini error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}. Retrying in 1.0s ...
2025-09-30 13:00:39 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2025-09-30 13:00:39 WARNING  __main__ :: [LLM] [pid=69497 proc=ForkProcess-2] Gemini error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}. Retrying in 1.0s ...
2025-09-30 13:00:39 INFO     __main__ :: [LLM] [pid=69502 proc=ForkProcess-7] Attempt 2/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:39 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:40 INFO     __main__ :: [LLM] [pid=69503 proc=ForkProcess-8] Attempt 2/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:40 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:40 INFO     __main__ :: [LLM] [pid=69498 proc=ForkProcess-3] Attempt 2/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:40 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:40 INFO     __main__ :: [LLM] [pid=69497 proc=ForkProcess-2] Attempt 2/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:40 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:40 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-30 13:00:40 ERROR    __main__ :: [LLM] [pid=69498 proc=ForkProcess-3] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 19.511149953s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '19s'}]}}. Falling back to AskSage.
2025-09-30 13:00:40 INFO     __main__ :: [LLM] [pid=69498 proc=ForkProcess-3] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-30 13:00:40 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-30 13:00:40 ERROR    __main__ :: [LLM] [pid=69497 proc=ForkProcess-2] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 19.379857107s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '19s'}]}}. Falling back to AskSage.
2025-09-30 13:00:40 INFO     __main__ :: [LLM] [pid=69497 proc=ForkProcess-2] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-30 13:00:41 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2025-09-30 13:00:41 WARNING  __main__ :: [LLM] [pid=69499 proc=ForkProcess-4] Gemini error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}. Retrying in 1.0s ...
2025-09-30 13:00:41 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2025-09-30 13:00:41 WARNING  __main__ :: [LLM] [pid=69501 proc=ForkProcess-6] Gemini error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}. Retrying in 1.0s ...
2025-09-30 13:00:41 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2025-09-30 13:00:41 WARNING  __main__ :: [LLM] [pid=69502 proc=ForkProcess-7] Gemini error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}. Retrying in 2.0s ...
2025-09-30 13:00:41 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2025-09-30 13:00:41 WARNING  __main__ :: [LLM] [pid=69500 proc=ForkProcess-5] Gemini error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}. Retrying in 1.0s ...
2025-09-30 13:00:42 INFO     __main__ :: [LLM] [pid=69499 proc=ForkProcess-4] Attempt 2/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:42 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:42 INFO     __main__ :: [LLM] [pid=69501 proc=ForkProcess-6] Attempt 2/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:42 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:42 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-30 13:00:42 ERROR    __main__ :: [LLM] [pid=69499 proc=ForkProcess-4] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 17.652914778s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}. Falling back to AskSage.
2025-09-30 13:00:42 INFO     __main__ :: [LLM] [pid=69499 proc=ForkProcess-4] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-30 13:00:42 INFO     __main__ :: [LLM] [pid=69500 proc=ForkProcess-5] Attempt 2/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:42 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:42 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-30 13:00:42 ERROR    __main__ :: [LLM] [pid=69500 proc=ForkProcess-5] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 17.164575537s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}. Falling back to AskSage.
2025-09-30 13:00:42 INFO     __main__ :: [LLM] [pid=69500 proc=ForkProcess-5] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-30 13:00:43 INFO     __main__ :: [LLM] [pid=69502 proc=ForkProcess-7] Attempt 3/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:43 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-30 13:00:43 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-30 13:00:43 ERROR    __main__ :: [LLM] [pid=69502 proc=ForkProcess-7] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 16.407362706s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}. Falling back to AskSage.
2025-09-30 13:00:43 INFO     __main__ :: [LLM] [pid=69502 proc=ForkProcess-7] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-30 13:00:43 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2025-09-30 13:00:43 WARNING  __main__ :: [LLM] [pid=69501 proc=ForkProcess-6] Gemini error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}. Retrying in 2.0s ...
2025-09-30 13:00:44 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 503 Service Unavailable"
2025-09-30 13:00:44 WARNING  __main__ :: [LLM] [pid=69503 proc=ForkProcess-8] Gemini error: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'The model is overloaded. Please try again later.', 'status': 'UNAVAILABLE'}}. Retrying in 2.0s ...
2025-09-30 13:00:45 INFO     __main__ :: [T1578.004] [pid=69500 proc=ForkProcess-5] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:45 INFO     __main__ :: [LLM] [pid=69500 proc=ForkProcess-5] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:45 INFO     __main__ :: [T1027.009] [pid=69502 proc=ForkProcess-7] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:45 INFO     __main__ :: [LLM] [pid=69502 proc=ForkProcess-7] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:45 INFO     __main__ :: [T1056.001] [pid=69501 proc=ForkProcess-6] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:45 INFO     __main__ :: [LLM] [pid=69501 proc=ForkProcess-6] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:45 INFO     __main__ :: [T1556.003] [pid=69499 proc=ForkProcess-4] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-30 13:00:45 INFO     __main__ :: [LLM] [pid=69499 proc=ForkProcess-4] Attempt 1/3: endpoint=gemini model=gemini-2.5-flash
