2025-09-29 15:22:14 INFO     __main__ :: Run initialized at: 20250929T152214Z | Logging to: logs/refiner_20250929T152214Z.log
2025-09-29 15:22:14 INFO     __main__ :: Loading Gemini API key
2025-09-29 15:22:14 INFO     __main__ :: Loading Sage API key
2025-09-29 15:22:14 INFO     __main__ :: Loading configuration
2025-09-29 15:22:14 INFO     __main__ :: Successfully loaded configuration from 'config/refine.yml'.
2025-09-29 15:22:14 INFO     __main__ :: Building technique dictionary
2025-09-29 15:22:14 INFO     src.attack_retriever :: Processing matrix: ics
2025-09-29 15:22:14 INFO     src.attack_retriever :: Using cached version of 'ics' matrix from 'ics-attack.json'.
2025-09-29 15:22:14 INFO     src.attack_retriever :: Built dictionary with 83 unique techniques across 1 matrices.
2025-09-29 15:22:14 INFO     __main__ :: Will attempt to refine plans for up to 83 techniques (existing files only).
2025-09-29 15:22:14 INFO     __main__ :: Running in multi-core mode with 8 workers.
2025-09-29 15:22:14 INFO     __main__ :: [T0803] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0803: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: [T0829] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: [T0836] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0829: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: [T0881] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0836: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: T0881: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: [T0800] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: [T0831] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: [T0887] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0800: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: T0831: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: T0887: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: [T0821] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0821: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: [T0807] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0807: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: [T0814] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0814: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: [T0860] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: [T0894] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0860: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: T0894: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: [T0816] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: [T0805] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0816: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: T0805: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: [T0861] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0861: skip (version_gt)
2025-09-29 15:22:14 INFO     __main__ :: [T0863] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:14 INFO     __main__ :: T0863: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: [T0858] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: [T0878] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: T0858: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: T0878: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: [T0853] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: T0853: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: [T0888] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: [T0801] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: T0888: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: [T0845] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: T0801: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: T0845: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: [T0837] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: T0837: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: [T0868] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:15 INFO     __main__ :: [T0819] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: T0819: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: [T0811] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: T0811: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: [T0864] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [T0802] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: T0802: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: [T0835] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: [T0842] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: [T0851] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: T0835: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: T0842: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: T0851: skip (version_gt)
2025-09-29 15:22:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:15 INFO     __main__ :: [T0804] SKIP: version 1.2 > 1.1.
2025-09-29 15:22:15 INFO     __main__ :: T0804: skip (version_gt)
2025-09-29 15:22:15 INFO     __main__ :: [T0855] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [T0809] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:15 INFO     __main__ :: [T0832] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [T0872] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [T0877] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:15 INFO     __main__ :: [T0815] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:38 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:22:38 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:22:38 INFO     __main__ :: [T0868] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:38 INFO     __main__ :: T0868: ok
2025-09-29 15:22:38 INFO     __main__ :: [T0871] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:38 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:38 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:46 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:22:46 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:22:46 INFO     __main__ :: [T0864] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:46 INFO     __main__ :: T0864: ok
2025-09-29 15:22:46 INFO     __main__ :: [T0862] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:46 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:46 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:48 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:22:48 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:22:48 INFO     __main__ :: [T0877] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:48 INFO     __main__ :: T0877: ok
2025-09-29 15:22:48 INFO     __main__ :: [T0880] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:48 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:48 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:49 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:22:49 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 10.993001356s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}. Falling back to AskSage.
2025-09-29 15:22:49 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:22:49 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:22:49 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:22:49 INFO     __main__ :: [T0855] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:49 INFO     __main__ :: T0855: ok
2025-09-29 15:22:49 INFO     __main__ :: [T0828] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:49 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:49 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:50 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:22:50 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:22:50 INFO     __main__ :: [T0815] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:50 INFO     __main__ :: T0815: ok
2025-09-29 15:22:50 INFO     __main__ :: [T0865] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:50 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:50 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:51 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:22:51 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:22:52 INFO     __main__ :: [T0809] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:52 INFO     __main__ :: T0809: ok
2025-09-29 15:22:52 INFO     __main__ :: [T0895] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:52 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:52 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:56 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:22:56 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:22:56 INFO     __main__ :: [T0872] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:56 INFO     __main__ :: T0872: ok
2025-09-29 15:22:56 INFO     __main__ :: [T0817] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:56 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:22:56 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:22:56 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:22:56 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 3.558756601s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}. Falling back to AskSage.
2025-09-29 15:22:56 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:23:10 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:23:10 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:23:10 INFO     __main__ :: [T0871] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:10 INFO     __main__ :: T0871: ok
2025-09-29 15:23:10 INFO     __main__ :: [T0879] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:10 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:10 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:23:10 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:23:10 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 49.487385763s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '49s'}]}}. Falling back to AskSage.
2025-09-29 15:23:10 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:23:14 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:23:14 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:23:14 INFO     __main__ :: [T0862] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:14 INFO     __main__ :: T0862: ok
2025-09-29 15:23:14 INFO     __main__ :: [T0856] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:14 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:14 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:23:14 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:23:14 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 45.285434992s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '45s'}]}}. Falling back to AskSage.
2025-09-29 15:23:14 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:23:17 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:23:17 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:23:17 INFO     __main__ :: [T0832] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:17 INFO     __main__ :: T0832: ok
2025-09-29 15:23:17 INFO     __main__ :: [T0866] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:17 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:17 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:23:26 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:23:26 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:23:26 INFO     __main__ :: [T0865] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:26 INFO     __main__ :: T0865: ok
2025-09-29 15:23:26 INFO     __main__ :: [T0812] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:26 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:26 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:23:27 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:23:27 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:23:27 INFO     __main__ :: [T0895] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:27 INFO     __main__ :: T0895: ok
2025-09-29 15:23:27 INFO     __main__ :: [T0822] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:27 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:27 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:23:32 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:23:32 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:23:32 INFO     __main__ :: [T0828] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:32 INFO     __main__ :: T0828: ok
2025-09-29 15:23:32 INFO     __main__ :: [T0806] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:32 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:32 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:23:43 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:23:43 INFO     __main__ :: [T0880] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:23:43 INFO     __main__ :: [T0880] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:23:43 INFO     __main__ :: T0880: ok
2025-09-29 15:23:43 INFO     __main__ :: [T0830] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:43 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:43 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:23:56 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:23:56 INFO     __main__ :: [T0817] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:23:56 INFO     __main__ :: [T0817] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:23:56 INFO     __main__ :: T0817: ok
2025-09-29 15:23:56 INFO     __main__ :: [T0820] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:56 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:23:56 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:02 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:02 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:02 INFO     __main__ :: [T0866] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:02 INFO     __main__ :: T0866: ok
2025-09-29 15:24:02 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:02 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:02 INFO     __main__ :: [T0812] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:02 INFO     __main__ :: T0812: ok
2025-09-29 15:24:02 INFO     __main__ :: [T0827] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:02 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:02 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:02 INFO     __main__ :: [T0874] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:02 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:02 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:10 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:24:10 INFO     __main__ :: [T0879] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:24:10 INFO     __main__ :: [T0879] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:24:10 INFO     __main__ :: T0879: ok
2025-09-29 15:24:10 INFO     __main__ :: [T0823] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:10 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:10 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:13 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:13 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:13 INFO     __main__ :: [T0822] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:13 INFO     __main__ :: T0822: ok
2025-09-29 15:24:13 INFO     __main__ :: [T0848] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:13 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:13 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:18 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:18 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:18 INFO     __main__ :: [T0806] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:18 INFO     __main__ :: T0806: ok
2025-09-29 15:24:18 INFO     __main__ :: [T0834] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:18 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:18 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:28 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:28 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:28 INFO     __main__ :: [T0830] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:28 INFO     __main__ :: T0830: ok
2025-09-29 15:24:28 INFO     __main__ :: [T0826] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:28 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:28 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:30 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:24:30 INFO     __main__ :: [T0856] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:24:30 ERROR    __main__ :: [T0856] FAIL: JSON decode error: Expecting value: line 31 column 1 (char 2838)
2025-09-29 15:24:30 INFO     __main__ :: T0856: fail (json_error: Expecting value: line 31 column 1 (char 2838))
2025-09-29 15:24:30 INFO     __main__ :: [T0882] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:30 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:30 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:33 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:33 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:33 INFO     __main__ :: [T0827] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:33 INFO     __main__ :: T0827: ok
2025-09-29 15:24:33 INFO     __main__ :: [T0857] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:33 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:33 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:44 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:44 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:44 INFO     __main__ :: [T0823] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:44 INFO     __main__ :: T0823: ok
2025-09-29 15:24:45 INFO     __main__ :: [T0849] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:45 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:45 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:45 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:45 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:45 INFO     __main__ :: [T0820] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:45 INFO     __main__ :: T0820: ok
2025-09-29 15:24:46 INFO     __main__ :: [T0843] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:46 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:46 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:51 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:51 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:51 INFO     __main__ :: [T0874] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:51 INFO     __main__ :: T0874: ok
2025-09-29 15:24:51 INFO     __main__ :: [T0847] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:51 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:51 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:53 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:53 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:53 INFO     __main__ :: [T0834] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:53 INFO     __main__ :: T0834: ok
2025-09-29 15:24:54 INFO     __main__ :: [T0852] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:54 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:54 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:24:59 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:24:59 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:24:59 INFO     __main__ :: [T0848] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:59 INFO     __main__ :: T0848: ok
2025-09-29 15:24:59 INFO     __main__ :: [T0891] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:59 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:24:59 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:25:03 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:25:03 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:25:03 INFO     __main__ :: [T0826] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:03 INFO     __main__ :: T0826: ok
2025-09-29 15:25:04 INFO     __main__ :: [T0859] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:04 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:04 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:25:10 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:25:10 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:25:10 INFO     __main__ :: [T0882] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:10 INFO     __main__ :: T0882: ok
2025-09-29 15:25:10 INFO     __main__ :: [T0890] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:10 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:10 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:25:15 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:25:15 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:25:15 INFO     __main__ :: [T0843] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:15 INFO     __main__ :: T0843: ok
2025-09-29 15:25:15 INFO     __main__ :: [T0846] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:15 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:15 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:25:21 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:25:21 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:25:21 INFO     __main__ :: [T0857] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:21 INFO     __main__ :: T0857: ok
2025-09-29 15:25:22 INFO     __main__ :: [T0884] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:22 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:22 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:25:24 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:25:24 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:25:24 INFO     __main__ :: [T0847] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:24 INFO     __main__ :: T0847: ok
2025-09-29 15:25:24 INFO     __main__ :: [T0869] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:24 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:24 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:25:24 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:25:24 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:25:24 INFO     __main__ :: [T0849] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:24 INFO     __main__ :: T0849: ok
2025-09-29 15:25:24 INFO     __main__ :: [T0886] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:24 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:24 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:25:29 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:25:29 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:25:29 INFO     __main__ :: [T0852] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:29 INFO     __main__ :: T0852: ok
2025-09-29 15:25:29 INFO     __main__ :: [T0813] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:29 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:29 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:25:30 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:25:30 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:25:30 INFO     __main__ :: [T0891] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:30 INFO     __main__ :: T0891: ok
2025-09-29 15:25:31 INFO     __main__ :: [T0838] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:31 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:31 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:25:46 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:25:46 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:25:46 INFO     __main__ :: [T0890] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:46 INFO     __main__ :: T0890: ok
2025-09-29 15:25:46 INFO     __main__ :: [T0885] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:46 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:46 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:25:48 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:25:48 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:25:48 INFO     __main__ :: [T0859] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:48 INFO     __main__ :: T0859: ok
2025-09-29 15:25:49 INFO     __main__ :: [T0873] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:49 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:25:49 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:26:00 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:00 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:00 INFO     __main__ :: [T0884] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:00 INFO     __main__ :: T0884: ok
2025-09-29 15:26:00 INFO     __main__ :: [T0840] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:00 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:00 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:26:01 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:01 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:01 INFO     __main__ :: [T0846] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:01 INFO     __main__ :: T0846: ok
2025-09-29 15:26:02 INFO     __main__ :: [T0867] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:02 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:02 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:26:04 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:04 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:04 INFO     __main__ :: [T0813] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:04 INFO     __main__ :: T0813: ok
2025-09-29 15:26:05 INFO     __main__ :: [T0839] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:05 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:05 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:26:12 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:12 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:12 INFO     __main__ :: [T0886] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:12 INFO     __main__ :: T0886: ok
2025-09-29 15:26:13 INFO     __main__ :: [T0883] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:13 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:13 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:26:13 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:13 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:13 INFO     __main__ :: [T0869] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:13 INFO     __main__ :: T0869: ok
2025-09-29 15:26:13 INFO     __main__ :: [T0893] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:13 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:13 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:26:13 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 429 Too Many Requests"
2025-09-29 15:26:13 ERROR    __main__ :: [LLM] Gemini rate/quota issue: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10\nPlease retry in 46.223214918s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}. Falling back to AskSage.
2025-09-29 15:26:13 INFO     __main__ :: [LLM] Using endpoint=AskSage model=google-gemini-2.5-pro
2025-09-29 15:26:21 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:21 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:21 INFO     __main__ :: [T0885] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:21 INFO     __main__ :: T0885: ok
2025-09-29 15:26:21 INFO     __main__ :: [T0892] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:21 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:21 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:26:26 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:26 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:26 INFO     __main__ :: [T0838] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:26 INFO     __main__ :: T0838: ok
2025-09-29 15:26:26 INFO     __main__ :: [T0889] START: about to process with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:26 INFO     __main__ :: [LLM] Attempt 1/3: using endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:26 INFO     google_genai.models :: AFC is enabled with max remote calls: 10.
2025-09-29 15:26:29 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:29 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:29 INFO     __main__ :: [T0873] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:29 INFO     __main__ :: T0873: ok
2025-09-29 15:26:31 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:31 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:31 INFO     __main__ :: [T0840] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:31 INFO     __main__ :: T0840: ok
2025-09-29 15:26:33 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:33 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:33 INFO     __main__ :: [T0839] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:33 INFO     __main__ :: T0839: ok
2025-09-29 15:26:39 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:39 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:39 INFO     __main__ :: [T0883] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:39 INFO     __main__ :: T0883: ok
2025-09-29 15:26:42 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:42 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:42 INFO     __main__ :: [T0867] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:42 INFO     __main__ :: T0867: ok
2025-09-29 15:26:54 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:26:54 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:26:54 INFO     __main__ :: [T0892] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:26:54 INFO     __main__ :: T0892: ok
2025-09-29 15:27:05 INFO     httpx :: HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent "HTTP/1.1 200 OK"
2025-09-29 15:27:05 INFO     __main__ :: [LLM] Gemini success with model=gemini-2.5-flash
2025-09-29 15:27:05 INFO     __main__ :: [T0889] DONE: processing complete with endpoint=gemini model=gemini-2.5-flash
2025-09-29 15:27:05 INFO     __main__ :: T0889: ok
2025-09-29 15:27:06 INFO     __main__ :: [LLM] AskSage success with model=google-gemini-2.5-pro
2025-09-29 15:27:06 INFO     __main__ :: [T0893] INFO: fell back to endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:27:06 INFO     __main__ :: [T0893] DONE: processing complete with endpoint=asksage model=google-gemini-2.5-pro
2025-09-29 15:27:06 INFO     __main__ :: T0893: ok
2025-09-29 15:27:06 INFO     __main__ :: Refinement complete. Refined: 52 | Skipped: 30 | Missing: 0 | Failed: 1
2025-09-29 15:27:06 INFO     __main__ :: Script finished successfully.
