[
  {
    "information_requirement": "Is the adversary attempting to hide their activity to evade detection? (PIR)",
    "tactic_id": "TA0005",
    "tactic_name": "Defense Evasion",
    "indicators": [
      {
        "technique_id": "T1564",
        "name": "Hide Artifacts",
        "evidence": [
          {
            "description": "A process is created (Windows Event ID 4688) with a name or hash matching a known artifact-hiding tool (e.g., Slacker, Transmo), or a file is created (Windows Event ID 4663) with a name or hash matching a known rootkit component.",
            "data_sources": [
              "Windows Event ID 4688",
              "Windows Event ID 4663"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "All Windows Endpoints, All Windows Servers, Domain Controllers",
            "action": "1. Symbolic: Create a detection rule that queries process creation events (Windows Event ID 4688) and file creation events (Windows Event ID 4663) for process names, file names, or their corresponding hashes that match a curated threat intelligence list of tools known for hiding artifacts. 2. Statistical: For each process creation event, calculate the prevalence of the parent process name across the enterprise. Flag instances where a rare parent process (e.g., winword.exe, explorer.exe) spawds a command-line utility. Identify processes whose names have a high Levenshtein distance from common system processes but a low distance from known malicious tools, indicating typosquatting. 3. Machine Learning: Develop a supervised classification model (e.g., a Random Forest) trained on features from process creation events, including process name, parent process name, command-line length, and entropy. Train the model to classify events as benign or indicative of malicious tool execution."
          },
          {
            "description": "A command-line execution (Windows Event ID 4688) contains patterns consistent with hiding files, directories, or Alternate Data Streams (ADS), such as `attrib.exe +h`, `icacls.exe ... /deny`, or PowerShell stream manipulation.",
            "data_sources": [
              "Windows Event ID 4688"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "All Windows Endpoints, File Servers, Application Servers",
            "action": "1. Symbolic: Implement a SIEM rule using regular expressions to search command-line logs (Windows Event ID 4688) for specific strings like `attrib +h`, `icacls`, `type .* > .*:`, `Set-Content .* -Stream`, and `makecab` used with suspicious file paths. 2. Statistical: Establish a baseline of command-line argument patterns for common utilities (attrib.exe, icacls.exe, powershell.exe). Calculate the frequency of argument combinations. Flag executions where the combination of arguments is in the bottom 5th percentile of historical usage, indicating anomalous use. 3. Machine Learning: Use an unsupervised learning model, such as an autoencoder, to learn the normal structure of command-line arguments for system utilities. Feed command-line logs into the model and flag any command with a high reconstruction error, which suggests it deviates significantly from learned normal patterns."
          },
          {
            "description": "The 'Modified' or 'Created' timestamp of a file (observed via Windows Event ID 4663) is altered to a value significantly older than its 'Entry Modified' timestamp ($MFT), or to a value identical to a known-good system file in the same directory, particularly after being created by a process known for timestomping (Windows Event ID 4688).",
            "data_sources": [
              "Windows Event ID 4663",
              "Windows Event ID 4688"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Critical System Directories (e.g., System32), User Profile Directories, Temporary File Locations",
            "action": "1. Symbolic: Monitor process creation events (Windows Event ID 4688) for the execution of PowerShell with `Set-ItemProperty` and `-Name CreationTime` or `-Name LastWriteTime` arguments, or the execution of known timestomping utilities. Correlate these process events with nearby file modification events (Windows Event ID 4663). 2. Statistical: For file modification events (Windows Event ID 4663) in sensitive directories, calculate the time delta between the file's 'Created'/'Modified' timestamp and the event's occurrence time. Flag files where this delta is anomalously large (e.g., > 99th percentile) or negative. Compare the timestamps of a newly modified file to its neighboring files; flag if the timestamp is identical to an adjacent system file. 3. Machine Learning: Employ a time-series anomaly detection model on file system metadata. For a given file, model the expected sequence of timestamp changes. An event where a timestamp is set to a past value, breaking the monotonically increasing nature of time, would be flagged as a significant anomaly."
          },
          {
            "description": "A process is initiated (Windows Event ID 4688) from a file path that is hidden, resides in a temporary or unusual directory (e.g., C:\\Users\\Public, Recycle Bin), or is an Alternate Data Stream (ADS), and this process subsequently initiates an external network connection (Zeek conn.log).",
            "data_sources": [
              "Windows Event ID 4688",
              "Windows Event ID 5156",
              "Zeek conn.log"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "All Windows Endpoints, Network Egress Points (Firewalls, Proxies), DNS Servers",
            "action": "1. Symbolic: Create a correlation rule that joins process creation events (Windows Event ID 4688) with network connection logs (Zeek conn.log) on source IP and timestamp. Trigger an alert if a process path matches a regex for suspicious locations (e.g., `.*\\\\AppData\\\\Local\\\\Temp\\\\.*`, `C:\\\\Users\\\\Public\\\\.*`, `.*:.*\\\\.*`, `C:\\\\$Recycle.Bin\\\\.*`) and the corresponding network connection is to a known malicious IP or a low-reputation domain. 2. Statistical: Profile the execution paths for all processes. Calculate the rarity of each directory path being a source of execution using a method like TF-IDF. Assign a risk score based on path rarity. Sum this with scores from other attributes (e.g., unsigned binary, outbound connection to a high port) to create a composite risk score. Alert on processes exceeding a statistical threshold (e.g., 3 standard deviations above the mean score). 3. Machine Learning: Use a graph-based analysis model. Create a graph where nodes are processes, files, and network endpoints, and edges represent interactions. Apply a community detection algorithm to identify clusters of activity. A subgraph containing a process from a rare path, writing temporary files, and connecting to an external IP is a strong indicator of malicious activity."
          },
          {
            "description": "A new user account is created (Windows Event ID 4720) or a new scheduled task is registered (Windows Event ID 4698) with a name that is either a random-looking string (high Shannon entropy) or a close impersonation of a legitimate system account/task (low Levenshtein distance to 'svchost', 'administrator', etc.).",
            "data_sources": [
              "Windows Event ID 4720",
              "Windows Event ID 4698"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Domain Controllers, Active Directory Servers, All Windows Endpoints and Servers",
            "action": "1. Symbolic: Use a watchlist of common system account and task names (e.g., 'Administrator', 'SYSTEM', 'GoogleUpdateTask'). Create a rule that alerts on the creation of new accounts/tasks (Windows Event ID 4720, 4698) whose names are a close typographical match (e.g., Levenshtein distance of 1 or 2) to names on the watchlist, such as 'Administartor' or 'svch0st'. 2. Statistical: For every new user account or scheduled task name, calculate its Shannon entropy score. Establish a baseline entropy distribution for legitimate names in your environment. Flag any new name whose entropy score falls in the top 5th percentile, indicating a high degree of randomness. 3. Machine Learning: Train a one-class SVM (Support Vector Machine) on the feature vectors of all existing, legitimate account and task names. Features can include name length, character frequency distribution, and entropy. Use the trained model to classify new names. Any name that falls outside the learned boundary of 'normal' is flagged as an anomaly."
          }
        ]
      }
    ],
    "version": "2.2",
    "date_created": "2025-05-04",
    "last_updated": "2025-09-29",
    "contributors": [
      "Zachary Szewczyk"
    ]
  }
]