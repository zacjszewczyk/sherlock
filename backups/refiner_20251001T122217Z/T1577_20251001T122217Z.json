[
  {
    "information_requirement": "Has an adversary established persistence by modifying a legitimate application executable on a mobile device? (PIR)",
    "tactic_id": "TA0028",
    "tactic_name": "Persistence",
    "indicators": [
      {
        "technique_id": "T1577",
        "name": "Compromise Application Executable",
        "evidence": [
          {
            "description": "The SHA-256 hash of an installed application package on a mobile device, as reported by an MDM or EDR agent, does not match the known-good hash value stored in an authoritative organizational application manifest for that specific application and version. A mismatch is a direct indicator of unauthorized modification, such as rebuilding an application with malicious code [2].",
            "data_sources": [
              "MDM application inventory report (App ID, App Version, file hash)",
              "Mobile EDR agent logs (file path, SHA-256 hash)",
              "Organizational Application Manifest (App ID, App Version, known-good hash)"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Managed mobile device fleet (iOS, Android), Mobile Device Management (MDM) / Unified Endpoint Management (UEM) server, Organizational application manifest repository",
            "action": "1. (Symbolic) Continuously query and join MDM/EDR application inventory logs with the organizational application manifest on the application ID and version. Generate a high-severity alert for any device where the 'collected_hash' does not match the 'manifest_hash'. 2. (Statistical) For each unique application (e.g., 'com.example.app'), aggregate version data across the entire device fleet. Calculate the installation count for each version string. Generate a medium-severity alert for any device reporting an application version with a prevalence below a defined threshold (e.g., installed on fewer than 5 devices or <0.5% of the fleet), as this may indicate a non-standard or maliciously patched version requiring review. 3. (Machine Learning) For each device, generate a feature vector representing its installed applications (e.g., a multi-hot encoded vector of all possible app IDs). Train an Isolation Forest model on the feature vectors from the entire managed device fleet to learn 'normal' application profiles. Score each device in real-time; devices with an anomaly score indicating they are a significant outlier from the population should be flagged for investigation of unauthorized or modified software."
          },
          {
            "description": "Static analysis of an Android Application Package (APK) reveals a file structure where data exists after the APK's central directory but before the DEX section. This is a specific artifact of the Janus vulnerability (CVE-2017-13156), which allows malicious code injection without invalidating the v1 signature scheme [1].",
            "data_sources": [
              "Raw APK files retrieved from endpoints",
              "Mobile App Vetting (MAV) static analysis reports",
              "Digital forensic image of device storage"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Managed Android device fleet, Application sandbox environment, Mobile security analysis platforms",
            "action": "1. (Symbolic) Within a Mobile App Vetting (MAV) platform, create a static analysis rule to scan submitted APKs for byte sequences located between the end of the ZIP central directory and the start of the DEX file. Generate a critical-severity alert upon detection, as this is a strong signature of the Janus vulnerability (CVE-2017-13156). 2. (Statistical) For a large population of APKs analyzed by the MAV, calculate the size difference: $$ \\Delta_{size} = size_{on\\_disk} - size_{central\\_directory} $$. Establish a baseline distribution for this delta, which should be near zero for most valid apps. Alert on any APK where $$ \\Delta_{size} $$ is a statistical outlier (e.g., greater than the 99th percentile), indicating potentially injected data. 3. (Machine Learning) Train a supervised classification model (e.g., Gradient Boosting) using features extracted from APK file structures. Features should include header flags, section counts, file size discrepancies, and the Shannon entropy of file sections. Use a labeled dataset of known-benign, Janus-exploited, and other repacked malicious APKs. Integrate the trained model into the MAV pipeline to produce a risk score for all new and updated applications."
          },
          {
            "description": "Network traffic from a managed mobile device, attributed to a specific whitelisted application by an EDR or CASB, exhibits characteristics that deviate from an established baseline. Anomalies include connections to known malicious domains, DNS queries with high Shannon entropy indicative of DGA, or data transfer volumes that are statistical outliers.",
            "data_sources": [
              "Zeek conn.log",
              "Zeek dns.log",
              "CASB logs with application attribution",
              "Mobile EDR network flow logs"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Corporate Wi-Fi network gateways, VPN egress points, DNS resolvers, Cloud Access Security Broker (CASB) logs",
            "action": "1. (Symbolic) In a SIEM, enrich network logs (e.g., Zeek conn.log) with application context from CASB or EDR logs and device identity from DHCP/VPN logs. Correlate the destination IP or domain against a threat intelligence feed of known C2 servers. Generate a high-severity alert if a whitelisted application on a managed device communicates with a malicious indicator. 2. (Statistical) For each whitelisted application, establish a 30-day rolling baseline of network behavior per device. A) Using Zeek conn.log, calculate the 95th percentile for total bytes transferred ($$ orig\\_bytes + resp\\_bytes $$) per hour. Alert if an application's traffic exceeds this threshold. B) Using Zeek dns.log, calculate the average Shannon entropy of DNS queries made by the app. Alert if a new query's entropy score is more than 3 standard deviations above the app's historical average, suggesting DGA. 3. (Machine Learning) For each device-application pair, create a multivariate time-series dataset from network logs, including features like bytes sent/received per minute, connection count per minute, and unique destination IPs per hour. Train an LSTM Autoencoder model to learn the normal temporal patterns of network activity. In production, feed live data into the model and alert when the reconstruction error exceeds a dynamic threshold, indicating a significant behavioral deviation from the learned norm."
          }
        ]
      }
    ],
    "last_updated": "2025-09-29",
    "version": "1.3",
    "date_created": "2025-09-26",
    "contributors": [
      "Zachary Szewczyk",
      "Ask Sage"
    ]
  }
]