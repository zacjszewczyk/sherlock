name: 'T1628.001: Suppress Application Icon'
id: '6c1a8a2d-b586-4448-9630-f20349079f87'
description: 'Is an adversary hiding malicious applications by suppressing their icons on managed mobile devices? This playbook helps detect this Defense Evasion technique by identifying applications that are installed but lack corresponding user launch activity, monitoring for unusual process behavior where a launcher process opens an application''s settings page directly, and performing static analysis on application packages (APKs) to find code that programmatically disables its own launcher icon.'
type: 'technique'
related:
  - 'TA0030: Defense Evasion'
contributors:
  - 'Zachary Szewczyk'
  - 'Ask Sage'
created: '2025-10-01'
modified: '2025-10-01'
version: '1.0'
tags: 'none'
questions:
  - question: 'How can I detect installed applications that have no user launch activity, which might indicate a hidden, non-interactive malicious app?'
    context: 'This question addresses the detection of "ghost" applications. An adversary may install a malicious payload that runs as a background service without a user-launchable icon. By joining Mobile Device Management (MDM) inventory logs with Mobile Endpoint Detection and Response (EDR) launch activity logs, an analyst can identify packages that are present on a device but have never been launched by the user. This query is designed to filter out known helper applications and automatically enrich findings with threat intelligence to assess risk.'
    answer_sources:
      - 'MDM application inventory logs'
      - 'Mobile EDR launcher intent logs'
      - 'Threat intelligence package name blocklists'
      - 'Zeek conn.log'
      - 'Zeek dns.log'
      - 'Corporate-owned and bring-your-own-device (BYOD) mobile endpoints, MDM and Mobile Threat Defense (MTD) management servers, Security Information and Event Management (SIEM) platform, Network egress gateways, Internal DNS resolvers'
    range: 'last 30 days'
    queries:
      - 'Pseudocode: |
          SEARCH mdm_inventory_logs
          | LEFT JOIN edr_launcher_logs ON device_id, package_name
          | WHERE edr_launcher_logs.package_name IS NULL
          | AND mdm_inventory_logs.package_name NOT IN allowlist
          | DEDUP package_name
          | LOOKUP threat_intelligence FOR package_name, package_hash
          | ALERT'
  - question: 'How can I identify an unusually widespread installation of a non-launcher application, which could signal a coordinated malicious campaign?'
    context: 'While some non-launcher applications are benign services or plugins, a malicious non-interactive application might be pushed to many devices in a coordinated attack. This question focuses on using prevalence analysis to spot such threats. By first establishing a baseline installation count for known benign helper apps over a 90-day period, an analyst can then identify any new non-launcher app whose fleet-wide installation count is a statistical outlier (e.g., exceeds the 99th percentile), indicating an anomalous and potentially malicious distribution.'
    answer_sources:
      - 'MDM application inventory logs'
      - 'Mobile EDR launcher intent logs'
      - 'Threat intelligence package name blocklists'
      - 'Zeek conn.log'
      - 'Zeek dns.log'
      - 'Corporate-owned and bring-your-own-device (BYOD) mobile endpoints, MDM and Mobile Threat Defense (MTD) management servers, Security Information and Event Management (SIEM) platform, Network egress gateways, Internal DNS resolvers'
    range: 'last 90 days'
    queries:
      - 'Pseudocode: |
          // Step 1: Baseline benign apps
          SEARCH known_benign_non_launcher_apps over last 90 days
          | STATS count(device_id) by package_name
          | EVALUATE percentile(count, 99) as threshold
          
          // Step 2: Check new apps against baseline
          SEARCH new_non_launcher_apps
          | STATS count(device_id) by package_name
          | WHERE count > threshold
          | ALERT'
  - question: 'How can I build a machine learning model to assign a risk score to non-launcher applications based on their characteristics and network behavior?'
    context: 'To move beyond simple rules, this question proposes a machine learning approach for risk scoring. By training a logistic regression model, an analyst can proactively identify suspicious non-launcher apps. The model uses features from MDM logs (e.g., sideloaded status, dangerous permissions) and correlated network logs, such as the Shannon entropy of destination IPs ($$ H(X) = -\\sum p(x) \\log_2 p(x) $$) or queried domains, to predict the probability that an application is malicious. An alert is triggered if the probability exceeds a set threshold, such as $$ P(malicious) > 0.8 $$, automating the initial triage process.'
    answer_sources:
      - 'MDM application inventory logs'
      - 'Mobile EDR launcher intent logs'
      - 'Threat intelligence package name blocklists'
      - 'Zeek conn.log'
      - 'Zeek dns.log'
      - 'Corporate-owned and bring-your-own-device (BYOD) mobile endpoints, MDM and Mobile Threat Defense (MTD) management servers, Security Information and Event Management (SIEM) platform, Network egress gateways, Internal DNS resolvers'
    range: 'last 90 days'
    queries:
      - 'Pseudocode: |
          // Feature Engineering
          FETCH app_metadata from MDM
          EXTRACT is_sideloaded, permission_count, app_age
          CORRELATE device_ip with network_logs
          CALCULATE shannon_entropy(destination_ips), shannon_entropy(dns_queries)
          
          // Model Prediction
          LOAD logistic_regression_model
          PREDICT probability = model.predict(features)
          
          // Alerting
          IF probability > 0.8 THEN
            ALERT for analyst review
          END'
  - question: 'How can I detect if a user is being redirected from the home screen directly to an application''s settings page, indicating a synthesized icon was used to trick them?'
    context: 'Adversaries can create a fake icon that, when clicked, opens the system settings page for a hidden malicious app, tricking the user into enabling it. This question provides a specific SIEM rule to detect this behavior. The rule looks for process creation events where a known launcher process spawns the system settings process (`com.android.settings`) with command-line arguments that specify a target package, a clear indicator of this redirection technique.'
    answer_sources:
      - 'Mobile EDR process creation event logs'
      - 'Android Logcat logs'
      - 'ITSM ticket data'
      - 'Managed mobile endpoints running Android 10 or newer, EDR and SIEM log aggregation platforms, IT Service Management system'
    range: 'last 90 days'
    queries:
      - 'Pseudocode: |
          SEARCH process_creation_events
          | WHERE parent_process_name IN launcher_allowlist
          | AND process_name = ''com.android.settings''
          | AND process_cmdline CONTAINS ''com.android.settings.ApplicationDetailsPages''
          | AND process_cmdline CONTAINS ''package:''
          | EXTRACT package_name from process_cmdline
          | ALERT on package_name'
  - question: 'How can I use statistical analysis to find anomalous spikes in "launcher-to-settings" redirection events for a specific application?'
    context: 'A single redirection event could be benign, but a sudden increase across the fleet for one application is highly suspicious. This question focuses on anomaly detection by monitoring the frequency of the redirection behavior. By calculating a 30-day moving average ($$ MA_{30} $$) and standard deviation ($$ \\sigma_{30} $$) of these events per application, an analyst can create an alert that triggers when the daily count exceeds a statistical threshold (e.g., $$ DailyCount > MA_{30} + 3\\sigma_{30} $$), flagging a significant and likely malicious spike in activity.'
    answer_sources:
      - 'Mobile EDR process creation event logs'
      - 'Android Logcat logs'
      - 'ITSM ticket data'
      - 'Managed mobile endpoints running Android 10 or newer, EDR and SIEM log aggregation platforms, IT Service Management system'
    range: 'last 30 days'
    queries:
      - 'Pseudocode: |
          SEARCH alerts_from_redirection_rule over last 31 days
          | STATS count by package_name, day
          | CALCULATE moving_avg(count, 30) as MA30
          | CALCULATE std_dev(count, 30) as SD30
          | WHERE latest_day_count > (MA30 + 3 * SD30)
          | ALERT on package_name for anomalous spike'
  - question: 'How can a sequence analysis model be used to detect the anomalous user navigation path of going directly from the home screen to an app''s details page?'
    context: 'This question proposes using a behavioral model to detect synthesized icons. Normal user navigation follows common paths (e.g., home screen to app drawer). A direct transition from the home screen to an app''s settings details page is a highly anomalous sequence. By training a Hidden Markov Model (HMM) on sequences of UI events from normal usage, the model can learn the probabilities of state transitions. It can then score new user sessions and alert on the detection of this low-probability, suspicious navigation path.'
    answer_sources:
      - 'Mobile EDR process creation event logs'
      - 'Android Logcat logs'
      - 'ITSM ticket data'
      - 'Managed mobile endpoints running Android 10 or newer, EDR and SIEM log aggregation platforms, IT Service Management system'
    range: 'last 90 days'
    queries:
      - 'Pseudocode: |
          // Model Training
          FETCH ui_events, process_creations from EDR
          DEFINE states (HomeScreen, AppDrawer, AppDetailsPage, etc.)
          TRAIN HMM on baseline event sequences
          
          // Anomaly Detection
          FOR each user session:
            CONVERT session to state_sequence
            IF sequence contains ''HomeScreen'' -> ''AppDetailsPage'' transition:
              ALERT with low probability score'
  - question: 'How can I use a YARA rule to statically detect APKs that contain code to programmatically disable their own launcher icon?'
    context: 'This question describes a preventive control for an application vetting pipeline. A YARA rule can be crafted to detect the specific bytecode sequence for the `PackageManager.setComponentEnabledSetting` API call used with the `COMPONENT_ENABLED_STATE_DISABLED` flag. When the rule matches, a post-processing script can parse the APK''s `AndroidManifest.xml` to confirm that the disabled component was, in fact, the main launcher. A confirmed match allows the pipeline to automatically block the malicious application before it is ever distributed to users.'
    answer_sources:
      - 'Static analysis reports from application vetting sandbox'
      - 'Mobile application reputation service logs'
      - 'APK files'
      - 'Organizational application stores (e.g., managed Google Play), Application vetting sandboxes, Developer CI/CD pipelines, Threat intelligence platforms'
    range: 'last 90 days'
    queries:
      - 'Pseudocode: |
          // YARA Rule (conceptual)
          rule DisableLauncherComponent {
            strings: $api_call = "setComponentEnabledSetting"
            condition: $api_call
          }
          
          // Vetting Pipeline Logic
          SCAN apk with YARA rule
          IF match:
            PARSE AndroidManifest.xml
            CHECK if disabled component has LAUNCHER intent
            IF true:
              BLOCK application and ALERT'
  - question: 'How can I identify suspicious APKs by comparing their API usage and code complexity against a baseline of known-benign applications?'
    context: 'This question outlines an anomaly detection method for static analysis. An app that hides its icon should be scrutinized further. This is achieved by calculating the Jaccard distance ($$ d_J(A, B) = 1 - \\frac{|A \\cap B|}{|A \\cup B|} $$) between the API call set of a new app and that of a known-benign corpus, and by measuring the Shannon entropy of its code to detect obfuscation. An application that both uses the icon-hiding API and is a statistical outlier in API uniqueness and complexity is flagged for manual review.'
    answer_sources:
      - 'Static analysis reports from application vetting sandbox'
      - 'Mobile application reputation service logs'
      - 'APK files'
      - 'Organizational application stores (e.g., managed Google Play), Application vetting sandboxes, Developer CI/CD pipelines, Threat intelligence platforms'
    range: 'last 90 days'
    queries:
      - 'Pseudocode: |
          FOR each new_apk:
            EXTRACT api_set_A from new_apk
            FETCH baseline_api_set_B
            CALCULATE jaccard_distance = 1 - (size(intersect(A, B)) / size(union(A, B)))
            CALCULATE shannon_entropy of classes.dex
            
            IF new_apk contains icon_hiding_api
               AND jaccard_distance > percentile(95)
               AND entropy > percentile(95):
              FLAG for manual review'
  - question: 'How can I use a gradient boosting model to automate the classification of APKs as benign or malicious based on a broad set of static features?'
    context: 'This question describes an advanced machine learning approach for an application vetting pipeline. By training a powerful classifier like XGBoost or LightGBM on a rich feature set—including suspicious API calls, dangerous permissions, obfuscation signatures, and the reputation of embedded URLs—a robust scoring system can be developed. This model can fully automate the rejection of high-risk APKs (e.g., malice score $$ > 0.9 $$) and quarantine medium-risk ones (e.g., score $$ 0.7 - 0.9 $$) for analyst review, significantly improving the efficiency and accuracy of the vetting process.'
    answer_sources:
      - 'Static analysis reports from application vetting sandbox'
      - 'Mobile application reputation service logs'
      - 'APK files'
      - 'Organizational application stores (e.g., managed Google Play), Application vetting sandboxes, Developer CI/CD pipelines, Threat intelligence platforms'
    range: 'last 90 days'
    queries:
      - 'Pseudocode: |
          // Feature Engineering
          FOR each apk:
            EXTRACT features (api_calls, permissions, packer_signatures, url_reputation)
          
          // Model Prediction
          LOAD gradient_boosting_model
          PREDICT score = model.predict(features)
          
          // Triage
          IF score > 0.9 THEN
            REJECT apk
          ELSE IF score > 0.7 THEN
            QUARANTINE for manual review
          END'