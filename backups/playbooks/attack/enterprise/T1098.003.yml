name: T1098.003: Additional Cloud Roles
id: d76f8a2b-788b-4c4d-8b04-58e110c7a52f
description: This playbook helps investigate whether an adversary is adding or modifying cloud roles for persistence or privilege escalation. It focuses on detecting IAM policy modifications from anomalous sources, the attachment of self-modifying policies, assignment of high-privilege roles to unusual accounts (new, dormant, or external), and bursts of IAM-related API activity. It also looks for signs of privilege escalation, such as the use of malicious names for roles/policies, the creation of known privilege escalation paths, granting of IAM write permissions to non-admins, and the immediate use of newly granted permissions that were previously denied.
type: technique
related:
  - TA0003: Persistence
  - TA0004: Privilege Escalation
contributors:
  - Zachary Szewczyk
  - Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Are IAM modification events originating from source IPs or user agents found on threat intelligence feeds?
    context: This question aims to identify IAM changes made from infrastructure known to be malicious. An adversary might use compromised servers or specific tools with unique User-Agent strings to interact with the cloud environment. Matching the source IP or user agent of a sensitive action like an IAM modification against a threat intelligence feed provides a high-confidence indicator of compromise.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Zeek conn.log
      - Cloud provider IAM API endpoints
      - Network egress points and VPN gateways
      - Threat intelligence platform feeds.
    range: last 90 days
    queries:
      - technology: SIEM
        query: SEARCH cloud_audit_logs WHERE event_type='IAM_modification' AND (source_ip IN threat_intel_feed OR user_agent IN threat_intel_feed)
  - question: Is an administrative user modifying IAM policies from an unusual source ASN or with an uncommon User-Agent?
    context: This question seeks to detect deviations from established user behavior. Administrators typically perform their duties from predictable networks (corporate office, VPN) and using standard tools. An IAM modification originating from a rare ASN or using a rare User-Agent for that specific user is anomalous and could indicate an account compromise or an insider threat using non-standard tools.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Zeek conn.log
      - Cloud provider IAM API endpoints
      - Network egress points and VPN gateways
      - Threat intelligence platform feeds.
    range: last 90 days
    queries:
      - technology: SIEM/Data Analytics
        query: FOR each admin_user, BASELINE source_asn_frequency, user_agent_frequency over 90 days. ALERT ON new IAM_modification WHERE source_asn OR user_agent is in bottom 5% frequency for that user.
  - question: Does a machine learning model classify a new IAM modification event as malicious based on its contextual features?
    context: This question leverages a machine learning model to perform multi-dimensional anomaly detection. While a single feature like IP or User-Agent might be suspicious, a model can evaluate the combination of many features (source location, time of day, user identity, etc.) to identify complex patterns that suggest malicious activity. This approach can detect novel threats that don't match simple rules or statistical thresholds.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Zeek conn.log
      - Cloud provider IAM API endpoints
      - Network egress points and VPN gateways
      - Threat intelligence platform feeds.
    range: last 90 days
    queries:
      - technology: Machine Learning Model
        query: SCORE new IAM_modification_event with trained_classifier. ALERT IF classification is 'malicious' AND probability > 0.85.
  - question: Has a policy been attached to a user, group, or role that would allow it to modify its own permissions?
    context: This question is designed to detect a common persistence technique where an adversary grants a compromised identity the ability to alter its own permissions. This allows the adversary to re-grant themselves privileges if a defender revokes them, creating a difficult-to-eradicate foothold. Detecting the grant of permissions like 'iam:CreatePolicyVersion' or 'iam:SetDefaultPolicyVersion' is a critical control.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - Cloud Security Posture Management (CSPM) tool data repository.
    range: last 90 days
    queries:
      - technology: SIEM
        query: SEARCH cloud_audit_logs WHERE event_name IN ['Attach*Policy', 'Put*Policy'] AND request_parameters contains any permission from self_modification_watchlist.
  - question: Has a policy with an unusually high number of powerful and varied permissions been attached to a principal?
    context: This question aims to identify the attachment of overly permissive policies. Instead of looking for specific dangerous permissions, this statistical approach measures the overall 'power' or 'entropy' of a policy. A policy with an anomalously high score, even if it doesn't contain a specific known-bad permission, is suspicious and may indicate an adversary is attempting to grant broad access under the guise of a single policy attachment.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - Cloud Security Posture Management (CSPM) tool data repository.
    range: last 90 days
    queries:
      - technology: Data Analytics
        query: BASELINE permission_entropy_scores for all policies. ALERT ON new policy_attachment WHERE attached_policy_entropy > 98th_percentile of baseline.
  - question: Did a recent policy attachment create a privilege escalation path allowing a principal to modify its own permissions?
    context: This question uses graph theory to identify complex and often indirect self-modification paths. An adversary might grant permissions to a role that a user can assume, which in turn can modify a group the user belongs to. A simple rule might miss this, but a graph-based analysis can traverse these relationships to detect when a new policy attachment completes a circular, self-escalation path.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - Cloud Security Posture Management (CSPM) tool data repository.
    range: last 90 days
    queries:
      - technology: Graph Analysis
        query: MODEL IAM as graph. ON policy_attachment_event, RUN graph_traversal from affected_principal. ALERT IF new path allows principal to modify self.
  - question: Has a high-privilege role been assigned to a very new account or an unapproved external account?
    context: This question looks for the suspicious assignment of powerful roles to untrusted or untested principals. Adversaries often create new accounts for their activities to avoid detection. Granting a powerful role to an account created within the last few days, or to an external account from a domain that is not an approved partner, is a significant red flag for persistence or privilege escalation.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Windows Event ID 4624
      - Cloud provider IAM service endpoints
      - Identity Provider (IdP) authentication logs
      - Domain Controller security logs.
    range: last 90 days
    queries:
      - technology: SIEM
        query: SEARCH role_assignment_events WHERE role IN high_privilege_list AND (target_account_creation_date < 72h OR target_account_domain NOT IN federated_allowlist).
  - question: Has a high-privilege role been assigned to a dormant account?
    context: This question aims to detect the misuse of abandoned or inactive accounts. Adversaries may compromise old accounts that are not actively monitored. The assignment of new, powerful permissions to an account that has been inactive for an extended period (e.g., 90+ days) is highly anomalous and a common tactic for establishing persistence.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Windows Event ID 4624
      - Cloud provider IAM service endpoints
      - Identity Provider (IdP) authentication logs
      - Domain Controller security logs.
    range: last 90 days
    queries:
      - technology: SIEM/Data Analytics
        query: IDENTIFY accounts with no login > 90 days as 'dormant'. ALERT ON role_assignment_event WHERE target_account is in 'dormant' list.
  - question: Has a high-privilege role been assigned to an account that is anomalously inactive compared to its own historical patterns?
    context: This question refines the concept of a 'dormant' account using a more sophisticated, user-specific model. Instead of a fixed 90-day threshold for all users, a time-series model learns the typical activity rhythm for each user. An alert is triggered if a powerful role is assigned to a user who is currently in a period of inactivity that is statistically unusual *for them*, providing a more tailored and potentially more accurate signal.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Windows Event ID 4624
      - Cloud provider IAM service endpoints
      - Identity Provider (IdP) authentication logs
      - Domain Controller security logs.
    range: last 90 days
    queries:
      - technology: Machine Learning/Time-Series
        query: FORECAST expected activity for each user with ARIMA model. ALERT ON high_privilege_role_assignment IF target_user's recent_activity is a significant negative outlier to forecast.
  - question: Has any user made an excessive number of IAM modification API calls in a short period?
    context: This question is designed to detect brute-force or scripted IAM changes. While a legitimate administrator might make a few changes at once, a large number of modifications (e.g., >10 in an hour) by a single user is atypical and could represent an automated script run by an adversary to create, modify, or attach multiple roles and policies quickly.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Zeek conn.log
      - Windows Event ID 4624
      - Cloud provider IAM service endpoints
      - Administrator workstations
      - VPN and remote access gateways.
    range: last 90 days
    queries:
      - technology: SIEM
        query: COUNT IAM_modification_events by user over 60-min window. ALERT IF count > 10.
  - question: Is an administrator performing an anomalously high number of IAM modifications compared to their own typical behavior for this time of day?
    context: This question provides a more intelligent form of burst detection by comparing a user's activity against their own baseline. A senior admin making 15 changes might be normal, while 5 changes from a junior admin might be unusual. This method alerts on activity that is statistically significant *for that specific user and time*, reducing false positives from a simple global threshold and catching more subtle anomalies.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Zeek conn.log
      - Windows Event ID 4624
      - Cloud provider IAM service endpoints
      - Administrator workstations
      - VPN and remote access gateways.
    range: last 90 days
    queries:
      - technology: SIEM/Data Analytics
        query: FOR each admin, BASELINE hourly IAM_modification_count (mean, stddev) over 90 days. ALERT IF current_hour_count > (mean + 3*stddev) for that user and hour.
  - question: Is a recent burst of IAM modification activity by a user considered an anomaly by a time-series decomposition model?
    context: This question uses an advanced machine learning technique to identify anomalous bursts of activity. A decomposition model can separate a user's normal activity into a long-term trend (e.g., becoming more active over time) and seasonal patterns (e.g., always busier on Tuesdays). The model alerts only on activity that remains as an unexplainable 'residual' or anomaly after accounting for these normal patterns, providing a very high-fidelity signal.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Zeek conn.log
      - Windows Event ID 4624
      - Cloud provider IAM service endpoints
      - Administrator workstations
      - VPN and remote access gateways.
    range: last 90 days
    queries:
      - technology: Machine Learning/Time-Series
        query: FOR each user, MODEL activity with STL, separating trend, seasonality, and residual. ALERT IF a burst of IAM_modification_activity corresponds to a high residual value.
  - question: Has a new IAM role or policy been created with a name that matches a known malicious tool or term?
    context: This question seeks to identify adversary activity by looking for tell-tale names in created resources. Adversaries sometimes use default or recognizable names for their tools or backdoors (e.g., 'mimikittenz', 'backdoor_policy'). Matching newly created role or policy names against a watchlist of these terms is a simple but effective way to detect known threats.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - Threat intelligence platform feeds.
    range: last 90 days
    queries:
      - technology: SIEM
        query: SEARCH IAM_creation_events WHERE rolename IN known_bad_names_list OR policyname IN known_bad_names_list.
  - question: Has a new IAM role or policy been created with a name that is a close misspelling or variation of a known malicious term?
    context: This question enhances simple name-matching by looking for slight variations. Adversaries may try to evade detection by slightly altering known malicious names (e.g., 'mimikattenz' instead of 'mimikittenz'). Using a string-distance algorithm like Levenshtein allows for 'fuzzy' matching, catching these evasive attempts that an exact-match rule would miss.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - Threat intelligence platform feeds.
    range: last 90 days
    queries:
      - technology: Data Analytics/Scripting
        query: FOR each new role/policy name, CALCULATE Levenshtein_distance to all names in known_bad_list. ALERT IF normalized_distance < 0.2.
  - question: Does a natural language processing model classify a new role or policy name as suspicious or malicious?
    context: This question leverages a text classification model to understand the *intent* behind a name, rather than just matching it to a list. By training on thousands of examples, the model can learn the characteristics of both benign (e.g., 'S3-ReadOnly-Access-for-App-XYZ') and malicious names. This allows it to flag novel or cleverly disguised suspicious names that don't appear on any predefined list.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - Threat intelligence platform feeds.
    range: last 90 days
    queries:
      - technology: Machine Learning/NLP
        query: SCORE new role/policy name with trained_NLP_classifier. ALERT IF classification is 'suspicious' or 'malicious'.
  - question: Did a recent policy modification grant a principal the final permission needed to complete a known privilege escalation path?
    context: This question aims to detect the creation of specific, well-documented privilege escalation vulnerabilities. For example, in AWS, having both 'iam:PassRole' and 'ec2:RunInstances' allows a user to launch an EC2 instance with a high-privilege role. This query looks for the exact moment when a policy change gives a single user all the necessary components of such a known dangerous combination.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - Cloud Security Posture Management (CSPM) tools.
    range: last 90 days
    queries:
      - technology: SIEM
        query: ON policy_modification, CHECK if target_principal now has all permissions for any known_privesc_path. ALERT if true.
  - question: Did a recent policy modification cause a principal's cumulative permission risk score to become anomalously high?
    context: This question provides a quantitative measure of risk from permission changes. By assigning a score to each permission, we can calculate an overall risk score for any user or role. A sudden, large jump in this score, pushing the principal into the top percentile of riskiness, is a strong indicator of a privilege escalation event, even if it doesn't match a specific, pre-defined path.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - Cloud Security Posture Management (CSPM) tools.
    range: last 90 days
    queries:
      - technology: Data Analytics
        query: ON policy_modification, RECALCULATE target_principal's cumulative_risk_score. ALERT IF new_score is in 99th percentile of all principal scores.
  - question: Did a recent policy change create a pattern of permissions and relationships that a Graph Neural Network identifies as a high-risk escalation path?
    context: This question applies advanced machine learning to graph-based IAM analysis. A Graph Neural Network (GNN) can be trained to recognize the 'shape' or structure of privilege escalation paths within the IAM graph. This allows it to identify not only pre-documented paths but also new, unseen variations that share similar structural properties, providing a powerful and proactive detection capability.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - Cloud Security Posture Management (CSPM) tools.
    range: last 90 days
    queries:
      - technology: Machine Learning/Graph Analysis
        query: ON policy_modification, UPDATE IAM graph model. ANALYZE affected subgraph with GNN. ALERT IF model classifies new structure as high-risk escalation path.
  - question: Has a non-administrative user or group been granted permissions to modify IAM configurations?
    context: This question enforces the principle of least privilege by flagging when administrative-level permissions are granted to users who should not have them. Granting permissions like 'iam:PutUserPolicy' or 'Microsoft.Authorization/*/write' to a standard user or a 'developers' group is a major security risk and a clear sign of either misconfiguration or a malicious privilege escalation attempt.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - User and group definitions in Identity Provider (IdP).
    range: last 90 days
    queries:
      - technology: SIEM
        query: SEARCH policy_modification_events WHERE target_principal IN non_admin_list AND granted_permission IN iam_write_permissions_list.
  - question: Has a user been granted a new permission that makes their total permission set significantly different from the baseline for their job role?
    context: This question detects privilege escalation by identifying when a user's permissions deviate from their peer group. By establishing a 'template' of normal permissions for a role like 'Data Analyst', we can flag when a user in that role is granted a permission that is highly unusual for their function. A low Jaccard similarity score indicates this deviation and points to a potential targeted attack or insider threat.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - User and group definitions in Identity Provider (IdP).
    range: last 90 days
    queries:
      - technology: Data Analytics
        query: FOR each job_role, BASELINE common permission set. ON permission_grant, CALCULATE Jaccard_similarity of user's new permissions vs. role_baseline. ALERT IF similarity < 0.5.
  - question: Did a recent permission grant cause a user's permission profile to be re-classified as an outlier or to join a small, high-privilege group?
    context: This question uses unsupervised machine learning to automatically discover peer groups based on permissions, without needing pre-defined roles. A clustering algorithm like DBSCAN can identify large clusters of users with similar access (e.g., 'developers', 'read-only users'). An alert is triggered when a permission change moves a user out of their large, stable cluster and either makes them an outlier or moves them into a small, exclusive cluster (e.g., 'domain admins'), indicating a significant and suspicious change in their access level.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - Google Cloud Audit Log
      - Cloud provider IAM service endpoints
      - User and group definitions in Identity Provider (IdP).
    range: last 90 days
    queries:
      - technology: Machine Learning/Clustering
        query: CLUSTER users by permission vectors using DBSCAN. ON permission_grant, RE-EVALUATE user's cluster. ALERT IF user becomes outlier or moves to a smaller, higher-privilege cluster.
  - question: Did an account, shortly after receiving new permissions, successfully use those permissions to perform an action that was previously denied?
    context: This question looks for a clear, causal link between a privilege grant and its immediate, potentially malicious use. This 'before-and-after' scenario is a strong indicator of an adversary who has identified a privilege they need, found a way to grant it, and immediately used it to achieve their objective (e.g., access sensitive data). Correlating the permission grant with the subsequent successful-after-failure API call provides high-confidence evidence of a targeted attack.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - AWS S3 access logs
      - Google Cloud Storage logs
      - Cloud provider IAM service endpoints
      - Cloud storage services (S3, GCS)
      - Cloud compute and container services.
    range: last 90 days
    queries:
      - technology: SIEM (Correlated Rule)
        query: STAGE 1, On IAM_modification, watch principal for 15 min. STAGE 2, ALERT if principal successfully calls API_call that failed with AccessDenied for same principal in last 24h.
  - question: Following a policy modification, did a principal's rate of 'AccessDenied' errors drop significantly while their rate of successful sensitive API calls spiked?
    context: This question provides a statistical alternative to the symbolic correlated rule. It looks for a change in the *rate* of access denials and successes following a permission change. A user who was 'probing' for access would generate many 'AccessDenied' errors. A sudden drop in that error rate, coupled with a spike in successful calls to high-impact APIs after a permission change, statistically demonstrates that the user gained a new, powerful capability and immediately began using it.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - AWS S3 access logs
      - Google Cloud Storage logs
      - Cloud provider IAM service endpoints
      - Cloud storage services (S3, GCS)
      - Cloud compute and container services.
    range: last 90 days
    queries:
      - technology: SIEM/Data Analytics
        query: MONITOR rate of AccessDenied errors per principal. ALERT if IAM_modification is followed by >3-sigma drop in error rate and spike in successful sensitive API calls.
  - question: After a policy modification, did the user execute a sequence of API calls that is considered anomalous by a sequence-learning model?
    context: This question uses a sophisticated ML model to detect anomalous *behaviors* rather than just single events. A sequence model learns the normal 'grammar' of API calls for a user. An adversary, having just gained new privileges, is likely to perform a sequence of actions (e.g., list keys, create key, use key) that is different from the user's normal workflow. The model would flag this new sequence as having a high reconstruction error, indicating it's uncharacteristic and therefore suspicious.
    answer_sources:
      - AWS CloudTrail
      - Azure Activity Log
      - AWS S3 access logs
      - Google Cloud Storage logs
      - Cloud provider IAM service endpoints
      - Cloud storage services (S3, GCS)
      - Cloud compute and container services.
    range: last 90 days
    queries:
      - technology: Machine Learning/Sequence Modeling
        query: TRAIN LSTM autoencoder on user API call sequences. ON policy_modification, FEED subsequent API call sequence to model. ALERT if reconstruction_error is high.