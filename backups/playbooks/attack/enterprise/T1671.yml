name: T1671: Cloud Application Integration
id: 59c8a98d-e4d6-4a5f-9f7b-8c1d2e0a3b4c
description: This playbook focuses on detecting adversaries who are maintaining persistence by leveraging cloud application integrations. This involves monitoring for several key indicators, including the registration or consent of applications that match known malicious indicators, the appearance of applications with names indicative of impersonation, the granting of high-risk permissions, anomalous consent events (e.g., from unusual locations), and deviations in a service principal's data access patterns from its established baseline. It also covers the correlation of on-premises CLI tool usage for service principal creation with subsequent cloud activity.
type: technique
related:
  - TA0003: Persistence
contributors:
  - Zachary Szewczyk
  - Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Are there any cloud application registration or consent events where the application's properties match known-bad indicators from threat intelligence?
    context: This question aims to detect the use of pre-identified malicious applications. Adversaries may reuse infrastructure or application identifiers across campaigns. By comparing new application registrations and consents against a curated list of malicious indicators (Application IDs, publisher names, redirect URIs), analysts can quickly identify known threats.
    answer_sources:
      - Microsoft 365 Unified Audit Logs
      - Azure Active Directory Audit Logs
      - Threat Intelligence Platform Data
      - Microsoft Entra ID tenant
      - Threat intelligence platforms
    range: last 90 days
    queries:
      - pseudocode: SEARCH audit_logs (AzureAD, M365) WHERE event IN ('Add application', 'Consent to application') | LOOKUP application_details against threat_intel_feeds ON (app_id, publisher_name, redirect_uri) | RETURN events with a match
  - question: Has a user consented to an application from a publisher domain that is statistically rare or new to the enterprise?
    context: This question helps identify potential phishing or trojan applications from unknown publishers. Legitimate applications are typically from well-known publishers that are frequently used. An application from a publisher that has never or rarely been seen before is suspicious and could indicate an adversary's custom-built or newly registered application.
    answer_sources:
      - Microsoft 365 Unified Audit Logs
      - Azure Active Directory Audit Logs
      - Threat Intelligence Platform Data
      - Microsoft Entra ID tenant
      - Threat intelligence platforms
    range: last 90 days
    queries:
      - pseudocode: SEARCH audit_logs WHERE event = 'Consent to application' | CALCULATE frequency of publisher_domain over last 180 days | RETURN consents WHERE publisher_domain_frequency < 5th_percentile
  - question: Can machine learning models identify application consent events that are likely to be malicious based on their collective properties?
    context: This question leverages machine learning to find subtle or complex patterns of maliciousness that simple rules might miss. By training a model on features like publisher name characteristics, redirect URI domain age, and the specific permissions requested, it can score the risk of new consent events and flag those that exhibit a combination of suspicious traits.
    answer_sources:
      - Microsoft 365 Unified Audit Logs
      - Azure Active Directory Audit Logs
      - Threat Intelligence Platform Data
      - Microsoft Entra ID tenant
      - Threat intelligence platforms
    range: last 90 days
    queries:
      - pseudocode: PIPELINE new_consent_event -> FEATURE_EXTRACTION (publisher, domain_age, permissions) -> ML_MODEL (Random Forest) -> SCORE probability_malicious | ALERT if score > 0.85
  - question: Have any new applications been registered or consented to that have names designed to impersonate legitimate software (e.g., typosquatting)?
    context: This question targets a common adversary tactic of creating malicious applications with names that closely resemble legitimate, trusted applications. By using regular expressions to search for common impersonation techniques like typosquatting or homoglyphs, analysts can detect these deceptive applications.
    answer_sources:
      - Microsoft 365 Unified Audit Logs
      - Azure Active Directory Audit Logs
      - Public WHOIS Data
      - Zeek dns.log
      - Microsoft Entra ID tenant
      - Public DNS and WHOIS services
      - Network egress points
    range: last 90 days
    queries:
      - pseudocode: SEARCH audit_logs WHERE event IN ('Add application', 'Consent to application') | APPLY regex for typosquatting/homoglyphs to application_name | RETURN events with a match
  - question: Are there new applications from unverified publishers with recently registered domains or names very similar to existing trusted applications?
    context: This question combines two indicators of suspicion. An application from an unverified publisher with a brand-new domain is a red flag, as it suggests the infrastructure was recently created, possibly for a malicious campaign. Similarly, an application name that is only slightly different (low Levenshtein distance) from a known, trusted app suggests an impersonation attempt.
    answer_sources:
      - Microsoft 365 Unified Audit Logs
      - Azure Active Directory Audit Logs
      - Public WHOIS Data
      - Zeek dns.log
      - Microsoft Entra ID tenant
      - Public DNS and WHOIS services
      - Network egress points
    range: last 90 days
    queries:
      - pseudocode: SEARCH new_app_events | GET whois_data for publisher_domain | ALERT if domain_creation_date < 90 days | AND/OR | CALCULATE levenshtein_distance(new_app_name, known_good_app_names) | ALERT if distance <= 2
  - question: Can unsupervised machine learning detect clusters of anomalous application names that might represent sophisticated impersonation attempts?
    context: This question addresses advanced impersonation techniques that might evade simple pattern matching. By clustering applications based on features of their names (like character patterns), an unsupervised model like DBSCAN can group similar names together. Small, isolated clusters or outliers (noise) from this process often represent anomalous and potentially malicious application names that warrant investigation.
    answer_sources:
      - Microsoft 365 Unified Audit Logs
      - Azure Active Directory Audit Logs
      - Public WHOIS Data
      - Zeek dns.log
      - Microsoft Entra ID tenant
      - Public DNS and WHOIS services
      - Network egress points
    range: last 90 days
    queries:
      - pseudocode: EXTRACT features from all application_names (n-grams, char_freq) -> APPLY DBSCAN clustering -> INVESTIGATE outlier points and small clusters
  - question: Has any application been granted a known high-risk permission?
    context: This question focuses on the impact of a potential compromise. Certain permissions (e.g., 'Mail.ReadWrite.All', 'Directory.ReadWrite.All') are extremely powerful and dangerous in the hands of an adversary. This query uses a predefined list of these high-risk permissions to immediately flag any consent event that grants them.
    answer_sources:
      - Microsoft 365 Unified Audit Logs
      - Azure Active Directory Audit Logs
      - Zeek conn.log
      - Windows Security Event ID 4624
      - Microsoft Entra ID tenant
      - Network gateways and proxies
      - VPN concentrators
    range: last 90 days
    queries:
      - pseudocode: DEFINE high_risk_permissions_list | SEARCH audit_logs WHERE event = 'Consent to application' | ALERT if granted_permission IN high_risk_permissions_list
  - question: Has an application consent occurred from a geographically unusual location for that user, or does the application request an abnormally broad set of permissions?
    context: This question looks for two types of statistical anomalies. A user consenting to an application from a location they've never or rarely worked from is suspicious and could indicate a compromised account. Separately, an application requesting a wide and diverse set of permissions (high Shannon entropy) can be a sign of a malicious, overly permissive application.
    answer_sources:
      - Microsoft 365 Unified Audit Logs
      - Azure Active Directory Audit Logs
      - Zeek conn.log
      - Windows Security Event ID 4624
      - Microsoft Entra ID tenant
      - Network gateways and proxies
      - VPN concentrators
    range: last 90 days
    queries:
      - pseudocode: FOR each consent_event | GET user_location_history | ALERT if consent_location is outlier | AND/OR | CALCULATE shannon_entropy of requested_permissions | ALERT if entropy is high
  - question: Can an anomaly detection model identify suspicious application consent events based on a combination of factors like user role, permission risk, time, and IP reputation?
    context: This question uses a holistic, machine-learning-based approach to risk assessment. A single suspicious factor might not be enough to trigger an alert, but a combination of them (e.g., a non-admin user consenting to a medium-risk app at 3 AM from a low-reputation IP) is highly indicative of malicious activity. An Isolation Forest model can detect these unusual combinations.
    answer_sources:
      - Microsoft 365 Unified Audit Logs
      - Azure Active Directory Audit Logs
      - Zeek conn.log
      - Windows Security Event ID 4624
      - Microsoft Entra ID tenant
      - Network gateways and proxies
      - VPN concentrators
    range: last 90 days
    queries:
      - pseudocode: PIPELINE new_consent_event -> FEATURE_EXTRACTION (user_role, permission_risk, time_of_day, ip_rep) -> ML_MODEL (Isolation Forest) -> SCORE anomaly_score | ALERT if score is high
  - question: Is a service principal signing in or accessing data from a known malicious IP address?
    context: This is a straightforward threat intelligence correlation. Service principals are non-human identities and should generally operate from predictable, corporate-owned IP ranges. Any activity from an IP address on a threat intelligence list (e.g., known C2 server, TOR exit node) is a high-confidence indicator of compromise.
    answer_sources:
      - Microsoft 365 Unified Audit Logs (e.g., SharePointFileOperation, ExchangeItem)
      - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
      - Azure Active Directory Audit Logs
      - Microsoft 365 services (Exchange Online, SharePoint Online, OneDrive)
      - Microsoft Entra ID tenant
    range: last 90 days
    queries:
      - pseudocode: SEARCH service_principal_activity_logs | LOOKUP source_ip against threat_intel_feeds | RETURN events with a match
  - question: Is a service principal accessing an unusually high volume of data or an anomalous number of unique resources compared to its historical behavior?
    context: This question aims to detect data exfiltration or reconnaissance by a compromised service principal. By establishing a baseline of normal activity (e.g., average number of files accessed per hour), we can use standard deviation to detect significant spikes in activity. Similarly, a service principal suddenly accessing a much larger number of mailboxes than usual is a strong indicator of abuse.
    answer_sources:
      - Microsoft 365 Unified Audit Logs (e.g., SharePointFileOperation, ExchangeItem)
      - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
      - Azure Active Directory Audit Logs
      - Microsoft 365 services (Exchange Online, SharePoint Online, OneDrive)
      - Microsoft Entra ID tenant
    range: last 90 days
    queries:
      - pseudocode: FOR each service_principal | CALCULATE baseline (mean, std_dev) of hourly_data_access over 30 days | ALERT if current_hour_access > mean + 3*std_dev
  - question: Can a time-series model detect anomalous sequences of resource access events for a service principal?
    context: This question targets sophisticated attack patterns that unfold over time. An adversary might perform a series of actions that are individually benign but malicious in sequence (e.g., enumerate files, then rapidly download them). A time-series model like an LSTM autoencoder can learn the normal "rhythm" of a service principal's activity and flag sequences that deviate from this learned pattern.
    answer_sources:
      - Microsoft 365 Unified Audit Logs (e.g., SharePointFileOperation, ExchangeItem)
      - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
      - Azure Active Directory Audit Logs
      - Microsoft 365 services (Exchange Online, SharePoint Online, OneDrive)
      - Microsoft Entra ID tenant
    range: last 90 days
    queries:
      - pseudocode: FOR each service_principal | TRAIN LSTM_autoencoder on normal event sequences | APPLY model to new event sequences | ALERT if reconstruction_error is high
  - question: Was a service principal created on an endpoint using a CLI tool and then immediately used?
    context: This question correlates host-level activity with cloud activity to detect "just-in-time" credential creation. An attacker gaining access to an endpoint might use CLI tools to create a new service principal for persistence. A tight temporal correlation between the creation command on the host and the creation/first use event in the cloud is a strong indicator of this hands-on-keyboard activity.
    answer_sources:
      - Windows Security Event ID 4688
      - Azure Active Directory Audit Logs
      - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
      - Enterprise workstations and servers
      - Microsoft Entra ID tenant
    range: last 90 days
    queries:
      - pseudocode: CORRELATE process_creation (e.g., 'az ad sp create') on endpoint with cloud_log ('Add service principal') for same principal name | ALERT if time_delta < 5 minutes
  - question: Has there been a statistically significant spike in the number of service principals created in the environment?
    context: This question aims to detect automated or scripted creation of service principals at scale. By baselining the normal daily rate of service principal creation, a sudden spike exceeding a high percentile (e.g., the 99th) can indicate that an adversary is programmatically creating multiple backdoors. This can then be correlated with host data to find the source.
    answer_sources:
      - Windows Security Event ID 4688
      - Azure Active Directory Audit Logs
      - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
      - Enterprise workstations and servers
      - Microsoft Entra ID tenant
    range: last 90 days
    queries:
      - pseudocode: CALCULATE 99th_percentile of daily_service_principal_creations over 90 days | ALERT if current_day_count > 99th_percentile
  - question: Can a machine learning model identify high-risk initial activity patterns for newly created service principals?
    context: This question focuses on classifying the behavior of a service principal immediately after its creation. A model can be trained to recognize high-risk patterns, such as a principal that is created and almost instantly signs in from a rare geographic location to perform high-privilege operations. This allows for proactive risk scoring of new principals based on their initial "first impression."
    answer_sources:
      - Windows Security Event ID 4688
      - Azure Active Directory Audit Logs
      - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
      - Enterprise workstations and servers
      - Microsoft Entra ID tenant
    range: last 90 days
    queries:
      - pseudocode: FOR each new_service_principal | EXTRACT features (time_to_first_signin, signin_location, permissions) -> APPLY ML_Classifier -> SCORE risk of initial activity pattern | ALERT if risk_score is high