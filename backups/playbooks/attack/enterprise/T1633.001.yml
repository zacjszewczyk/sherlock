name: T1633.001: System Checks
id: 5a6b1c8d-9e0f-4a3b-8c7d-6e5f4a3b2c1d
description: This playbook focuses on detecting adversarial attempts to evade mobile analysis or sandbox environments by performing system checks. Adversaries use these checks to determine if the application is running on a real device versus a virtualized or analysis environment. Indicators of this activity include querying for known emulator artifacts (e.g., specific system properties or file paths), checking for the presence of hardware sensors (like accelerometers or gyroscopes) without subsequent use, and altering network behavior (e.g., switching to encrypted DNS) after querying network interface details. Detecting these behaviors can reveal malware attempting to hide its true functionality from security researchers and automated scanning tools.
type: technique
related:
- TA0030: Defense Evasion
contributors:
- Zachary Szewczyk
- Ask Sage
created: '2025-10-01'
modified: '2025-10-01'
version: 1.0
tags: none
questions:
- question: How can we detect if an application is checking for known emulator or sandbox artifacts via API calls or file reads?
  context: This question aims to identify malware attempting to evade analysis by looking for specific strings (e.g., 'goldfish', 'ranchu', 'qemu') or file paths (e.g., '/system/bin/qemu-props') that are characteristic of virtual or emulated environments. Detecting these checks early in an application's lifecycle is a strong indicator of malicious intent, as the application is trying to determine if it is being watched.
  answer_sources:
  - Mobile EDR API Monitoring Logs
  - Mobile EDR File Integrity Monitoring Logs
  - Mobile Application Vetting (MAV) Sandbox Reports
  - Android Logcat
  - Application sandboxing environment
  - Corporate-managed mobile devices (Android & iOS)
  - Mobile Device Management (MDM) platform
  - Mobile Application Vetting (MAV) platform
  range: last 90 days
  queries:
  - search_technology: Pseudocode
    query: |-
      ALERT on process event WHERE
        ( (api_call == "android.os.SystemProperties.get" OR process_name == "getprop")
          AND api_argument CONTAINS ("goldfish", "ranchu", "qemu", "vbox", "generic_x86", "sdk_google", "ttVM", "Genymotion") )
      OR
        ( (event_type == "file_read")
          AND (file_path == "/system/bin/qemu-props" OR (file_path == "/proc/cpuinfo" AND file_content CONTAINS "QEMU Virtual CPU")) )
- question: Can we identify anomalous applications by baselining the number of system properties they query upon startup?
  context: This question focuses on using statistical analysis to find outliers. Legitimate applications typically have a predictable range of system property queries needed for normal operation. Malware performing extensive reconnaissance to identify its environment will likely query an unusually high number of properties. By comparing an app's query count to a pre-established baseline for its category, we can spot outliers that warrant further investigation for evasive behavior.
  answer_sources:
  - Mobile EDR API Monitoring Logs
  - Mobile EDR File Integrity Monitoring Logs
  - Mobile Application Vetting (MAV) Sandbox Reports
  - Android Logcat
  - Application sandboxing environment
  - Corporate-managed mobile devices (Android & iOS)
  - Mobile Device Management (MDM) platform
  - Mobile Application Vetting (MAV) platform
  range: last 90 days
  queries:
  - search_technology: Pseudocode
    query: |-
      FOR each new application:
        query_count = COUNT (DISTINCT system_property) within 300s of process_start
        baseline = GET_BASELINE_DISTRIBUTION(app_category, last 30 days)
        threshold = PERCENTILE(baseline, 98)
        IF query_count > threshold THEN
          ALERT "Anomalous system property query count"
- question: Can a machine learning model be built to predict the probability that an application is performing evasive system checks?
  context: This question proposes using machine learning for more sophisticated detection. By training a model (e.g., XGBoost) on features like specific properties queried, query frequency, timing, and entropy of query prefixes, we can create a probabilistic score. This moves beyond simple rule-based alerts to a more nuanced, data-driven assessment of an application's likelihood of being malicious, enabling analysts to prioritize the most suspicious applications.
  answer_sources:
  - Mobile EDR API Monitoring Logs
  - Mobile EDR File Integrity Monitoring Logs
  - Mobile Application Vetting (MAV) Sandbox Reports
  - Android Logcat
  - Application sandboxing environment
  - Corporate-managed mobile devices (Android & iOS)
  - Mobile Device Management (MDM) platform
  - Mobile Application Vetting (MAV) platform
  range: last 90 days
  queries:
  - search_technology: Pseudocode
    query: |-
      FOR each new application:
        features = EXTRACT_FEATURES(
          - binary flags for known emulator properties
          - count of distinct properties queried
          - entropy of property prefixes
          - time to first query
          - queries per second
        )
        evasion_probability = evasion_model.PREDICT(features)
        IF evasion_probability > 0.85 THEN
          ALERT "High probability of evasive system checks"
- question: How can we detect if an application is checking for hardware sensors without intending to use them?
  context: This question targets malware that checks for the presence of physical sensors (e.g., accelerometer, gyroscope) to verify it's on a real device, as sandboxes often lack these. The key indicator is querying the list of available sensors but never registering to receive data from them within a short time window. This "dangling query" is a strong sign of evasion rather than legitimate functionality.
  answer_sources:
  - Mobile EDR API Monitoring Logs
  - MAV Sandbox API Call Trace Logs
  - Corporate-managed mobile devices
  - Bring-Your-Own-Device (BYOD) fleet with security agents
  - Application sandboxing environment
  - MDM/UEM platform logs
  range: last 90 days
  queries:
  - search_technology: Pseudocode
    query: |-
      DEFINE sensor_query = event WHERE api_call IN ("SensorManager.getSensorList", "CMMotionManager.isAccelerometerAvailable")
      DEFINE sensor_registration = event WHERE api_call IN ("registerListener", "startAccelerometerUpdates")

      TRIGGER on sensor_query(A) for a process_id
      IF no sensor_registration(B) from same process_id within 90s of A.timestamp
        AND process_name NOT IN (allowlist)
      THEN ALERT "Dangling sensor query detected"
- question: Can we statistically measure and baseline the ratio of sensor queries to sensor usage to find outliers?
  context: This approach quantifies the "dangling query" behavior described in the previous question. By calculating a 'Dangling Sensor Query Ratio' (sensor list queries divided by sensor listener registrations), we can establish a normal range for legitimate apps within specific categories. Applications with a ratio that is a statistical anomaly (e.g., 3 standard deviations above the mean) are likely performing sensor checks for evasive purposes.
  answer_sources:
  - Mobile EDR API Monitoring Logs
  - MAV Sandbox API Call Trace Logs
  - Corporate-managed mobile devices
  - Bring-Your-Own-Device (BYOD) fleet with security agents
  - Application sandboxing environment
  - MDM/UEM platform logs
  range: last 90 days
  queries:
  - search_technology: Pseudocode
    query: |-
      FOR each application:
        sensor_queries = COUNT(api_call == "getSensorList") in first 5 mins
        sensor_registrations = COUNT(api_call == "registerListener") in first 5 mins
        ratio = sensor_queries / (sensor_registrations + 1)
        category_mean, category_stddev = GET_BASELINE(app_category)
        IF ratio > (category_mean + 3 * category_stddev) THEN
          ALERT "Anomalous sensor query to usage ratio"
- question: Can we use unsupervised machine learning to cluster applications based on their sensor interaction patterns and identify evasive outliers?
  context: This question proposes using an unsupervised clustering algorithm like DBSCAN to find anomalous groups of applications without pre-existing labels. By representing applications as points in a feature space (e.g., based on counts of sensor types queried, listener registrations, permission requests), evasive apps will likely form small, distinct clusters or be identified as noise, separating them from the large clusters of legitimate applications.
  answer_sources:
  - Mobile EDR API Monitoring Logs
  - MAV Sandbox API Call Trace Logs
  - Corporate-managed mobile devices
  - Bring-Your-Own-Device (BYOD) fleet with security agents
  - Application sandboxing environment
  - MDM/UEM platform logs
  range: last 90 days
  queries:
  - search_technology: Pseudocode
    query: |-
      FOR each application:
        features = EXTRACT_FEATURES(
          - count of distinct sensor types queried
          - count of listener registration calls
          - flag for GPS query without location permission
        )
      clusters = DBSCAN.FIT(all_app_features)
      outliers = GET_POINTS_LABELED_AS_NOISE(clusters)
      IF application IN outliers THEN
        ALERT "Outlier in sensor interaction clustering"
- question: How can we correlate on-device network interface checks with subsequent suspicious network behavior like switching to DoH?
  context: Malware may check the device's network configuration (e.g., MAC address) to ensure it is not in a monitored environment, and then change its communication method to be more covert. This action correlates that initial on-device check with a pivot to encrypted DNS (DoH/DoT) and C2 communication identified by threat intelligence (e.g., JA3 hashes), linking an evasion attempt directly to malicious network activity.
  answer_sources:
  - Mobile EDR API Monitoring Logs
  - Zeek conn.log
  - Zeek dns.log
  - Zeek ssl.log
  - Network egress points for mobile devices (e.g., corporate Wi-Fi, VPN gateway)
  - DNS resolvers
  - Core network switches generating NetFlow/IPFIX
  - Corporate-managed mobile devices
  range: last 90 days
  queries:
  - search_technology: Pseudocode
    query: |-
      TRIGGER on EDR alert for "NetworkInterface.getHardwareAddress()" on device_ip
      WITHIN 5 minutes of trigger:
        SEARCH Zeek logs for device_ip
        dns_disappeared = COUNT(dns.log entries) == 0
        doh_appeared = COUNT(ssl.log entries to non-corp DoH resolver) > 0
        ja3_match = ssl.ja3 IN (malware_ja3_threat_feed)
        IF dns_disappeared AND doh_appeared AND ja3_match THEN
          ALERT "Post-evasion C2 activity detected via DoH"
- question: Can a sudden drop in network traffic entropy indicate that an application has completed its system checks and switched to a C2 channel?
  context: After confirming it is in a "safe" environment, malware often narrows its communication to a single, dedicated C2 channel. This is observable on the network as a sharp decrease in the variety (entropy) of destination IP addresses and DNS queries. Monitoring for a significant, sudden drop in network entropy for a device can be an effective way to detect this post-evasion pivot to covert C2 communications.
  answer_sources:
  - Mobile EDR API Monitoring Logs
  - Zeek conn.log
  - Zeek dns.log
  - Zeek ssl.log
  - Network egress points for mobile devices (e.g., corporate Wi-Fi, VPN gateway)
  - DNS resolvers
  - Core network switches generating NetFlow/IPFIX
  - Corporate-managed mobile devices
  range: last 90 days
  queries:
  - search_technology: Pseudocode
    query: |-
      FOR each device_ip, in 5-minute windows:
        current_ip_entropy = SHANNON_ENTROPY(destination_ips in conn.log)
        rolling_avg_entropy = ROLLING_AVERAGE(ip_entropy, 1 hour)
        IF current_ip_entropy < (0.2 * rolling_avg_entropy) THEN
          ALERT "Significant drop in network entropy detected"
- question: Can a time-series model detect subtle, anomalous shifts in a device's overall network profile that are indicative of post-check malicious activity?
  context: This advanced approach uses a time-series model like an LSTM autoencoder to learn the normal "rhythm" of a device's network traffic (e.g., bytes transferred, connection counts, protocol ratios, JA3 hash entropy). When malware begins its C2 communication, it creates a subtle but complex deviation from this learned baseline. The model will flag this deviation as an anomaly with a high reconstruction error, providing a powerful signal for investigation that may be missed by simpler metrics.
  answer_sources:
  - Mobile EDR API Monitoring Logs
  - Zeek conn.log
  - Zeek dns.log
  - Zeek ssl.log
  - Network egress points for mobile devices (e.g., corporate Wi-Fi, VPN gateway)
  - DNS resolvers
  - Core network switches generating NetFlow/IPFIX
  - Corporate-managed mobile devices
  range: last 90 days
  queries:
  - search_technology: Pseudocode
    query: |-
      FOR each device, per minute:
        timeseries_vector = AGGREGATE_FEATURES(
          - total_bytes
          - unique_dest_ips
          - unique_conn_uids
          - entropy_of_ja3
          - udp_to_tcp_ratio
        )
      reconstruction = lstm_autoencoder.PREDICT(timeseries_vector)
      reconstruction_error = CALCULATE_ERROR(reconstruction, timeseries_vector)
      IF reconstruction_error > threshold THEN
        ALERT "Time-series anomaly in network behavior detected"