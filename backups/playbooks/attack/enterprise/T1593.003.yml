name: T1593.003: Code Repositories
id: f47ac10b-58cc-4372-a567-0e02b2c3d479
description: This playbook focuses on detecting if an adversary is conducting reconnaissance against an organization's public code repositories. It covers identifying leaked credentials via secret scanning services, tracking suspicious clone or fork activity from new or anomalous user accounts, detecting misconfigured repositories that are publicly exposed, monitoring for authentication attempts using credentials found in repositories, identifying password spraying attacks, and detecting probes against internal services whose endpoints were exposed in public code.
type: technique
related:
- TA0043: Reconnaissance
contributors:
- Zachary Szewczyk
- Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
- question: Are secret scanning services detecting high-impact credentials in commits to public repositories?
  context: This question aims to identify the most critical type of secret leak in real-time. An alert for a predefined sensitive secret type (like 'AWS_KEY', 'PRIVATE_KEY', or 'API_TOKEN') in a public repository represents a direct and immediate threat, potentially allowing an adversary to gain unauthorized access to critical systems. Triggering a high-severity incident ensures a rapid response to contain the exposure and revoke the compromised credential.
  answer_sources:
  - GitHub Advanced Security alert logs
  - GitGuardian alert logs
  - Third-party secret scanning service API logs
  - Third-party secret scanning platforms and APIs
  range: last 90 days
  queries:
  - pseudocode: SEARCH secret_scanning_alerts WHERE repository_visibility = 'public' AND secret_type IN ('AWS_KEY', 'PRIVATE_KEY', 'API_TOKEN') | TRIGGER high_severity_incident
- question: Are any specific developers repeatedly leaking credentials, suggesting a need for training or a compromised account?
  context: This question focuses on identifying patterns of behavior rather than single events. A developer who consistently triggers secret leak alerts may be unaware of security best practices or could have their development environment or account compromised. By aggregating alerts over 30 days and flagging outliers (those in the 95th percentile), security teams can proactively intervene with targeted training or investigate the account for signs of compromise.
  answer_sources:
  - GitHub Advanced Security alert logs
  - GitGuardian alert logs
  - Third-party secret scanning service API logs
  - Third-party secret scanning platforms and APIs
  range: last 90 days
  queries:
  - pseudocode: SEARCH secret_scanning_alerts | AGGREGATE count by author over 30_days | WHERE count > 95th_percentile_of_all_authors | TRIGGER medium_severity_alert
- question: Can we use machine learning to automatically prioritize secret scanning alerts and identify high-impact true positives?
  context: This question addresses the challenge of alert fatigue from secret scanning tools, which can have high false positive rates. By training a classification model on historical alert data (using features like repository sensitivity, file type, commit message, and secret entropy), we can predict the likelihood that a new alert represents a genuine, high-impact leak. Automatically escalating alerts with a high prediction score (>0.85) allows analysts to focus their attention on the most critical threats first.
  answer_sources:
  - GitHub Advanced Security alert logs
  - GitGuardian alert logs
  - Third-party secret scanning service API logs
  - Third-party secret scanning platforms and APIs
  range: last 90 days
  queries:
  - pseudocode: RUN classification_model ON new_secret_scanning_alerts | WHERE prediction_score > 0.85 | ESCALATE alert
- question: Are newly created user accounts cloning or forking sensitive repositories shortly after creation?
  context: This question aims to detect suspicious reconnaissance activity. Adversaries may create new accounts on platforms like GitHub and immediately start gathering information. A brand-new account (created within 72 hours) cloning or forking a sensitive or critical repository is highly anomalous behavior and could indicate the initial stages of a targeted attack.
  answer_sources:
  - GitHub audit stream
  - GitLab audit events
  - Cloud-based Git provider audit logs
  range: last 90 days
  queries:
  - pseudocode: SEARCH git_audit_logs WHERE action IN ('git.clone', 'repo.fork') AND repository_tag IN ('sensitive', 'critical') AND user_creation_age < 72_hours | TRIGGER medium_severity_alert
- question: Is there a statistically significant spike in clone activity for critical repositories, especially from new accounts?
  context: This question seeks to identify mass-cloning events that deviate from normal activity patterns. By establishing a baseline (30-day moving average) of clone events for critical repositories, a sudden spike (exceeding 3 standard deviations) can be flagged as an anomaly. The alert is escalated if a high percentage of this activity comes from new accounts, as this combination strongly suggests a coordinated reconnaissance effort.
  answer_sources:
  - GitHub audit stream
  - GitLab audit events
  - Cloud-based Git provider audit logs
  range: last 90 days
  queries:
  - pseudocode: FOR each critical_repository CALC baseline_clone_activity | IF daily_clones > (baseline_mean + 3 * baseline_stddev) THEN ALERT | IF percentage_from_new_accounts > 90th_percentile THEN ESCALATE_ALERT
- question: Can a time-series model detect anomalous patterns in clone and fork activity for critical repositories?
  context: This question leverages a more sophisticated statistical method to detect unusual activity that might be missed by simple thresholding. A time-series model (like SARIMA) can account for seasonality and trends in repository access. An activity count that falls outside the model's 99% confidence interval is a statistically significant anomaly, indicating a deviation from expected behavior that warrants investigation.
  answer_sources:
  - GitHub audit stream
  - GitLab audit events
  - Cloud-based Git provider audit logs
  range: last 90 days
  queries:
  - pseudocode: RUN time_series_anomaly_model ON clone_fork_events for critical_repositories | IF activity_count is outside 99%_confidence_interval THEN TRIGGER alert
- question: Are any repositories intended to be private or internal currently exposed to the public due to misconfiguration?
  context: This question addresses the risk of accidental data exposure through repository misconfigurations. By regularly comparing the actual visibility setting of each repository (via API) with a master list of intended settings, we can immediately detect and alert on any discrepancies. Finding a repository that should be 'private' but is set to 'public' is a critical security gap that needs immediate remediation.
  answer_sources:
  - GitHub audit stream
  - GitLab audit events
  - Cloud-based Git provider APIs and audit logs
  range: last 90 days
  queries:
  - pseudocode: GET all_repository_visibility_settings from API | COMPARE with master_list_of_intended_settings | IF actual_visibility > intended_visibility THEN TRIGGER high_priority_alert
- question: Is there a shift in access patterns from broad, diverse repository access to narrow, targeted access?
  context: This question attempts to detect the transition from general browsing to a focused attack. Normal user activity often involves accessing many different repositories (high entropy). An attacker, having identified a target, will repeatedly access a small number of specific repositories (low entropy). A significant drop in the Shannon entropy of accessed repository names can therefore signal that an adversary is focusing their efforts on a specific target.
  answer_sources:
  - GitHub audit stream
  - GitLab audit events
  - Cloud-based Git provider APIs and audit logs
  range: last 90 days
  queries:
  - pseudocode: CALCULATE hourly_shannon_entropy of accessed_repository_names from git_audit_logs | IF entropy_score < 10th_percentile_of_historical_distribution THEN TRIGGER alert
- question: Can we identify anomalous user sessions involving access to sensitive repositories?
  context: This question uses machine learning to profile user behavior and find outliers. An unsupervised model like Isolation Forest can learn what a 'normal' user session looks like based on features like the number of clones/forks, time of day, and account age. Sessions that the model flags as highly anomalous, especially those that interact with repositories intended to be private, are strong candidates for investigation as they may represent malicious activity.
  answer_sources:
  - GitHub audit stream
  - GitLab audit events
  - Cloud-based Git provider APIs and audit logs
  range: last 90 days
  queries:
  - pseudocode: RUN isolation_forest_model ON user_session_data | IF anomaly_score is high AND session_involves_sensitive_repo THEN FLAG_for_review
- question: Is anyone attempting to authenticate from an external IP address using a username whose credentials were recently leaked in a public repository?
  context: This question directly connects reconnaissance (leaked credentials) to an active intrusion attempt. Maintaining a watchlist of accounts compromised in public code leaks allows for high-fidelity alerting. Any authentication attempt (successful or failed) for an account on this list from an external IP is a critical event, as it's a strong indicator that an adversary is actively trying to use the stolen credential.
  answer_sources:
  - Windows Event ID 4624
  - Windows Event ID 4625
  - Zeek conn.log
  - Domain Controllers
  - VPN Concentrators
  - Cloud Identity Provider Logs (e.g., Azure AD)
  - Perimeter Firewalls
  range: last 90 days
  queries:
  - pseudocode: SEARCH authentication_logs WHERE username IN leaked_credential_watchlist AND source_ip is external | TRIGGER critical_severity_alert
- question: Are users on the leaked credential watchlist experiencing an unusual number of authentication failures, suggesting a credential stuffing attack?
  context: This question looks for targeted brute-force or credential stuffing attacks against known-compromised accounts. Even if an adversary has an old or incorrect password, they may try variations. By baselining the normal external authentication failure rate for each user on the watchlist, a sudden spike (more than 3 standard deviations above the baseline) can indicate a concerted effort to guess the password for that specific account.
  answer_sources:
  - Windows Event ID 4624
  - Windows Event ID 4625
  - Zeek conn.log
  - Domain Controllers
  - VPN Concentrators
  - Cloud Identity Provider Logs (e.g., Azure AD)
  - Perimeter Firewalls
  range: last 90 days
  queries:
  - pseudocode: FOR each user in watchlist CALC baseline_auth_failure_rate | IF hourly_failure_rate > (baseline_mean + 3 * baseline_stddev) THEN TRIGGER alert
- question: Can a machine learning model score the risk of external authentication attempts to better detect malicious logins?
  context: This question proposes a proactive, risk-based approach to authentication monitoring. A supervised model can learn the characteristics of malicious login attempts by considering multiple factors simultaneously, such as whether the user is on a watchlist, the rarity of the source IP/ASN/geolocation, and the time of day. This provides a more nuanced detection capability than simple rules and can identify sophisticated attacks that might otherwise be missed.
  answer_sources:
  - Windows Event ID 4624
  - Windows Event ID 4625
  - Zeek conn.log
  - Domain Controllers
  - VPN Concentrators
  - Cloud Identity Provider Logs (e.g., Azure AD)
  - Perimeter Firewalls
  range: last 90 days
  queries:
  - pseudocode: RUN random_forest_model ON external_authentication_events | IF malicious_probability_score > 0.9 THEN TRIGGER alert
- question: Is a single external IP address attempting to log in to many different accounts in a short period, indicating a password spraying attack?
  context: This question aims to detect a classic password spraying attack, where an adversary uses one or a few common passwords against many different usernames. The key indicator is a single source IP generating login failures for a high number of distinct accounts in a short time frame. A threshold of >10 accounts in 5 minutes is a strong, simple rule to identify this behavior.
  answer_sources:
  - Windows Event ID 4625
  - Zeek conn.log
  - Domain Controllers
  - VPN Concentrators
  - Web Application Firewalls (WAFs)
  range: last 90 days
  queries:
  - pseudocode: SEARCH logon_failure_logs (EventID 4625) | AGGREGATE distinct_user_count by source_ip over 5_minutes | WHERE distinct_user_count > 10 | TRIGGER high_severity_alert
- question: Can we more accurately identify password spraying by analyzing the ratio of unique accounts to failed logins from a source IP?
  context: This question refines the detection of password spraying. In a password spray, an attacker tries one password against many accounts, so the ratio of unique accounts targeted to total failures will be close to 1.0. In a brute-force attack against a single account, this ratio would be very low. By alerting when the ratio is high (>0.9) and a minimum number of accounts are targeted (>10), we can more reliably distinguish password spraying from other types of attacks.
  answer_sources:
  - Windows Event ID 4625
  - Zeek conn.log
  - Domain Controllers
  - VPN Concentrators
  - Web Application Firewalls (WAFs)
  range: last 90 days
  queries:
  - pseudocode: FOR each source_ip over 1_hour CALC ratio = (distinct_failed_users / total_failed_logins) | IF ratio > 0.9 AND distinct_failed_users > 10 THEN TRIGGER alert
- question: Can we use clustering algorithms to automatically discover password spraying activity in authentication logs?
  context: This question applies unsupervised machine learning to find attack patterns without predefined rules. A clustering algorithm like DBSCAN can group similar login events based on features like source IP and user-agent. A password spraying attack will form a distinct cluster characterized by a single source IP and user-agent but many different target user accounts. This allows the model to automatically identify and alert on such activity.
  answer_sources:
  - Windows Event ID 4625
  - Zeek conn.log
  - Domain Controllers
  - VPN Concentrators
  - Web Application Firewalls (WAFs)
  range: last 90 days
  queries:
  - pseudocode: RUN DBSCAN_clustering on authentication_logs over 15_minutes | FIND clusters with 1 source_ip AND high_distinct_user_count | TRIGGER alert
- question: Is an external entity attempting to resolve the DNS name of an internal-only service?
  context: This question aims to detect when an adversary, having found an internal hostname (e.g., 'dev-api.internal.corp.com') in a public code repository, attempts to find its IP address. DNS queries for internal-only hostnames that originate from external resolvers are highly suspicious, as these names should never be queried from outside the corporate network. This is a strong indicator of targeted reconnaissance.
  answer_sources:
  - Zeek conn.log
  - Zeek dns.log
  - Perimeter Firewalls
  - DNS Resolvers
  - Network TAPs providing data to Zeek sensors
  range: last 90 days
  queries:
  - pseudocode: SEARCH dns_logs (Zeek dns.log) WHERE query IN internal_hostname_watchlist AND source_resolver is external | TRIGGER high_severity_alert
- question: Are external entities successfully connecting to uncommon or rare service ports on our network?
  context: This question seeks to identify connections to non-standard or hidden services that may have been exposed in code. Most legitimate inbound traffic goes to common ports (e.g., 80, 443). A successful connection to a very rare port (in the bottom 1% of historical activity) suggests an attacker is probing for a service they discovered through other means, such as code reconnaissance.
  answer_sources:
  - Zeek conn.log
  - Zeek dns.log
  - Perimeter Firewalls
  - DNS Resolvers
  - Network TAPs providing data to Zeek sensors
  range: last 90 days
  queries:
  - pseudocode: CALCULATE historical_inbound_port_frequency | SEARCH connection_logs (Zeek conn.log) WHERE connection_state = 'SF' AND destination_port_frequency < 1st_percentile | TRIGGER medium_severity_alert
- question: Can we use machine learning to identify anomalous inbound network connections that might indicate probing of exposed services?
  context: This question uses an anomaly detection model to establish a baseline of 'normal' inbound network traffic. A One-Class SVM can learn the multi-dimensional profile of legitimate connections based on features like port, protocol, duration, and data volume. Any new connection that the model identifies as a significant outlier is flagged for investigation, as it may represent an attempt to connect to a service discovered through reconnaissance.
  answer_sources:
  - Zeek conn.log
  - Zeek dns.log
  - Perimeter Firewalls
  - DNS Resolvers
  - Network TAPs providing data to Zeek sensors
  range: last 90 days
  queries:
  - pseudocode: RUN one_class_svm_model ON inbound_connection_logs | IF connection is identified as outlier THEN TRIGGER alert