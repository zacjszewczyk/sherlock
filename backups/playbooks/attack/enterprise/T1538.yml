name: T1538: Cloud Service Dashboard
id: 5e6a9f1a-8d7b-4c3e-9a0f-2b1c8d7e6f5a
description: This playbook helps investigate whether an adversary is attempting to discover cloud resources or services by interacting with the cloud management console. This involves detecting anomalous console logins (based on IP reputation, geovelocity, or behavioral patterns), the use of suspicious User-Agent strings indicative of offensive tools or scripts, an unusually high volume and variety of read-only API calls suggesting automated reconnaissance, and unauthorized attempts to discover sensitive resources like secrets, encryption keys, or user permissions.
type: technique
related:
- TA0007: Discovery
contributors: Zachary Szewczyk, Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
- question: Is a cloud console login originating from a known malicious IP address, TOR exit node, or anonymizing proxy?
  context: This question aims to identify logins from sources with a poor reputation. An adversary might use compromised infrastructure or anonymizing services to hide their true origin. Correlating login source IPs against active threat intelligence feeds is a direct way to detect this activity. A match is a strong indicator of malicious intent.
  answer_sources:
  - AWS CloudTrail logs (ConsoleLogin event)
  - Azure SignIn Logs
  - Google Cloud Audit Logs (Admin Activity)
  - Zeek conn.log
  - Windows Security Event ID 4624
  - Cloud IAM infrastructure
  - Internet gateways and proxies
  - Endpoint devices of privileged users
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: SEARCH cloud_login_events | EXTRACT source_ip | JOIN threat_intel_feed ON source_ip | WHERE match_found | ALERT severity=high
- question: Is a cloud console login occurring from a geographic location, Autonomous System (AS), or at a time of day that is statistically rare for the user?
  context: This question looks for behavioral anomalies. Adversaries often operate from different locations and at different times than legitimate users. By establishing a baseline of normal activity for each user (source country, ASN, login hour), we can spot deviations that suggest an account may be compromised. A login that is rare across multiple dimensions increases the likelihood of malicious intent.
  answer_sources:
  - AWS CloudTrail logs (ConsoleLogin event)
  - Azure SignIn Logs
  - Google Cloud Audit Logs (Admin Activity)
  - Zeek conn.log
  - Windows Security Event ID 4624
  - Cloud IAM infrastructure
  - Internet gateways and proxies
  - Endpoint devices of privileged users
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: FOR each user, BUILD baseline of login_country, login_asn, login_hour over 90d. FOR each new login, CALCULATE frequency of current attributes. IF frequency < 5th_percentile, INCREMENT risk_score. IF risk_score > threshold, ALERT severity=medium.
- question: Has a user account logged in from two geographically distant locations in a time frame that would be physically impossible?
  context: This question seeks to identify 'impossible travel' scenarios, a classic indicator of account sharing or compromise. If a user logs in from New York and then five minutes later from Moscow, it is clear that at least one of the sessions is not legitimate. This model calculates the required travel speed between consecutive logins to detect such anomalies.
  answer_sources:
  - AWS CloudTrail logs (ConsoleLogin event)
  - Azure SignIn Logs
  - Google Cloud Audit Logs (Admin Activity)
  - Zeek conn.log
  - Windows Security Event ID 4624
  - Cloud IAM infrastructure
  - Internet gateways and proxies
  - Endpoint devices of privileged users
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: FOR each user, GET previous and current login location/time. CALCULATE required_speed = distance / time_difference. IF required_speed > 800 km/h, ALERT severity=high.
- question: Is a cloud console session associated with a User-Agent string known to belong to an offensive security tool or unauthorized script?
  context: This question aims to detect the use of specific hacking or automation tools. Adversaries and red teamers use tools like Pacu, and their User-Agent strings can be a dead giveaway. Similarly, unauthorized scripts can be identified. Matching User-Agents against a blocklist of known malicious or unauthorized tool signatures is an effective detection method.
  answer_sources:
  - AWS CloudTrail logs
  - Azure Activity Logs
  - Google Cloud Audit Logs (Admin Activity)
  - Zeek http.log
  - Cloud management consoles (e.g., AWS Management Console, Azure Portal)
  - Internet gateways and proxies
  - Cloud API endpoints
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: SEARCH cloud_activity_logs | EXTRACT user_agent | MATCH user_agent against regex_list_of_bad_tools | IF match_found, ALERT severity=medium.
- question: Is a user logging in with a User-Agent string that is both new for that specific user and rare across the entire organization?
  context: This question identifies anomalous User-Agents without relying on a predefined blocklist. A User-Agent might not be from a known bad tool, but if it is new for a particular user and very uncommon organization-wide, it is suspicious. This could indicate an adversary using a custom tool or a less common browser/scripting environment to evade detection.
  answer_sources:
  - AWS CloudTrail logs
  - Azure Activity Logs
  - Google Cloud Audit Logs (Admin Activity)
  - Zeek http.log
  - Cloud management consoles (e.g., AWS Management Console, Azure Portal)
  - Internet gateways and proxies
  - Cloud API endpoints
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: FOR each new login, EXTRACT user, user_agent. CHECK if user_agent is new for user. CALCULATE global_rarity of user_agent. IF new_for_user AND global_rarity < 1%, ALERT.
- question: Does a machine learning model classify a console session's User-Agent string as likely belonging to a malicious tool?
  context: This question leverages machine learning to move beyond simple string matching or rarity analysis. By training a model on a large dataset of known benign and malicious User-Agents, the system can learn to identify suspicious patterns and characteristics of malicious tool strings, potentially catching new or unknown tools that are not on a static list.
  answer_sources:
  - AWS CloudTrail logs
  - Azure Activity Logs
  - Google Cloud Audit Logs (Admin Activity)
  - Zeek http.log
  - Cloud management consoles (e.g., AWS Management Console, Azure Portal)
  - Internet gateways and proxies
  - Cloud API endpoints
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: FOR each new login, EXTRACT user_agent. CLASSIFY user_agent with ML_model. IF classification == 'malicious-tool', ALERT severity=medium.
- question: Has a single user session generated an unusually high volume of read-only API calls across many different cloud services in a short period?
  context: This question seeks to identify automated reconnaissance. After gaining access, an adversary will often run scripts to enumerate all available resources. This activity manifests as a large burst of read-only calls (like 'List*', 'Describe*', 'Get*') across multiple services, a pattern that is highly atypical for normal human administrative work.
  answer_sources:
  - AWS CloudTrail logs (List*, Describe*, Get* events)
  - Azure Activity Logs (Microsoft.Resources/subscriptions/resourceGroups/read)
  - Google Cloud Audit Logs (Data Access)
  - Cloud API endpoints
  - Cloud management consoles
  - Specific cloud service infrastructure (e.g., S3, EC2, RDS)
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: SEARCH read_only_api_calls within 15_min_window by session_id. COUNT calls, COUNT_DISTINCT services. IF calls > 100 AND distinct_services > 5, ALERT severity=medium.
- question: Is the variety of API calls within a user session statistically unusual compared to the user's normal behavior?
  context: This question uses information theory to detect anomalous activity. Normal user sessions involve predictable API calls for a task. Automated reconnaissance often involves a wide, less predictable variety of calls. Calculating the Shannon entropy of the API call names quantifies this variety; a sudden spike in entropy for a user's session can indicate a shift from normal work to broad discovery.
  answer_sources:
  - AWS CloudTrail logs (List*, Describe*, Get* events)
  - Azure Activity Logs (Microsoft.Resources/subscriptions/resourceGroups/read)
  - Google Cloud Audit Logs (Data Access)
  - Cloud API endpoints
  - Cloud management consoles
  - Specific cloud service infrastructure (e.g., S3, EC2, RDS)
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: FOR each session, CALCULATE shannon_entropy of api_call_names in 10_min_window. COMPARE to user's 90d historical entropy. IF current_entropy > 99th_percentile, FLAG for review.
- question: Does the sequence of API calls in a user session deviate from patterns learned by a sequence-based anomaly detection model?
  context: This advanced technique considers the specific order of API calls. Legitimate tasks often follow predictable sequences. An LSTM autoencoder can learn these normal sequences. When an adversary performs reconnaissance, the sequence will likely differ, causing the model to generate a high 'reconstruction error' and flag the session as anomalous.
  answer_sources:
  - AWS CloudTrail logs (List*, Describe*, Get* events)
  - Azure Activity Logs (Microsoft.Resources/subscriptions/resourceGroups/read)
  - Google Cloud Audit Logs (Data Access)
  - Cloud API endpoints
  - Cloud management consoles
  - Specific cloud service infrastructure (e.g., S3, EC2, RDS)
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: FOR each active session, GET sequence of api_calls. FEED sequence to LSTM_autoencoder_model. CALCULATE reconstruction_error. IF reconstruction_error > threshold, FLAG as anomalous.
- question: Is a user who is not in a pre-approved security or audit group attempting to discover sensitive resources like secrets, encryption keys, or detailed authorization policies?
  context: This question focuses on high-risk actions performed by unauthorized personnel. Access to secrets, keys, and IAM policies should be tightly controlled. This is a rule-based check that immediately alerts when any user outside of a defined privileged group tries to perform a sensitive discovery action. This is a high-fidelity indicator of privilege escalation or internal reconnaissance.
  answer_sources:
  - AWS CloudTrail logs (e.g., secretsmanager:ListSecrets, iam:GetAccountAuthorizationDetails)
  - Azure Activity Logs (e.g., Microsoft.KeyVault/vaults/secrets/list/action)
  - Google Cloud Audit Logs (Data Access)
  - Secrets management services (e.g., AWS Secrets Manager, Azure Key Vault)
  - IAM infrastructure
  - Data storage services hosting sensitive information
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: SEARCH for sensitive_api_calls in watchlist. EXTRACT user, user_groups. IF user_groups NOT IN ('Cloud Security Admin', 'Cloud Auditor'), ALERT severity=high.
- question: Is a user performing a sensitive API call that is extremely rare or has never been performed by anyone in their assigned role before?
  context: This provides a dynamic approach by baselining normal behavior at the role level. If a user in a 'Marketing' role suddenly calls 'ListSecrets,' an action that no one in that role has ever performed, it is highly suspicious. This detects privilege abuse or compromise even for users who might have overly permissive roles.
  answer_sources:
  - AWS CloudTrail logs (e.g., secretsmanager:ListSecrets, iam:GetAccountAuthorizationDetails)
  - Azure Activity Logs (e.g., Microsoft.KeyVault/vaults/secrets/list/action)
  - Google Cloud Audit Logs (Data Access)
  - Secrets management services (e.g., AWS Secrets Manager, Azure Key Vault)
  - IAM infrastructure
  - Data storage services hosting sensitive information
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: FOR each sensitive_api_call, EXTRACT user_role, api_call. GET historical_frequency of api_call for user_role. IF historical_frequency is 0 or < 1st_percentile, ALERT.
- question: Does a graph-based model predict that a user's attempt to access a sensitive resource is a low-probability, and therefore anomalous, event?
  context: This sophisticated, relationship-based method models the cloud environment as a graph (users/resources as nodes, access as edges). By analyzing historical patterns, the model learns which connections are 'normal.' When a new, unexpected connection is made (e.g., a non-technical user accessing a production key), the model flags it as a low-probability link, indicating a significant anomaly.
  answer_sources:
  - AWS CloudTrail logs (e.g., secretsmanager:ListSecrets, iam:GetAccountAuthorizationDetails)
  - Azure Activity Logs (e.g., Microsoft.KeyVault/vaults/secrets/list/action)
  - Google Cloud Audit Logs (Data Access)
  - Secrets management services (e.g., AWS Secrets Manager, Azure Key Vault)
  - IAM infrastructure
  - Data storage services hosting sensitive information
  range: last 90 days
  queries:
  - query_language: pseudocode
    query: MODEL graph with nodes(users, resources) and edges(access_events). FOR each new access_event (user -> resource), CALCULATE link_prediction_probability. IF probability < threshold, ALERT severity=high.