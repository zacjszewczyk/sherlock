name: T0829: Loss of View
id: 2a7d8c5e-9e1f-4b3a-8f9c-0d1e2f3a4b5d
description: This playbook helps investigate if an adversary is attempting to cause a Loss of View, a type of Impact tactic. This can manifest in several ways: instability or termination of critical HMI processes, a significant reduction in network traffic from control devices like PLCs to HMIs or Historians, or a denial-of-service attack against HMI servers causing a surge in failed network connections. The goal is to detect attempts to blind operators from the true state of the industrial process.
type: technique
related:
  - TA0105: Impact
contributors:
  - Zachary Szewczyk
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Are critical HMI processes crashing or hanging more frequently than expected on a specific host?
    context: This question investigates whether a critical HMI process, identified from a predefined watchlist, is showing signs of instability. By monitoring for specific application error or hang events (Windows Event IDs 1000, 1002) and process termination events (4689) without a corresponding restart (4688), we can detect targeted attacks or induced failures designed to disrupt the operator's view. A sudden spike in these events or a failure to auto-restart can be a strong indicator of malicious activity aimed at causing a Loss of View.
    answer_sources:
      - Windows Event ID 1000
      - Windows Event ID 1002
      - Windows Event ID 4688
      - Windows Event ID 4689
      - Critical Operator Workstations and HMI Servers within the Level 2 (Supervisory) and Level 3 (Site Control) zones of the Process Control Network (PCN), including any associated DMZ for remote HMI access.
    range: last 90 days
    queries:
      - query_type: pseudocode
        query: |
          WATCHLIST = [critical_hmi_process_names]
          QUERY Windows Events WHERE (EventID IN (1000, 1002) AND ProcessName IN WATCHLIST)
          GROUP BY Hostname
          ALERT if count > 2 in 60 seconds
          ---
          QUERY Windows Events WHERE (EventID == 4689 AND ProcessName IN WATCHLIST)
          CHECK for subsequent EventID 4688 for same ProcessName and Hostname within 30 seconds
          ALERT if no EventID 4688 is found
  - question: Has the rate of HMI process errors or the time it takes for them to restart deviated statistically from their normal baseline?
    context: This question uses statistical analysis to detect subtle signs of HMI instability. By establishing a historical baseline (e.g., 14 days) for the frequency of application errors/hangs and the typical time required for an auto-restarting process to come back online, we can identify anomalies. An alert is triggered if the current error rate exceeds the 99th percentile of the baseline, or if a process takes significantly longer (e.g., 3 standard deviations above the mean) to restart after termination. This method is effective at finding slow, low-frequency attacks that might be missed by simple thresholding.
    answer_sources:
      - Windows Event ID 1000
      - Windows Event ID 1002
      - Windows Event ID 4688
      - Windows Event ID 4689
      - Critical Operator Workstations and HMI Servers within the Level 2 (Supervisory) and Level 3 (Site Control) zones of the Process Control Network (PCN), including any associated DMZ for remote HMI access.
    range: last 90 days
    queries:
      - query_type: pseudocode
        query: |
          BASELINE error counts (EventID 1000, 1002) per 10-min interval over 14 days
          CALCULATE 99th percentile threshold
          MONITOR live 10-min counts and ALERT if count > threshold
          ---
          BASELINE time delta between EventID 4689 and 4688 over 14 days
          CALCULATE mean and standard deviation
          MONITOR live restart times and ALERT if delta > (mean + 3 * stddev)
  - question: Is there an anomalous pattern in HMI process stability events that a machine learning model identifies as a deviation from normal behavior?
    context: This question applies an unsupervised machine learning model, such as an Isolation Forest, to detect complex anomalies in HMI stability. The model is trained on historical time-series data (e.g., 30 days) that includes features like the counts of application errors, hangs, and terminations per minute. By learning the normal operational patterns of HMI hosts, the model can identify novel or sophisticated attack techniques that might not trigger rule-based or statistical alerts. An anomaly score exceeding a tuned threshold indicates a significant deviation that warrants investigation.
    answer_sources:
      - Windows Event ID 1000
      - Windows Event ID 1002
      - Windows Event ID 4689
      - Critical Operator Workstations and HMI Servers within the Level 2 (Supervisory) and Level 3 (Site Control) zones of the Process Control Network (PCN), including any associated DMZ for remote HMI access.
    range: last 90 days
    queries:
      - query_type: pseudocode
        query: |
          TRAIN Isolation Forest model on 30+ days of feature data (EventID 1000, 1002, 4689 counts per minute)
          APPLY trained model to live data stream from HMI hosts
          CALCULATE anomaly score
          ALERT if anomaly score > configured_threshold
  - question: Has communication from a critical field device (PLC, RTU) to a control system (HMI, Historian) stopped for an unusual amount of time?
    context: This question aims to detect a complete or prolonged interruption in communication between essential OT components. It uses a rule-based approach by defining critical communication pairs (e.g., a specific PLC and its Historian) and their expected maximum polling interval. If network logs (like Zeek) show no traffic for that specific pair for a period significantly longer than normal (e.g., three times the interval), it triggers an alert. This can indicate a device failure, a network partition, or a deliberate "man-in-the-middle" attack blocking traffic to blind operators.
    answer_sources:
      - Zeek conn.log
      - Zeek modbus.log
      - Zeek dnp3.log
      - Zeek enip.log
      - Zeek opcua.log
      - Network sensors monitoring critical network segments at the Level 1.5 (Industrial Demilitarized Zone/IDMZ) and Level 2 (Supervisory) boundaries within the Process Control Network (PCN), specifically those carrying traffic between Level 0/1 devices (PLCs, RTUs) and Level 2/3 systems (HMI, Historian, Engineering Workstations).
    range: last 90 days
    queries:
      - query_type: pseudocode
        query: |
          DEFINE critical_pairs = [(src_ip, dest_ip, port, max_interval)]
          FOR each pair in critical_pairs:
             QUERY Zeek logs for latest communication timestamp
             IF (current_time - latest_timestamp) > (3 * pair.max_interval):
                 ALERT for communication loss
  - question: Has the volume or type of network traffic from field devices dropped below its statistically normal baseline?
    context: This question looks for statistically significant reductions in network traffic that may not be a complete stoppage but still indicate a problem. It establishes a rolling baseline (e.g., 7 days) for metrics like total bytes and message counts per minute for critical traffic flows. An alert is triggered if the current traffic volume drops below a low percentile (e.g., 5th percentile) for a sustained period. Additionally, it monitors the diversity of protocol commands (e.g., Modbus function codes) using entropy; a sudden drop in entropy can signify that the device is only sending basic heartbeats and not actual operational data, which is another form of a Loss of View.
    answer_sources:
      - Zeek conn.log
      - Zeek modbus.log
      - Zeek dnp3.log
      - Zeek enip.log
      - Zeek opcua.log
      - Network sensors monitoring critical network segments at the Level 1.5 (Industrial Demilitarized Zone/IDMZ) and Level 2 (Supervisory) boundaries within the Process Control Network (PCN), specifically those carrying traffic between Level 0/1 devices (PLCs, RTUs) and Level 2/3 systems (HMI, Historian, Engineering Workstations).
    range: last 90 days
    queries:
      - query_type: pseudocode
        query: |
          BASELINE traffic metrics (bytes, message count) per 1-min interval over 7 days
          CALCULATE 5th percentile threshold
          MONITOR live metrics and ALERT if value < threshold for 3 consecutive minutes
          ---
          BASELINE Shannon entropy of protocol function codes per 5-min window
          CALCULATE 10th percentile threshold
          MONITOR live entropy and ALERT if value < threshold
  - question: Does a machine learning model predict that the current network traffic volume from a field device is anomalously low?
    context: This question uses a time-series forecasting model (like SARIMA) to predict the expected volume of network traffic for critical flows. The model is trained on extensive historical data (e.g., 30+ days) to understand normal patterns, including daily and weekly seasonality. It then compares the real-time observed traffic volume against the model's prediction. If the actual volume falls below the lower bound of a high-confidence prediction interval (e.g., 99%) for a sustained period, it signals an anomalous drop in traffic that could be part of an attack to cause a Loss of View.
    answer_sources:
      - Zeek conn.log
      - Zeek modbus.log
      - Zeek dnp3.log
      - Zeek enip.log
      - Zeek opcua.log
      - Network sensors monitoring critical network segments at the Level 1.5 (Industrial Demilitarized Zone/IDMZ) and Level 2 (Supervisory) boundaries within the Process Control Network (PCN), specifically those carrying traffic between Level 0/1 devices (PLCs, RTUs) and Level 2/3 systems (HMI, Historian, Engineering Workstations).
    range: last 90 days
    queries:
      - query_type: pseudocode
        query: |
          TRAIN SARIMA model on 30+ days of traffic volume data (total bytes, packets)
          FORECAST expected traffic volume and 99% prediction interval for live data
          COMPARE observed volume to forecast
          ALERT if observed_volume < lower_bound_of_interval for > 10 minutes
  - question: Is a critical HMI server experiencing a high volume of failed or blocked network connections from one or more sources?
    context: This question seeks to identify a potential Denial-of-Service (DoS) attack targeting an HMI server by using simple, high-volume thresholds. It monitors network logs (Zeek) for failed connection states ('S0', 'REJ') and host firewall logs (Windows Event ID 5156) for blocked packets. An alert is triggered if a single source IP generates an excessive number of failed connections or blocked packets in a short time window, or if the total number of failed connections from all sources exceeds a high threshold. This indicates an attempt to overwhelm the HMI server and prevent legitimate operator access.
    answer_sources:
      - Zeek conn.log
      - Windows Event ID 5156
      - Network sensors and host logs on critical HMI Servers within the Level 2 (Supervisory) zone of the Process Control Network (PCN) and any associated IDMZ or enterprise DMZ enabling remote access to HMI systems.
    range: last 90 days
    queries:
      - query_type: pseudocode
        query: |
          QUERY Zeek conn.log WHERE dest_ip is HMI_server and conn_state IN ('S0', 'REJ', 'RSTO')
          ALERT if count from single src_ip > 30 in 30s OR total count > 100 in 60s
          ---
          QUERY Windows Event ID 5156 on HMI_server
          ALERT if blocked packet count from single src_ip > 50 in 60s
  - question: Is the rate of total connections and the ratio of failed-to-successful connections to an HMI server statistically anomalous?
    context: This question uses a more nuanced statistical approach to detect DoS attacks. Instead of fixed thresholds, it establishes a baseline (e.g., 7 days) for both the total number of new connections and the ratio of failed connections to total connections. An attack is suspected when both metrics deviate from the norm simultaneously. An alert is triggered if the current connection rate exceeds a high percentile (e.g., 99th) of its baseline, AND the failed connection ratio also exceeds its own high percentile (e.g., 95th). This helps distinguish a legitimate high-traffic event from a malicious resource exhaustion attack.
    answer_sources:
      - Zeek conn.log
      - Windows Event ID 5156
      - Network sensors and host logs on critical HMI Servers within the Level 2 (Supervisory) zone of the Process Control Network (PCN) and any associated IDMZ or enterprise DMZ enabling remote access to HMI systems.
    range: last 90 days
    queries:
      - query_type: pseudocode
        query: |
          BASELINE total connection rate per 5-min interval over 7 days, calculate 99th percentile
          BASELINE failed_conn_ratio per 5-min interval over 7 days, calculate 95th percentile
          MONITOR live metrics
          ALERT if (current_conn_rate > 99th_percentile) AND (current_failed_ratio > 95th_percentile)
  - question: Does a machine learning model classify the current network traffic pattern to an HMI server as an anomaly consistent with a DoS attack?
    context: This question employs an unsupervised machine learning model (like a One-Class SVM) to identify complex DoS attack patterns that may evade simpler detection methods. The model is trained on a variety of features from normal network traffic, such as connection rate, entropy of source IPs and ports, and connection state ratios. By learning this multi-dimensional profile of "normal," it can flag traffic patterns that are outliers, indicating sophisticated attacks like distributed DoS (DDoS) or slow, low-rate DoS attacks that might not trigger volume-based thresholds.
    answer_sources:
      - Zeek conn.log
      - Windows Event ID 5156
      - Network sensors and host logs on critical HMI Servers within the Level 2 (Supervisory) zone of the Process Control Network (PCN) and any associated IDMZ or enterprise DMZ enabling remote access to HMI systems.
    range: last 90 days
    queries:
      - query_type: pseudocode
        query: |
          TRAIN One-Class SVM model on 30+ days of feature data (conn_rate, src_ip_entropy, src_port_entropy, state_ratios, etc.)
          APPLY trained model to live traffic vectors targeting HMI servers
          ALERT if model classifies a data point as an outlier/anomaly