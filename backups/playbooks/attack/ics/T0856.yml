name: T0856: Spoof Reporting Message
id: f47ac10b-58cc-4372-a567-0e02b2c3d479
description: |
  This playbook investigates adversary actions to spoof reporting messages in Industrial Control Systems (ICS). This can be done to hide the true state of an industrial process or to mislead operators, potentially impairing process control. Key indicators include protocol-level anomalies like unusual sequence numbers or message timing; physically implausible telemetry values that contradict correlated sensors; communications from unauthorized IP or MAC addresses; the generation of false critical alarms to trigger shutdowns or alarm floods to distract operators; and spoofing 'all-clear' signals from safety systems to prevent them from activating during a dangerous event.
type: technique
related:
  - TA0103: Evasion
  - TA0106: Impair Process Control
contributors:
  - Zachary Szewczyk
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Have any ICS devices transmitted messages with duplicate or non-monotonic sequence numbers, suggesting a potential message spoofing or replay attack?
    context: |
      This question aims to detect low-level protocol manipulation. Adversaries may replay or inject messages, which can disrupt the expected sequence of protocol communications. Detecting duplicate sequence numbers in a very short time frame or sequence numbers that decrease without a valid protocol reset command are strong indicators of a man-in-the-middle or replay attack attempting to spoof device state.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek conn.log
      - Network segments monitoring Level 1 (Basic Control) devices (PLCs, RTUs, IEDs), the Level 2 (Supervisory Control) network, and Industrial Demilitarized Zone (IDMZ) network segments where ICS protocol traffic (DNP3, Modbus, IEC 61850) is captured and processed.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Rule 1: Duplicate sequence number
          FOR each dnp3.log or modbus.log entry
            LET device = entry.id.orig_h
            LET seq_num = entry.dnp3.seq_num or entry.modbus.trans_id
            IF seq_num for device was seen in last 5 seconds
              ALERT "Duplicate sequence number detected"
          # Rule 2: Non-monotonic sequence number
          FOR each dnp3.log or modbus.log entry
            LET device = entry.id.orig_h
            LET current_seq = entry.dnp3.seq_num
            LET previous_seq = last seen seq_num for device
            IF current_seq < previous_seq
              CHECK for "Cold Restart" or "Restart Communications" command to device in last 60 seconds
              IF no restart command found
                ALERT "Non-monotonic sequence number detected without reset"
  - question: Are there any ICS devices exhibiting anomalous message timing (inter-arrival time) or sequence number patterns that suggest a replay attack?
    context: |
      This question looks for statistical deviations in message timing and sequencing. Legitimate devices report at configured, often periodic, intervals. A significant deviation from the normal inter-arrival time (IAT) can indicate injected or dropped packets. A sudden drop in the randomness (entropy) of sequence number increments suggests a pre-recorded, fixed sequence is being replayed, which is a classic sign of a replay attack.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek conn.log
      - Network segments monitoring Level 1 (Basic Control) devices (PLCs, RTUs, IEDs), the Level 2 (Supervisory Control) network, and Industrial Demilitarized Zone (IDMZ) network segments where ICS protocol traffic (DNP3, Modbus, IEC 61850) is captured and processed.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # IAT Anomaly Detection
          FOR each device
            CALCULATE 30-day rolling baseline of IAT (5th and 95th percentiles)
            FOR each new message from device
              CALCULATE current IAT
              IF current IAT is outside baseline range
                ALERT "Anomalous message inter-arrival time"
          # Sequence Entropy Drop
          FOR each device
            CALCULATE Shannon entropy of sequence number increments over 1-hour window
            IF entropy drops significantly below historical baseline
              ALERT "Sudden drop in sequence number entropy, possible replay attack"
  - question: Can advanced time-series analysis detect subtle, multi-faceted anomalies in device communication patterns (sequence number, timing, payload size) that indicate spoofing?
    context: |
      This question uses machine learning to build a comprehensive model of a device's normal behavior. Simple rule-based checks might miss sophisticated attacks where an adversary subtly manipulates multiple parameters at once. A multivariate model like an LSTM Autoencoder learns the complex relationships between sequence numbers, timing, and payload size. When a live message stream doesn't fit this learned pattern (high reconstruction error), it signals a complex anomaly that could be a spoofing attack.
    answer_sources:
      - Zeek dnp3.log
      - Zeek conn.log
      - Network segments monitoring Level 1 (Basic Control) devices (PLCs, RTUs, IEDs), the Level 2 (Supervisory Control) network, and Industrial Demilitarized Zone (IDMZ) network segments where ICS protocol traffic (DNP3, Modbus, IEC 61850) is captured and processed.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # LSTM Autoencoder Anomaly Detection
          TRAIN LSTM Autoencoder model on 90 days of baseline data (seq_num, IAT, payload_size) per device
          FOR each new message stream
            FEED data into trained model
            CALCULATE reconstruction error
            CALCULATE dynamic threshold (e.g., moving_avg(error) + N * stddev(error))
            IF reconstruction error > dynamic threshold
              ALERT "Multivariate anomaly detected in device communication"
  - question: Is there a contradiction between alarms logged by high-level systems (like a Process Historian) and the raw sensor data observed on the network?
    context: |
      This question seeks to find discrepancies between different layers of the control system. An adversary might spoof a normal value at the network level to hide a real-world problem. If the Process Historian, which may have its own analytics, detects a physics-based anomaly (e.g., tank pressure is too high), but the network traffic from that tank's sensor shows a normal value, it strongly implies the network message is being spoofed to conceal the dangerous state.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek iec61850.log
      - Windows Application Event Logs
      - SCADA servers, Process Historian servers, HMI workstations, Engineering Workstations, and network segments where ICS protocol traffic is captured.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Correlate Historian Alarms with Network Data
          ON Historian alarm event (e.g., "High pressure for Tank A")
            GET associated sensor IP/ID for "Tank A"
            QUERY Zeek logs for sensor data from that IP/ID in the last 30 seconds
            IF sensor data shows a value within normal range
              ALERT "Contradiction between Historian alarm and network sensor data"
  - question: Are physically linked processes (e.g., pump speed and flow rate) showing a breakdown in their expected correlation, suggesting one of the signals is spoofed?
    context: |
      This question leverages the laws of physics to detect anomalies. In a stable process, certain measurements are tightly correlated (e.g., increasing a pump's speed increases the flow rate). If this strong correlation suddenly weakens or disappears, it's a physical impossibility under normal circumstances. It likely means one of the sensor signals is no longer reporting the true state of the process and is being spoofed.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek iec61850.log
      - Windows Application Event Logs
      - SCADA servers, Process Historian servers, HMI workstations, Engineering Workstations, and network segments where ICS protocol traffic is captured.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Cross-Correlation Analysis
          FOR each pair of physically linked sensors
            ESTABLISH baseline correlation coefficient (e.g., 0.95) from historical data
            IN real-time over a 5-minute sliding window
              CALCULATE cross-correlation coefficient of the two data streams
              IF calculated coefficient < critical threshold (e.g., 0.5)
                ALERT "Breakdown in correlation between physically linked sensors"
  - question: Can a machine learning model, trained on known good and bad states, predict in real-time when a sensor's reported value diverges from a trusted, secondary source?
    context: |
      This question applies supervised machine learning to formalize the detection of data divergence. By training a model like XGBoost on historical examples of both normal and divergent behavior (where a primary sensor reading contradicts a trusted secondary source), the system can learn the complex patterns that signify a spoofed value. This allows for automated, high-confidence detection of these events in real-time.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek iec61850.log
      - Windows Application Event Logs
      - SCADA servers, Process Historian servers, HMI workstations, Engineering Workstations, and network segments where ICS protocol traffic is captured.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Supervised Divergence Detection
          TRAIN XGBoost model on historical data (primary_value, secondary_value, difference, etc.) labeled as 'divergent' or 'normal'
          DEPLOY trained model
          FOR each new data point from primary sensor
            GET corresponding secondary source value
            PREDICT state using model
            IF prediction is 'divergent' with confidence > 0.9
              ALERT "High-confidence prediction of sensor value divergence"
  - question: Are ICS protocol messages originating from IP or MAC addresses that do not match the authoritative asset inventory for that device?
    context: |
      This is a fundamental check for network integrity. Every device on the OT network should have a known, documented IP and MAC address. If a message purporting to be from a specific field device comes from an unrecognized IP or MAC, it is a strong indicator of an impersonation or spoofing attack. This requires maintaining an accurate and up-to-date asset inventory.
    answer_sources:
      - Zeek conn.log
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek iec61850.log
      - Level 0 (Process Control) and Level 1 (Basic Control) network segments, Level 2 (Supervisory Control) network segments, Industrial Demilitarized Zone (IDMZ), and network gateways between IT and OT environments.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Asset Inventory Cross-Reference
          LOAD OT asset inventory (Device_ID, IP, MAC) into SIEM watchlist
          FOR each Zeek conn.log with ICS service
            LET source_ip = log.id.orig_h
            LET source_mac = log.id.orig_l2_addr
            LOOKUP source_ip and source_mac in asset inventory
            IF source_ip or source_mac does not match any registered device
              ALERT "ICS traffic from unauthorized IP/MAC address"
  - question: Are the communication flow patterns (e.g., ratio of bytes sent to bytes received) for an ICS device deviating significantly from their established baseline?
    context: |
      This question looks for anomalies in the network flow characteristics, rather than the content of the packets. ICS devices typically have very predictable communication patterns. A spoofed packet might be malformed or unexpected, causing the receiving device to respond with an error message or an unusual amount of data. A significant deviation in the ratio of originator-to-responder bytes can reveal these anomalous exchanges.
    answer_sources:
      - Zeek conn.log
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek iec61850.log
      - Level 0 (Process Control) and Level 1 (Basic Control) network segments, Level 2 (Supervisory Control) network segments, Industrial Demilitarized Zone (IDMZ), and network gateways between IT and OT environments.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Communication Ratio Anomaly
          FOR each ICS device
            CALCULATE 60-day baseline (mean, stddev) of (orig_bytes / resp_bytes) ratio
            FOR each new connection
              CALCULATE current ratio
              IF current ratio deviates > 3 * stddev from mean
                ALERT "Anomalous communication byte ratio for device"
  - question: Can an unsupervised machine learning model detect anomalous network flows from ICS devices based on their metadata, even without prior knowledge of attack patterns?
    context: |
      This question uses unsupervised learning to find "unknown unknowns." An Isolation Forest model is effective at identifying outliers in data without needing to be trained on labeled attack examples. By analyzing a combination of flow metadata (bytes sent/received, duration, port entropy), it can flag connections that are statistically different from the device's normal behavior, potentially identifying novel or sophisticated spoofing techniques.
    answer_sources:
      - Zeek conn.log
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek iec61850.log
      - Level 0 (Process Control) and Level 1 (Basic Control) network segments, Level 2 (Supervisory Control) network segments, Industrial Demilitarized Zone (IDMZ), and network gateways between IT and OT environments.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Unsupervised Flow Anomaly Detection
          FOR each ICS device
            TRAIN Isolation Forest model on historical flow metadata (orig_bytes, resp_bytes, duration, port_entropy)
            FOR each new network flow
              CALCULATE anomaly score using the model
              IF score > 0.75
                ALERT "High anomaly score for network flow detected"
  - question: Has a critical alarm been reported by a sensor without any corresponding operator action or corroborating physical evidence, suggesting a false alarm was injected?
    context: |
      This question aims to identify spoofed alarms intended to cause disruption. An adversary might inject a fake critical alarm to trick an automated system into an unnecessary shutdown or to mislead an operator. This rule checks for this by verifying two things: was there a legitimate operator command that could have caused the condition, and does a separate, physically related sensor confirm the anomaly? If the answer to both is no, the alarm is likely spoofed.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Windows Application Event Logs
      - Windows Security Event ID 4624
      - HMI workstations, Engineering Workstations, SCADA servers, and the Level 2 Supervisory Control network where operator actions and alarms are logged.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # False Critical Alarm Correlation
          ON critical alarm value in dnp3.log
            CHECK for operator logon (Event ID 4624) or command on HMI in last 5 minutes
            CHECK data from physically correlated sensor
            IF no operator action AND correlated sensor is normal
              ALERT "Potential spoofed critical alarm detected"
  - question: Has any critical sensor value changed at a physically impossible rate, indicating a spoofed, instantaneous jump in value?
    context: |
      This question leverages the physical constraints of industrial processes. Real-world values like temperature or pressure cannot change instantaneously. A spoofed message, however, can set a value from normal to critical in a single packet, resulting in a near-infinite rate of change (a step function). By monitoring this rate of change and alerting when it exceeds the maximum possible physical rate, we can effectively detect these artificial value jumps.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Windows Application Event Logs
      - Windows Security Event ID 4624
      - HMI workstations, Engineering Workstations, SCADA servers, and the Level 2 Supervisory Control network where operator actions and alarms are logged.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Rate of Change Anomaly
          FOR each critical sensor
            CALCULATE baseline of historical maximum rate of change
            FOR each new measurement
              CALCULATE rate of change from previous measurement
              IF rate of change > 3 * stddev of baseline maximum
                ALERT "Physically impossible rate of change detected"
  - question: Can a machine learning classifier distinguish between authentic critical alarms and likely spoofed alarms based on a combination of sensor data and contextual information?
    context: |
      This question proposes using a supervised model to automate the complex task of validating critical alarms. By training a model like a Random Forest on data that process engineers have labeled as 'true alarms' or 'normal', the system learns the subtle multivariate patterns that differentiate them. Features can include the reported value, its rate of change, data from correlated sensors, and recent operator activity, allowing for a holistic and high-confidence classification of incoming alerts.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Windows Application Event Logs
      - Windows Security Event ID 4624
      - HMI workstations, Engineering Workstations, SCADA servers, and the Level 2 Supervisory Control network where operator actions and alarms are logged.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Supervised Alarm Classification
          TRAIN Random Forest model on historical data (value, rate_of_change, correlated_values, operator_activity) labeled as 'true alarm' or 'normal'
          DEPLOY trained model
          FOR each new critical alert
            PREDICT 'likely spoofed' or 'likely authentic' using the model
            IF prediction is 'likely spoofed'
              ALERT "ML model classified alarm as likely spoofed"
  - question: Has there been a sudden, high-volume flood of alarms from the central alarm server, indicative of an 'alarm flood' attack?
    context: |
      This question addresses the 'alarm fatigue' tactic, where an adversary overwhelms operators with numerous, often low-priority, alarms to distract them from a real, concurrent event. This is a simple but effective detection that counts the number of alarm events within a short time window. Exceeding a defined threshold suggests a coordinated event rather than random, unrelated process issues.
    answer_sources:
      - Windows Application Event Logs
      - Zeek conn.log
      - Zeek dnp3.log
      - Central Alarm Servers, Process Historian, HMI workstations, and the Level 2 Supervisory Control Network.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Alarm Flood Detection
          MONITOR Windows Application Log on central alarm server
          COUNT distinct alarm events over a 5-minute sliding window
          IF count > threshold (e.g., 20)
            ALERT "Potential alarm flood condition detected"
  - question: Is the variety of devices generating alarms suddenly increasing, suggesting a coordinated, widespread event rather than a localized process issue?
    context: |
      This question uses information theory to detect an alarm flood. In normal operations, alarms typically come from a predictable subset of devices. An alarm flood attack might involve sending spoofed alarms from many different devices simultaneously. This increase in the randomness and variety of alarm sources will cause a spike in the Shannon entropy of the source IP addresses, providing a clear signal of an anomalous, distributed event.
    answer_sources:
      - Windows Application Event Logs
      - Zeek conn.log
      - Zeek dnp3.log
      - Central Alarm Servers, Process Historian, HMI workstations, and the Level 2 Supervisory Control Network.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Alarm Source Entropy
          CALCULATE historical baseline for Shannon entropy of alarm source IPs (from Zeek logs)
          OVER a 10-minute sliding window
            CALCULATE current entropy of alarm source IPs
            IF current entropy > 98th percentile of baseline
              ALERT "Anomalous spike in alarm source variety"
  - question: Can unsupervised clustering identify an anomalous group of alarms that share characteristics of a distraction attack (e.g., simultaneous, low-priority, from disparate sources)?
    context: |
      This question applies unsupervised machine learning to find patterns within alarm data itself. A clustering algorithm like DBSCAN can group events based on their properties (time, source, priority) without prior training. A distraction attack would likely create a dense cluster of alarms that are close in time but far apart in terms of source device and have low priority. DBSCAN would identify this as an anomalous cluster, distinct from normal operational alarm patterns.
    answer_sources:
      - Windows Application Event Logs
      - Zeek conn.log
      - Zeek dnp3.log
      - Central Alarm Servers, Process Historian, HMI workstations, and the Level 2 Supervisory Control Network.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Alarm Clustering Analysis
          COLLECT alarm events with features (timestamp, device_ID, priority)
          APPLY DBSCAN clustering algorithm
          IDENTIFY clusters with high density, low priority, and high variance in device_ID
          IF such a cluster is found
            ALERT "Anomalous cluster of alarms detected, possible distraction attack"
  - question: Has a command been issued to put a process into a high-risk state while the associated safety system sensor fails to report the expected corresponding change?
    context: |
      This is a critical logic-based check to detect a safety system bypass. If an adversary sends a command to, for example, open a valve to a dangerous level, the associated safety system (e.g., a pressure sensor) should react. If the command is sent, but the safety sensor's value remains unchanged (because it's being fed a spoofed 'all-clear' signal), it means the safety system is blind to the danger. This rule directly encodes that critical process logic.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek conn.log
      - Network segments monitoring Safety Instrumented Systems (SIS), network taps between PLCs and SIS controllers, and the Process Historian.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Safety Bypass Logic Rule
          ON control command to high-risk device
            LET expected_safety_sensor_change = ... # from engineering logic
            MONITOR associated safety sensor log for expected change within time window
            IF expected change does NOT occur
              ALERT "CRITICAL: Potential safety system bypass detected"
  - question: Are the heartbeat messages from critical safety systems exhibiting unnaturally perfect timing (near-zero jitter), suggesting a replay attack?
    context: |
      This question targets a subtle indicator of a sophisticated replay attack. Real-world network communications always have some small, random variations in timing (jitter). A replay attack, however, might involve re-transmitting a captured 'healthy' heartbeat message at perfect intervals. This results in a jitter value that is unnaturally low, often approaching zero. Detecting this lack of natural randomness is a strong sign that the heartbeat signal is not authentic.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek conn.log
      - Network segments monitoring Safety Instrumented Systems (SIS), network taps between PLCs and SIS controllers, and the Process Historian.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Heartbeat Jitter Analysis
          FOR each SIS device heartbeat message
            CALCULATE historical baseline of inter-arrival time jitter
            OVER a 1-hour window
              CALCULATE current jitter
              IF current jitter is below 1st percentile of baseline (near zero)
                ALERT "Unnaturally low jitter in SIS heartbeat, possible replay attack"
  - question: Is there a significant divergence between the forecasted value of a safety sensor (based on a related, trusted variable) and the actual value it is reporting?
    context: |
      This question uses a forecasting model to create a 'virtual sensor' to check against a real one. By modeling a trusted, related variable (e.g., fuel flow rate), we can predict what a dependent safety sensor's value *should* be (e.g., temperature). If the actual reported temperature significantly deviates from this physics-based forecast, it implies the sensor is not reporting the true value and may be spoofed to hide a dangerous condition.
    answer_sources:
      - Zeek dnp3.log
      - Zeek modbus.log
      - Zeek conn.log
      - Network segments monitoring Safety Instrumented Systems (SIS), network taps between PLCs and SIS controllers, and the Process Historian.
    range: last 90 days
    queries:
      - technology: pseudocode
        query: |
          # Physics-Based Forecasting
          TRAIN ARIMA model to forecast safety sensor value based on a related, trusted variable
          IN real-time
            FORECAST expected safety sensor value
            COMPARE forecast to actual reported value
            IF prediction error exceeds dynamic threshold for > 60 seconds
              ALERT "Reported safety sensor value violates physics-based forecast"