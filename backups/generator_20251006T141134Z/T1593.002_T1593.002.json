[
  {
    "information_requirement": "Is the adversary using search engines to find exploitable information about our organization? (PIR)",
    "tactic_id": "TA0043",
    "tactic_name": "Reconnaissance",
    "indicators": [
      {
        "technique_id": "T1593.002",
        "name": "Search Engines",
        "evidence": [
          {
            "description": "A result from a public search engine query that indexes a document or web page containing sensitive organizational data, identified by matching keywords (e.g., 'password', 'confidential', 'internal-only'), file types (e.g., '.config', '.sql', '.pem'), or patterns (e.g., API keys, internal hostnames) associated with the organization's domains.",
            "data_sources": [
              "External Search Engine API Query Results"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Public-facing websites and web applications, public code repositories (e.g., GitHub, GitLab), public cloud storage (e.g., S3 buckets, Azure blobs), and public paste sites (e.g., Pastebin) indexed by search engines.",
            "action": [
              "Execute automated queries (dorks) against public search engine APIs (e.g., Google, Bing, Shodan) using a watchlist of high-risk keywords ('password', 'secret', 'api_key'), sensitive file extensions ('pem', 'sql', 'config'), and internal hostnames or IP ranges. Trigger an alert for any direct match returned in the search results.",
              "For each discovered public document, calculate a risk score based on the weighted frequency of sensitive keyword matches. Establish a statistical baseline for 'normal' public document content for your organization. Flag any document whose risk score exceeds the 95th percentile of this baseline for manual review.",
              "Deploy a pre-trained text classification model (e.g., Naive Bayes, BERT) to categorize discovered documents as 'sensitive,' 'technical,' or 'benign.' Train the model using a labeled dataset of known sensitive data leaks and approved public marketing materials. Generate an alert for any document classified as 'sensitive' with a confidence score above a predefined threshold (e.g., 0.90)."
            ]
          },
          {
            "description": "A process creation event (Windows Event ID 4688) on a server or non-developer workstation that executes a command-line download utility (e.g., `curl.exe`, `wget.exe`, `bitsadmin.exe`, `certutil.exe`) with a URL argument pointing to a non-corporate, non-whitelisted domain, potentially to retrieve adversary tools or scripts discovered via reconnaissance.",
            "data_sources": [
              "Windows Event ID 4688",
              "Zeek http.log",
              "Zeek files.log",
              "Zeek conn.log"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Domain Controllers, database servers, application servers, non-developer user workstations, and DMZ-hosted servers.",
            "action": [
              "Monitor for process creation events (Windows Event ID 4688) where ProcessName is one of ('curl.exe', 'wget.exe', 'bitsadmin.exe', 'certutil.exe') and the CommandLine contains a URL. Correlate the destination IP from the URL (via Zeek conn.log) against a threat intelligence feed of known malicious domains. Trigger an alert on any match.",
              "For each host, establish a baseline of command-line download utility usage over a 30-day period. Calculate the rarity of each utility's execution per host and per user. Flag any execution on a server or by a non-privileged user that is statistically rare (e.g., its execution frequency is in the bottom 5th percentile for that host/user group), indicating an unusual behavior.",
              "Train a logistic regression model to predict the probability of a download being malicious. Use features such as: host role (server, workstation), user privileges, process name, domain age and reputation of the source URL (from enrichment), and time of day. Generate an alert for any download event where the model's predicted probability exceeds a defined risk threshold (e.g., 0.85)."
            ]
          },
          {
            "description": "A series of inbound HTTP requests to a public-facing web server from a single external IP address, where the `Referer` header contains a search engine URL incorporating advanced search operators (dorks) and the request rate or error rate is anomalous.",
            "data_sources": [
              "Zeek http.log",
              "Zeek conn.log"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Network ingress points (firewalls, load balancers), public-facing web server farms, and reverse proxy servers.",
            "action": [
              "Parse the `Referer` header from inbound `Zeek http.log` records. Match the query string against a regex pattern or list of known 'dorking' operators and keywords (e.g., 'filetype:', 'inurl:admin', 'intitle:index of', 'site:'). Trigger an alert for any match originating from an external source IP.",
              "For each external source IP, calculate the Shannon entropy of requested URIs and the ratio of HTTP 4xx client error codes to HTTP 2xx success codes within a 5-minute window. Establish a baseline for these metrics across all traffic. Generate an alert when an IP's URI entropy and 4xx/2xx ratio both exceed the 98th percentile of their respective baselines, indicating targeted enumeration.",
              "Implement a time-series forecasting model (e.g., ARIMA) on `Zeek conn.log` data, aggregated by source IP, to predict the expected volume of requests originating from known search engine referrers. Trigger an alert when the actual traffic volume from a single IP significantly deviates from the predicted volume (e.g., exceeds the 99% confidence interval), suggesting a large-scale, automated reconnaissance campaign."
            ]
          },
          {
            "description": "An outbound HTTP GET request from an internal host to an external URL that is present on a watchlist of known sensitive data exposures previously identified through external reconnaissance, indicating an internal user or compromised host is accessing the leaked data.",
            "data_sources": [
              "Zeek http.log",
              "Zeek dns.log",
              "Zeek conn.log"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Network egress points, forward proxy server logs, DNS resolver logs, and user workstations subnets.",
            "action": [
              "Maintain a dynamic watchlist of URLs known to host leaked corporate data, populated from external reconnaissance findings. Create a rule to generate a high-severity alert when an outbound request in `Zeek http.log` has a `host` and `uri` field that exactly matches an entry on the watchlist.",
              "For all outbound web traffic, calculate the Jaccard similarity between the requested URL and each URL on the sensitive data watchlist. While an exact match is a high-fidelity alert, a high similarity score (e.g., > 0.85) may indicate access to a related resource on the same compromised site. Flag high-similarity requests for investigation.",
              "Employ an anomaly detection model (e.g., Isolation Forest) on features derived from outbound web traffic per user from `Zeek http.log` and `dns.log`. Use features like requested domain reputation, destination site category, historical access frequency by the user and their peers, and DNS query characteristics. Use the model to flag access requests to leaked data URLs as anomalous, even if the specific URL is previously unseen, based on characteristics that deviate from the user's established browsing behavior."
            ]
          }
        ]
      }
    ],
    "last_updated": "2025-09-30",
    "version": "2.3",
    "date_created": "2025-05-04",
    "contributors": [
      "Zachary Szewczyk",
      "Ask Sage"
    ]
  }
]