[
  {
    "information_requirement": "Is the adversary maintaining persistence by adding roles to a compromised cloud account?",
    "tactic_id": "TA0003",
    "tactic_name": "Persistence",
    "indicators": [
      {
        "technique_id": "T1098.003",
        "name": "Additional Cloud Roles",
        "evidence": [
          {
            "description": "An IAM policy modification event is observed where the source IP address or User-Agent string matches known-bad indicators, or is statistically rare for the actor.",
            "data_sources": [
              "AWS CloudTrail logs",
              "Azure Activity Logs",
              "Google Cloud Audit Logs",
              "Zeek conn.log"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Cloud IAM control plane; Network gateways and firewalls; Threat intelligence platforms.",
            "action": "1. (Symbolic) Ingest CTI feeds of malicious IPs and User-Agent strings. Create a SIEM rule to alert when a cloud API call (e.g., AWS:CreatePolicyVersion, Azure:CreateOrUpdatePolicyDefinition) has a sourceIP or userAgent that matches the CTI list. 2. (Statistical) For each administrator, baseline their source ASN and User-Agent strings. Calculate the rarity of each. Alert when a modification event originates from an ASN or User-Agent in the bottom 5th percentile of frequency for that user. 3. (ML) Train a classification model (e.g., Random Forest) on features from IAM modification events (source IP, ASN, country, user, user-agent, time of day). Use the model to score each new event's likelihood of being malicious and alert on high scores."
          },
          {
            "description": "A policy is attached to a user, group, or role that allows the principal to modify its own permissions, creating a self-perpetuating persistence mechanism.",
            "data_sources": [
              "AWS CloudTrail logs",
              "Azure Activity Logs",
              "Google Cloud Audit Logs"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Cloud IAM control plane; Cloud configuration management database (CMDB).",
            "action": "1. (Symbolic) Create and maintain a watchlist of 'self-modification' permissions (e.g., 'iam:CreatePolicyVersion', 'iam:SetDefaultPolicyVersion', 'iam:AttachUserPolicy'). Alert whenever a policy containing these permissions is attached to a principal. 2. (Statistical) Analyze the 'permission entropy' of policies. High-entropy policies (those with a wide variety of disparate, powerful permissions) are anomalous. Establish a baseline for policy entropy and alert when a newly attached policy's entropy exceeds the 98th percentile. 3. (ML) Model your IAM environment as a directed graph (principals and resources are nodes, permissions are edges). Use a graph algorithm to detect any permission assignment that creates a cycle, allowing a node to modify its own inbound edges. Alert on any detected cycles."
          },
          {
            "description": "A role with high-privilege access is assigned to a dormant, newly created, or external (non-federated) account.",
            "data_sources": [
              "AWS CloudTrail logs",
              "Azure Activity Logs",
              "Windows Event ID 4624"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Cloud IAM control plane; Identity Provider (IdP) logs; User activity and authentication logs.",
            "action": "1. (Symbolic) Create a SIEM rule that triggers when a high-privilege role (from a predefined list) is assigned to an account that was created < 72 hours ago, or to an account whose domain is not on an approved list of federated domains. 2. (Statistical) For all active accounts, baseline their last activity timestamp. Define 'dormant' as no activity for > 90 days. Alert if a role assignment targets an account that is flagged as dormant. 3. (ML) Use time-series analysis on user activity logs to forecast expected activity. An alert is generated when a high-privilege role is assigned to an account whose recent activity is a significant negative outlier compared to its forecast, indicating dormancy."
          },
          {
            "description": "An administrative account performs an anomalously high number of role or policy modifications in a short period or at an unusual time.",
            "data_sources": [
              "AWS CloudTrail logs",
              "Azure Activity Logs",
              "Zeek conn.log",
              "Windows Event ID 4624"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Cloud IAM control plane; Endpoints used by privileged administrators; VPN and remote access gateways.",
            "action": "1. (Symbolic) Implement a simple threshold rule to alert if any single user principal performs > 10 IAM modification API calls within a 60-minute window. 2. (Statistical) For each administrator, establish a baseline of modification activity (count per hour, per day). Use descriptive statistics to alert when an administrator's activity exceeds 3 standard deviations above their individual mean for a given hour. 3. (ML) Use a time-series decomposition model to establish a baseline of activity for each user, accounting for seasonality (e.g., time of day, day of week). Alert when a burst of activity is detected as an anomaly that cannot be explained by seasonal patterns."
          }
        ]
      }
    ],
    "version": "2.2",
    "date_created": "2025-05-04",
    "last_updated": "2025-09-29",
    "contributors": [
      "Zachary Szewczyk",
      "Ask Sage"
    ]
  },
  {
    "information_requirement": "Has the adversary escalated privileges by assigning powerful roles to a controlled account?",
    "tactic_id": "TA0004",
    "tactic_name": "Privilege Escalation",
    "indicators": [
      {
        "technique_id": "T1098.003",
        "name": "Additional Cloud Roles",
        "evidence": [
          {
            "description": "A new IAM role or policy is created with a name or description that is an exact or near-match to known malicious indicators.",
            "data_sources": [
              "AWS CloudTrail logs",
              "Azure Activity Logs",
              "Google Cloud Audit Logs"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Cloud IAM control plane; Threat intelligence platform.",
            "action": "1. (Symbolic) Scan the 'roleName' and 'policyName' parameters of all IAM creation events against a CTI watchlist of known-bad names (e.g., 'backdoor_policy', 'AWSUpdate'). Alert on any exact match. 2. (Statistical) For each new role/policy name, calculate the Levenshtein distance to all names on the CTI watchlist. Alert if the normalized distance is below a threshold (e.g., < 0.2), indicating a close misspelling or variation. 3. (ML) Train an NLP classifier on thousands of known-good and known-bad role/policy names. Use the model to classify each new name as 'benign,' 'suspicious,' or 'malicious' based on its characteristics and alert on the latter two."
          },
          {
            "description": "An account is granted a specific combination of permissions that completes a known privilege escalation path.",
            "data_sources": [
              "AWS CloudTrail logs",
              "Azure Activity Logs",
              "Google Cloud Audit Logs"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Cloud IAM control plane; Cloud security posture management (CSPM) tools.",
            "action": "1. (Symbolic) Codify known privilege escalation paths (e.g., in AWS, the combination of 'iam:PassRole' and 'ec2:RunInstances') into SIEM rules. The rule should trigger when a policy modification results in a single principal possessing all permissions required to complete a path. 2. (Statistical) Assign a risk score to each individual IAM permission. Calculate a cumulative risk score for a principal's effective permissions after any change. Alert if the change causes the principal's risk score to jump into the 99th percentile of all principals. 3. (ML) Use a graph-based analysis tool (e.g., BloodHound, Cloudsplaining) to periodically model the IAM environment. Train a model to recognize the graph structure of known escalation paths. Alert when a policy change creates a new instance of a malicious graph pattern."
          },
          {
            "description": "A non-administrative account is granted IAM write permissions, enabling it to alter the access control configuration.",
            "data_sources": [
              "AWS CloudTrail logs",
              "Azure Activity Logs",
              "Google Cloud Audit Logs"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Cloud IAM control plane; User and group definitions in IdP.",
            "action": "1. (Symbolic) Maintain a list of non-administrative users and groups. Create a rule to alert any time a permission containing 'iam:*', 'iam:Put*', 'iam:Attach*', 'iam:Detach*', or 'Microsoft.Authorization/*/write' is granted to a principal on this list. 2. (Statistical) For each job role (e.g., 'Developer', 'DataAnalyst'), create a baseline set of common permissions. When a permission is granted to a user, calculate the Jaccard similarity index between their new permission set and their role's baseline. Alert if the score is anomalously low, indicating a deviation from role norms. 3. (ML) Use a clustering algorithm (e.g., DBSCAN) to group users based on their permission sets. An alert is triggered if a permission grant causes a user to move from a large, well-defined cluster (e.g., 'developers') to a small, high-privilege cluster or become a noise point (outlier)."
          },
          {
            "description": "An account, after receiving new permissions, immediately performs high-impact actions that were previously denied.",
            "data_sources": [
              "AWS CloudTrail logs",
              "Azure Activity Logs",
              "AWS S3 access logs",
              "Google Cloud Storage logs"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Cloud IAM control plane; Sensitive data stores (S3 buckets, databases); Compute and container services.",
            "action": "1. (Symbolic) Create a two-stage rule: Stage 1 triggers on any IAM policy modification. Stage 2 triggers if the same principal, within 15 minutes, successfully executes a high-impact API call (from a watchlist, e.g., 's3:GetObject', 'iam:CreateAccessKey') that was previously failing with an 'AccessDenied' error. 2. (Statistical) For each principal, monitor the rate of 'AccessDenied' errors over time. Alert if a policy modification event is immediately followed by a statistically significant drop in the 'AccessDenied' rate and a corresponding spike in successful, sensitive API calls. 3. (ML) Use a sequence-to-sequence model (e.g., LSTM autoencoder) to learn normal sequences of API calls for each user. Feed real-time API call sequences into the model. An alert is generated if a policy modification is followed by a sequence of calls that results in a high reconstruction error, indicating the model considers the new behavior anomalous."
          }
        ]
      }
    ],
    "version": "2.2",
    "date_created": "2025-05-04",
    "last_updated": "2025-09-29",
    "contributors": [
      "Zachary Szewczyk",
      "Ask Sage"
    ]
  }
]