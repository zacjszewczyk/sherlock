[
  {
    "information_requirement": "Has the adversary elevated privileges using VDSO hijacking?",
    "tactic_id": "TA0004",
    "tactic_name": "Privilege Escalation",
    "indicators": [
      {
        "technique_id": "T1055.014",
        "name": "VDSO Hijacking",
        "evidence": [
          {
            "description": "An executable file is executed whose file hash matches a known VDSO hijacking tool or malware sample from threat intelligence feeds.",
            "data_sources": [
              "auditd logs",
              "osquery file_hash",
              "EDR process creation logs"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Critical Linux servers (e.g., web servers, database servers, authentication servers), Linux developer workstations, Production container environments",
            "action": [
              "Symbolic Logic: Continuously compare file hashes from process execution events (e.g., auditd `execve` records) against a curated list of known malicious hashes from threat intelligence specific to VDSO hijacking tools. Generate a high-severity alert upon a match.",
              "Statistical Method: For each executed file hash, calculate its prevalence across the entire environment. Flag executions where the file hash is present on fewer than 1% of endpoints or has never been seen before. A low prevalence score for a newly executed file indicates a statistical anomaly requiring investigation.",
              "Machine Learning Application: Train a classification model (e.g., Gradient Boosting, Random Forest) on file metadata features (e.g., file size, entropy, string analysis, import/export tables) from both benign and known malicious executables. Use the model to score all new executables to predict the probability of them being malicious tools associated with process injection."
            ]
          },
          {
            "description": "A lower-privileged process executes a ptrace attach, memory map read, and memory write sequence of system calls against a higher-privileged process within a short time window.",
            "data_sources": [
              "auditd logs",
              "eBPF trace data",
              "Falco logs"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Critical Linux servers, Privileged user accounts, Core system daemons (e.g., sshd, cron)",
            "action": [
              "Symbolic Logic: Implement a stateful detection rule that triggers when a single source process (by PID) targeting a single destination process performs the following syscall sequence: 1) `ptrace(PTRACE_ATTACH)`, 2) `openat` on `/proc/[target_pid]/maps`, and 3) `ptrace(PTRACE_POKEDATA)` or `mmap`. The rule should only trigger if the source process has lower privileges than the target process.",
              "Statistical Method: For each process type (e.g., nginx, java), model its typical syscall sequences using a Markov chain to establish transition probabilities between syscalls. A sequence of syscalls with a joint probability below a dynamically calculated threshold (e.g., 1st percentile) is flagged as anomalous, particularly if it involves `ptrace`.",
              "Machine Learning Application: Utilize a sequence-based Recurrent Neural Network (RNN) or LSTM model trained on benign syscall traces from across the environment. Feed real-time syscall sequences into the model and measure the prediction error. A significant spike in error indicates a deviation from normal behavior, suggesting a potential hijacking attempt."
            ]
          },
          {
            "description": "A high-privilege process, immediately following a ptrace event targeting it, spawns an anomalous child process or accesses sensitive system configuration files.",
            "data_sources": [
              "auditd logs",
              "osquery process_events"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "System configuration directories (e.g., /etc/, /root/), Authentication-related files (e.g., /etc/shadow, /etc/sudoers), Privileged processes on critical servers",
            "action": [
              "Symbolic Logic: Create a correlation alert that triggers if a process (e.g., `httpd`) is the target of a `ptrace` call, and within the next 60 seconds, that same process PID spawns a shell (e.g., `/bin/sh`, `/bin/bash`) or opens `/etc/shadow` for writing.",
              "Statistical Method: For each privileged process, build a historical baseline of normal child process names and file access paths. Calculate a rarity score for any new child process or file access event post-`ptrace`. If the behavior falls in the 99.9th percentile of rarity for that process, flag it for investigation.",
              "Machine Learning Application: Employ a one-class SVM or Isolation Forest model to create a behavioral profile for each critical, high-privilege process based on features like child processes, file paths accessed, and user context. Any activity from a process that is flagged as an outlier by the model, especially after being targeted by `ptrace`, indicates a likely compromise."
            ]
          },
          {
            "description": "A system call from a monitored process is redirected to a memory address within user-space memory instead of the expected kernel or vDSO regions.",
            "data_sources": [
              "eBPF trace data",
              "Kernel module logging"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Kernel memory space on critical Linux hosts, vDSO memory region of running processes",
            "action": [
              "Symbolic Logic: Using an eBPF probe attached to a kernel tracepoint like `sys_enter`, inspect the instruction pointer. If the address is outside the known, valid memory range for the kernel and the process's mapped vDSO, generate an immediate, high-priority alert as this is a direct sign of a hijack.",
              "Statistical Method: For each critical process, calculate the entropy of syscall handler addresses over 1-minute windows. A baseline entropy should be very low (ideally zero). A sudden increase in entropy indicates that syscalls are being redirected to multiple, potentially malicious, locations. Alert if entropy increases by more than 2 standard deviations.",
              "Machine Learning Application: Apply a clustering algorithm (e.g., DBSCAN) to the set of all observed syscall handler addresses for a given process name across the fleet. Normal handlers in the kernel and vDSO will form one or more dense clusters. Any address that is classified as a noise point by the algorithm is a strong candidate for a malicious, user-space hook."
            ]
          }
        ]
      }
    ],
    "version": "2.2",
    "date_created": "2025-05-04",
    "last_updated": "2025-09-30",
    "contributors": [
      "Zachary Szewczyk",
      "Ask Sage"
    ]
  },
  {
    "information_requirement": "Is the adversary evading defenses using VDSO hijacking?",
    "tactic_id": "TA0005",
    "tactic_name": "Defense Evasion",
    "indicators": [
      {
        "technique_id": "T1055.014",
        "name": "VDSO Hijacking",
        "evidence": [
          {
            "description": "A memory scan of a security process (e.g., EDR agent, auditd) reveals memory segments with executable permissions that do not map to a known on-disk binary, or match signatures of vDSO hooks.",
            "data_sources": [
              "Live memory dumps",
              "Yara scan logs",
              "osquery memory_map"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Memory space of security tools (EDR, auditd, AV) on critical Linux hosts and developer workstations",
            "action": [
              "Symbolic Logic: Periodically perform memory scans on security agent processes (e.g., `auditd`, `osqueryd`) using YARA rules designed to find vDSO hook signatures, shellcode patterns, or pointers to unexpected user-space memory. An alert on any match indicates likely tampering.",
              "Statistical Method: For each security process, establish a baseline for its memory map, specifically the count of executable memory segments. Monitor for deviations. An increase in the number of executable segments beyond 3 standard deviations from the mean suggests code injection.",
              "Machine Learning Application: Train a classifier on features extracted from process memory segments (e.g., entropy, size, permissions, proximity to other segments) to distinguish between benign library code and injected malicious code. Apply this model in real-time to memory segments of security tools to detect anomalies indicative of hijacking."
            ]
          },
          {
            "description": "A security tool process (e.g., auditd) is targeted by a ptrace attach call, immediately followed by write or delete operations on its own configuration or log files.",
            "data_sources": [
              "auditd logs",
              "eBPF trace data"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "File system paths for security tool configurations and logs (e.g., /etc/audit/, /var/log/audit/, /opt/edr/)",
            "action": [
              "Symbolic Logic: Create a critical alert for the sequence: 1) `ptrace(PTRACE_ATTACH)` syscall targeting a known security process (e.g., `auditd`, `rsyslogd`), followed within 30 seconds by 2) an `openat` or `unlinkat` syscall from any process that targets a file in that security tool's configuration or log directory.",
              "Statistical Method: The rate of `ptrace` calls targeting security processes in a healthy environment is zero. Establish a baseline count of these events per hour (which should be 0). Any event that causes this count to be greater than zero is a statistically significant anomaly and should be alerted on.",
              "Machine Learning Application: Model process and file interactions as a graph. Use a graph-based anomaly detection algorithm to learn the normal interaction patterns. An edge representing a `ptrace` call from an unexpected process to a security agent node, or a `write` edge from a hijacked process to a log file node, would be identified as a structural anomaly."
            ]
          },
          {
            "description": "A legitimate system process, after being targeted by a ptrace call, initiates network connections with beaconing characteristics or to a destination IP with low prevalence.",
            "data_sources": [
              "Zeek conn.log",
              "Zeek dns.log",
              "auditd logs"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Network egress points (firewalls, proxies), DNS servers, Critical Linux servers",
            "action": [
              "Symbolic Logic: Correlate `auditd logs` showing a `ptrace` event with subsequent `Zeek conn.log` entries from the same source host IP. If the process targeted by `ptrace` initiates an outbound connection to an IP address present on a threat intelligence feed of C2 servers, trigger a high-severity alert.",
              "Statistical Method: After a `ptrace` event is noted for a process, analyze its subsequent network connections in `Zeek conn.log`. Calculate the time delta between connections to the same destination IP/port. A low standard deviation in these time deltas indicates periodic beaconing. Additionally, flag connections to destination IPs that are in the bottom 1st percentile of prevalence across the enterprise.",
              "Machine Learning Application: For critical processes, use a time series forecasting model (e.g., ARIMA) to predict expected outbound data volume (`orig_bytes` in `conn.log`). If a `ptrace` event occurs, and the subsequent actual data volume significantly exceeds the forecasted volume's confidence interval, flag it as a potential C2 channel or data exfiltration."
            ]
          },
          {
            "description": "The volume of security logs from a host drops significantly or stops entirely, immediately following a ptrace call targeting a logging daemon on that host.",
            "data_sources": [
              "SIEM internal performance logs",
              "auditd logs",
              "Heartbeat data from log forwarders"
            ],
            "data_platforms": [
              "TBD"
            ],
            "nai": "Log aggregation platform (SIEM), Logging daemons (auditd, rsyslogd, journald) on all Linux hosts",
            "action": [
              "Symbolic Logic: Create a dedicated, high-priority alert that triggers if a `ptrace` syscall is ever observed targeting a known logging daemon process, such as `auditd`, `rsyslogd`, or `journald`. This action is unequivocally malicious.",
              "Statistical Method: On the central log aggregator (SIEM), monitor the events-per-second (EPS) rate for each reporting host. Establish a moving average and standard deviation. If a host's EPS drops more than 3 standard deviations below its baseline for a sustained period (e.g., 5 minutes), generate an alert for a potential offline or tampered sensor.",
              "Machine Learning Application: Employ a time series anomaly detection model (e.g., an autoencoder) on the log volume data for each host. The model learns the host's normal logging rhythm (including periods of low activity). An anomalous drop flagged by the model, when correlated with a recent `ptrace` event on the host, strongly indicates targeted log tampering."
            ]
          }
        ]
      }
    ],
    "version": "2.2",
    "date_created": "2025-05-04",
    "last_updated": "2025-09-30",
    "contributors": [
      "Zachary Szewczyk",
      "Ask Sage"
    ]
  }
]