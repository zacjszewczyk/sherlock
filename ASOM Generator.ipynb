{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bMTjh8St9lq"
   },
   "source": [
    "# Analytic Scheme of Maneuver Generator\n",
    "\n",
    "This notebook uses analytic plans to generate an analytic scheme of maneuver.\n",
    "\n",
    "## Background\n",
    "\n",
    "As described in TC 3-12.2.4.1, \"The Analytic Scheme of Maneuver is the plan to collect and analyze technical data to meet specific information requirements. It identifies what data to analyze, how to analyze it, and why it is being analyzed.\" The analytic scheme of maneuver, or ASOM, consists of the following components:\n",
    "\n",
    "* **Priority information requirement**:\n",
    "* **Indicator**:\n",
    "* **Evidence**:\n",
    "* **Data**:\n",
    "* **NAI**:\n",
    "* **Analytic**:\n",
    "\n",
    "\n",
    "\n",
    "## Environment Setup\n",
    "\n",
    "This section sets up the environment. It installs packages necessary to generate the analytic plans, imports modules, initializes helper functions, and finally defines global variables. This section also mounts Google Drive to the runtime and moves into the project folder.\n",
    "\n",
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10613,
     "status": "ok",
     "timestamp": 1752686185506,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "oEPZ2nM0t9ls",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install -U -q \"google\" 1> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cVdZHRPYQ2Kg"
   },
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1752686185948,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "W6lw6d8_usYi"
   },
   "outputs": [],
   "source": [
    "# from google.colab import userdata\n",
    "# from google.colab import drive\n",
    "import json\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhqL4Wb1Q2Kh"
   },
   "source": [
    "### Initialize Helper Functions\n",
    "\n",
    "The first function, `log`, logs a message to the console prepended with the current timestamp in the ISO8601 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1752686185975,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "6jbJGnYHg5I5"
   },
   "outputs": [],
   "source": [
    "def log(message, end=\"\\n\", flush = True):\n",
    "    \"\"\"\n",
    "    Logs a message to the console, prepended with the current timestamp\n",
    "    in ISO 8601 format.\n",
    "\n",
    "    Args:\n",
    "    message (str): The string message to log.\n",
    "    \"\"\"\n",
    "\n",
    "    # Access the global flag controlling verbosity\n",
    "    global verbose\n",
    "\n",
    "    # Get the current date and time\n",
    "    current_time = datetime.datetime.now()\n",
    "\n",
    "    # Format the timestamp in ISO 8601 format\n",
    "    timestamp = current_time.isoformat()\n",
    "\n",
    "    # Construct the final log string using an f-string for clean formatting\n",
    "    log_string = f\"[{timestamp}] {message}\"\n",
    "\n",
    "    # Print the log string to the console if logging is turned on (verbose = True)\n",
    "    if (verbose == True):\n",
    "        print(log_string, end = end, flush = flush)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9H36gENw6DN_"
   },
   "source": [
    "The second function, `build_asom`, accepts a series of MITRE ATT&CK techniques as input and returns a collection of analytic plans that correspond to those techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752686185981,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "kCIRqedzUoF7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Set, Any, Tuple\n",
    "\n",
    "TACTIC_ID_PATTERN = re.compile(r'^(?P<tactic_id>[A-Z0-9]{2,}-?[A-Z0-9]{0,})')\n",
    "# Technique IDs: MITRE (T#### or T####.###) OR D3-* style identifiers\n",
    "TECHNIQUE_ID_PATTERN = re.compile(r'^(?P<tech_id>T\\d{4}(?:\\.\\d{3})?|D3-[A-Z]+)')\n",
    "\n",
    "def _normalize_tactic_key(tactic: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Accepts strings like:\n",
    "        \"TA0001 - Initial Access\"\n",
    "        \"D3-D - Detect\"\n",
    "        \"TA0001\"\n",
    "    Returns (tactic_id, tactic_name_or_empty).\n",
    "    \"\"\"\n",
    "    if \" - \" in tactic:\n",
    "        tid, name = tactic.split(\" - \", 1)\n",
    "        return tid.strip(), name.strip()\n",
    "    return tactic.strip(), \"\"\n",
    "\n",
    "def _normalize_technique_id(tech: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract technique ID from various accepted forms:\n",
    "      \"T1055\"\n",
    "      \"T1055.009\"\n",
    "      \"T1055.009 - Process Injection\"\n",
    "      \"D3-NTA - Network Traffic Analysis\"\n",
    "      \"D3-PM\"\n",
    "    Returns the normalized ID or empty string if not found.\n",
    "    \"\"\"\n",
    "    m = TECHNIQUE_ID_PATTERN.match(tech.strip())\n",
    "    return m.group(\"tech_id\") if m else \"\"\n",
    "\n",
    "def _load_json_safely(path: Path) -> Any:\n",
    "    \"\"\"\n",
    "    Loads JSON; strips code fences if present.\n",
    "    Returns parsed object or raises.\n",
    "    \"\"\"\n",
    "    text = path.read_text(encoding=\"utf-8\").strip()\n",
    "    if text.startswith(\"```\"):\n",
    "        # Remove fenced code markers (``` or ```json)\n",
    "        text = re.sub(r'^```(?:json)?\\s*', '', text)\n",
    "        text = re.sub(r'\\s*```$', '', text)\n",
    "    return json.loads(text)\n",
    "\n",
    "def _is_new_schema_object(obj: dict) -> bool:\n",
    "    required = {\"information_requirement\", \"tactic_id\", \"tactic_name\", \"indicators\"}\n",
    "    return isinstance(obj, dict) and required.issubset(obj.keys())\n",
    "\n",
    "def _filter_indicators(ir_obj: dict, allowed_ids: Set[str]) -> dict:\n",
    "    \"\"\"\n",
    "    Return a *new copy* of ir_obj with indicators filtered to those whose technique_id\n",
    "    is in allowed_ids. If allowed_ids is empty, returns ir_obj unchanged.\n",
    "    \"\"\"\n",
    "    if not allowed_ids:\n",
    "        return ir_obj  # no filtering requested\n",
    "\n",
    "    new_obj = copy.deepcopy(ir_obj)\n",
    "    new_indicators = [\n",
    "        ind for ind in new_obj.get(\"indicators\", [])\n",
    "        if _normalize_technique_id(ind.get(\"technique_id\", \"\")) in allowed_ids\n",
    "    ]\n",
    "    new_obj[\"indicators\"] = new_indicators\n",
    "    return new_obj\n",
    "\n",
    "def build_asom(\n",
    "    attack_chain: Dict[str, List[str]],\n",
    "    directory: str | Path = \".\",\n",
    "    detect_filename: str = \"D3-D - Detect.json\",\n",
    "    include_detect_first: bool = True,\n",
    "    filter_indicators: bool = True,\n",
    "    deduplicate: bool = True\n",
    ") -> List[dict]:\n",
    "    \"\"\"\n",
    "    Build an ASOM (list of IR objects in the *new* analytic plan schema) filtered\n",
    "    by the provided attack_chain.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attack_chain : dict\n",
    "        Mapping of tactic strings -> list of technique strings.\n",
    "        Tactic strings can be 'TA0001 - Initial Access' or just 'TA0001'.\n",
    "        Techniques can be:\n",
    "            'T1078'\n",
    "            'T1078 - Valid Accounts'\n",
    "            'T1055.009'\n",
    "            'T1055.009 - Process Injection'\n",
    "            'D3-NTA - Network Traffic Analysis'\n",
    "            'D3-PM'\n",
    "    directory : str | Path\n",
    "        Directory containing new-format analytic plan JSON files.\n",
    "    detect_filename : str\n",
    "        Special file whose IR objects should be placed first (if include_detect_first = True).\n",
    "    include_detect_first : bool\n",
    "        If True, IR objects from detect_filename (if present) are prepended before the rest.\n",
    "    filter_indicators : bool\n",
    "        If True, restrict the 'indicators' list in each returned IR object to only those\n",
    "        techniques explicitly requested for that tactic. If False, include all indicators\n",
    "        for matching IR objects (as long as tactic matches).\n",
    "    deduplicate : bool\n",
    "        If True, remove duplicates (same information_requirement + tactic_id combination).\n",
    "        Keeps the first occurrence (maintaining order).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict]\n",
    "        List of IR objects (each already in the new schema).\n",
    "    \"\"\"\n",
    "\n",
    "    directory = Path(directory)\n",
    "\n",
    "    # Normalize attack_chain into:\n",
    "    #   tactic_map: tactic_id -> set(normalized technique IDs)\n",
    "    tactic_map: Dict[str, Set[str]] = {}\n",
    "    for tactic_str, technique_list in attack_chain.items():\n",
    "        tactic_id, _ = _normalize_tactic_key(tactic_str)\n",
    "        norm_tecs = {_normalize_technique_id(t) for t in technique_list}\n",
    "        # Remove empties\n",
    "        norm_tecs = {t for t in norm_tecs if t}\n",
    "        tactic_map.setdefault(tactic_id, set()).update(norm_tecs)\n",
    "\n",
    "    results: List[dict] = []\n",
    "\n",
    "    def process_file(path: Path):\n",
    "        try:\n",
    "            data = _load_json_safely(path)\n",
    "        except Exception as e:  # noqa\n",
    "            print(f\"[WARN] Could not parse {path.name}: {e}\")\n",
    "            return\n",
    "\n",
    "        if not isinstance(data, list):\n",
    "            # print(f\"[WARN] {path.name} root is not a list. Skipping.\")\n",
    "            return\n",
    "\n",
    "        for obj in data:\n",
    "            if not _is_new_schema_object(obj):\n",
    "                print(f\"[WARN] {path.name} does not conform to schema. Skipping.\")\n",
    "                continue  # silently skip non-conforming entries\n",
    "\n",
    "            tactic_id = obj.get(\"tactic_id\", \"\").strip()\n",
    "            if tactic_id not in tactic_map:\n",
    "                # print(f\"[INFO] {tactic_id} not in tactic map. Skipping.\")\n",
    "                continue  # tactic not requested\n",
    "\n",
    "            # Possibly filter indicators\n",
    "            if filter_indicators:\n",
    "                filtered_obj = _filter_indicators(copy.deepcopy(obj), tactic_map[tactic_id])\n",
    "                # If after filtering there are no indicators (and we requested some), skip.\n",
    "                if tactic_map[tactic_id] and not filtered_obj.get(\"indicators\"):\n",
    "                    continue\n",
    "                results.append(filtered_obj)\n",
    "            else:\n",
    "                results.append(copy.deepcopy(obj))\n",
    "\n",
    "    # 1. Optionally process the special detect_filename first\n",
    "    if include_detect_first:\n",
    "        detect_path = directory / detect_filename\n",
    "        if detect_path.exists():\n",
    "            process_file(detect_path)\n",
    "        else:\n",
    "            print(f\"[ERROR] {detect_filename} not found\")\n",
    "            pass\n",
    "\n",
    "    # 2. Process all other JSON files\n",
    "    for path in sorted(directory.glob(\"*.json\")):\n",
    "        if include_detect_first and path.name == detect_filename:\n",
    "            continue\n",
    "        process_file(path)\n",
    "\n",
    "    # 3. Deduplicate (stable) if requested\n",
    "    if deduplicate:\n",
    "        seen = set()\n",
    "        unique: List[dict] = []\n",
    "        for obj in results:\n",
    "            key = (obj.get(\"information_requirement\"), obj.get(\"tactic_id\"))\n",
    "            if key in seen:\n",
    "                continue\n",
    "            seen.add(key)\n",
    "            unique.append(obj)\n",
    "        results = unique\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Of_0WhnQ2Kh"
   },
   "source": [
    "### Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752686185987,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "ZjuIZinBQ2Ki"
   },
   "outputs": [],
   "source": [
    "# Toggle logging on (verbose = True)/off (verbose = False)\n",
    "verbose = True\n",
    "# verbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1752686186253,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "-74quC1cM8Mq",
    "outputId": "791dc605-d66d-4a80-e061-4486cadbaabb"
   },
   "outputs": [],
   "source": [
    "# Rate limits: https://ai.google.dev/gemini-api/docs/rate-limits\n",
    "# Pricing: https://ai.google.dev/gemini-api/docs/pricing\n",
    "# Usage: https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/metrics?project=gen-lang-client-0497172401\n",
    "# Note that this notebook is designed to be run in Google Colab. The line below reads the Gemini API key for AI Studio,\n",
    "# which is configured in the Secrets tab on the left side of the Colab window.\n",
    "# os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
    "# log(\"Gemii API key loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-kK0vWh7Q2Ki"
   },
   "source": [
    "### Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45314,
     "status": "ok",
     "timestamp": 1752686231562,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "QbeB5obluk-_",
    "outputId": "bbb14fdb-65e9-4a37-aa4a-be37258adcf5"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive and move into the Google AI Studio folder\n",
    "# DRIVE_PATH = \"/content/drive\"\n",
    "# TECHNIQUES_PATH = \"/content/drive/MyDrive/Google AI Studio/techniques\"\n",
    "\n",
    "# drive.mount(DRIVE_PATH)\n",
    "# log(f\"Google Drive mounted to {DRIVE_PATH}\")\n",
    "\n",
    "# os.chdir(TECHNIQUES_PATH)\n",
    "# log(f\"Changed directory to {TECHNIQUES_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQokR-C_5Qng"
   },
   "source": [
    "## Test Analytic Scheme of Maneuver Generation\n",
    "\n",
    "This section generates a small analytic scheme of maneuver off of a test attack chain data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3903,
     "status": "ok",
     "timestamp": 1752686235467,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "sFs785QVxZEa",
    "outputId": "65bf4a0d-6ea3-405a-c4ee-0a1a86a8f029"
   },
   "outputs": [],
   "source": [
    "# Example attack_chain data structure\n",
    "attack_chain_data = {\n",
    "    \"D3-D - Detect\": [\n",
    "        \"D3-NTA - Network Traffic Analysis\",\n",
    "        \"D3-PM - Platform Monitoring\"\n",
    "    ],\n",
    "    \"TA0001 - Initial Access\": [\n",
    "        \"T1190 - Exploit Public-Facing Application\",\n",
    "        \"T1566 - Phishing\",\n",
    "        \"T1078 - Valid Accounts\"\n",
    "    ],\n",
    "    \"TA0004 - Privilege Escalation\": [\n",
    "        \"T1078 - Valid Accounts\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "log(\"Building ASOM...\")\n",
    "resulting_asom = build_asom(attack_chain_data)\n",
    "log(\"Finished.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752686235473,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "u6SGBlaoTEvh"
   },
   "outputs": [],
   "source": [
    "# print(json.dumps(resulting_asom, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1752686235479,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "iX6GbgGchDLc"
   },
   "outputs": [],
   "source": [
    "def format_asom(asom_input_list, joiner=\"; \"):\n",
    "    \"\"\"\n",
    "    Format the output from build_asom_new (new analytic plan schema) into a pandas DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    asom_input_list : list[dict]\n",
    "        List of IR objects, each with keys:\n",
    "          - information_requirement (str)\n",
    "          - tactic_id (str)\n",
    "          - tactic_name (str)\n",
    "          - indicators (list of indicator dicts)\n",
    "              * indicator dict: { \"technique_id\", \"name\", \"evidence\": [ evidence dicts ] }\n",
    "              * evidence dict: { \"description\", \"data_sources\", \"data_platforms\", \"nai\", \"action\" }\n",
    "          - version\n",
    "          - date_created\n",
    "          - last_updated\n",
    "          - contributors (list)\n",
    "    joiner : str\n",
    "        Delimiter to join list fields (data_sources, data_platforms, contributors).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Tabular view with hierarchical-style indices expressed as string columns:\n",
    "          IR Index -> Indicator Index (IRIndex.TechSubIndex) -> Evidence Index (IRIndex.TechSubIndex.EvidenceSubIndex)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    table_rows = []\n",
    "    ir_index = 0\n",
    "\n",
    "    if not isinstance(asom_input_list, list):\n",
    "        raise TypeError(\"Expected asom_input_list to be a list produced by build_asom_new.\")\n",
    "\n",
    "    for ir_obj in asom_input_list:\n",
    "        if not isinstance(ir_obj, dict):\n",
    "            print(f\"[WARN] Skipping non-dict IR object: {ir_obj}\")\n",
    "            continue\n",
    "\n",
    "        required_ir_keys = {\"information_requirement\", \"tactic_id\", \"tactic_name\", \"indicators\"}\n",
    "        if not required_ir_keys.issubset(ir_obj.keys()):\n",
    "            print(f\"[WARN] IR object missing required keys: {ir_obj.keys()}\")\n",
    "            continue\n",
    "\n",
    "        indicators = ir_obj.get(\"indicators\", [])\n",
    "        if not indicators:\n",
    "            # Optionally emit a placeholder row; for now just warn and skip.\n",
    "            print(f\"[INFO] IR '{ir_obj.get('information_requirement')}' has no indicators; skipping.\")\n",
    "            continue\n",
    "\n",
    "        ir_index += 1\n",
    "        tactic_id = ir_obj.get(\"tactic_id\", \"\")\n",
    "        tactic_name = ir_obj.get(\"tactic_name\", \"\")\n",
    "        information_requirement = ir_obj.get(\"information_requirement\", \"\")\n",
    "        version = ir_obj.get(\"version\", \"\")\n",
    "        date_created = ir_obj.get(\"date_created\", \"\")\n",
    "        last_updated = ir_obj.get(\"last_updated\", \"\")\n",
    "        contributors = ir_obj.get(\"contributors\", [])\n",
    "        contributors_joined = joiner.join(contributors) if isinstance(contributors, list) else str(contributors)\n",
    "\n",
    "        tech_sub_index = 0\n",
    "        for indicator in indicators:\n",
    "            if not isinstance(indicator, dict):\n",
    "                print(f\"[WARN] Skipping non-dict indicator in IR '{information_requirement}': {indicator}\")\n",
    "                continue\n",
    "\n",
    "            technique_id = indicator.get(\"technique_id\", \"\")\n",
    "            technique_name = indicator.get(\"name\", \"\")\n",
    "            evidence_list = indicator.get(\"evidence\", [])\n",
    "\n",
    "            information_requirement = f\"{information_requirement} ({tactic_id} - {tactic_name})\"\n",
    "\n",
    "            tech_sub_index += 1\n",
    "            indicator_index_str = f\"{ir_index}.{tech_sub_index}\"\n",
    "\n",
    "            if not evidence_list:\n",
    "                # If no evidence entries, optionally create a placeholder row.\n",
    "                # (Current behavior: skip but warn.)\n",
    "                print(f\"[INFO] Indicator '{technique_id} - {technique_name}' has no evidence entries.\")\n",
    "                continue\n",
    "\n",
    "            evidence_sub_index = 0\n",
    "            for evidence in evidence_list:\n",
    "                if not isinstance(evidence, dict):\n",
    "                    print(f\"[WARN] Skipping non-dict evidence under technique '{technique_id}': {evidence}\")\n",
    "                    continue\n",
    "\n",
    "                evidence_sub_index += 1\n",
    "                evidence_index_str = f\"{indicator_index_str}.{evidence_sub_index}\"\n",
    "\n",
    "                description = evidence.get(\"description\", \"\")\n",
    "                data_sources = evidence.get(\"data_sources\", [])\n",
    "                data_platforms = evidence.get(\"data_platforms\", [])\n",
    "                nai = evidence.get(\"nai\", \"\")\n",
    "                action = evidence.get(\"action\", \"\")\n",
    "\n",
    "                # Normalize list fields\n",
    "                if isinstance(data_sources, list):\n",
    "                    data_sources_joined = joiner.join(data_sources)\n",
    "                else:\n",
    "                    data_sources_joined = str(data_sources)\n",
    "\n",
    "                if isinstance(data_platforms, list):\n",
    "                    data_platforms_joined = joiner.join(data_platforms)\n",
    "                else:\n",
    "                    data_platforms_joined = str(data_platforms)\n",
    "\n",
    "                row = {\n",
    "                    \"CCIR Index\": ir_index,\n",
    "                    \"CCIR\": information_requirement,\n",
    "                    \"Tactic ID\": tactic_id,\n",
    "                    \"Tactic Name\": tactic_name,\n",
    "                    \"Indicator Index\": indicator_index_str,\n",
    "                    \"Indicator\": f\"{technique_id} - {technique_name}\",\n",
    "                    \"Technique ID\": technique_id,\n",
    "                    \"Technique Name\": technique_name,\n",
    "                    \"Evidence Index\": evidence_index_str,\n",
    "                    \"Evidence Description\": description,\n",
    "                    \"Data Sources\": data_sources_joined,\n",
    "                    \"Data Platforms\": data_platforms_joined,\n",
    "                    \"NAI\": nai,\n",
    "                    \"Action\": action\n",
    "                    # \"Version\": version,\n",
    "                    # \"Date Created\": date_created,\n",
    "                    # \"Last Updated\": last_updated,\n",
    "                    # \"Contributors\": contributors_joined,\n",
    "                }\n",
    "                table_rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(table_rows)\n",
    "\n",
    "    # Ensure all expected columns exist (important if there were zero rows)\n",
    "    column_order = [\n",
    "        \"CCIR Index\",\n",
    "        \"CCIR\",\n",
    "        \"Tactic ID\",\n",
    "        \"Tactic Name\",\n",
    "        \"Indicator Index\",\n",
    "        \"Indicator\",\n",
    "        \"Technique ID\",\n",
    "        \"Technique Name\",\n",
    "        \"Evidence Index\",\n",
    "        \"Evidence Description\",\n",
    "        \"Data Sources\",\n",
    "        \"Data Platforms\",\n",
    "        \"NAI\",\n",
    "        \"Action\"\n",
    "        # \"Version\",\n",
    "        # \"Date Created\",\n",
    "        # \"Last Updated\",\n",
    "        # \"Contributors\",\n",
    "    ]\n",
    "    for col in column_order:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "\n",
    "    # Optional: sort by hierarchical indices for readability\n",
    "    if not df.empty:\n",
    "        df.sort_values(by=[\"CCIR Index\", \"Indicator Index\", \"Evidence Index\"], inplace=True, ignore_index=True)\n",
    "\n",
    "    return df[column_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1752686235535,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "s73T869oiGL9",
    "outputId": "d3ba4731-8160-49c3-a3ff-85aa60b39618"
   },
   "outputs": [],
   "source": [
    "formatted_df = format_asom(resulting_asom)\n",
    "# To display the full content of cells if they are long\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                        'display.max_columns', None,\n",
    "                        'display.width', 1000,\n",
    "                        'display.max_colwidth', None):\n",
    "    display(formatted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 443,
     "status": "ok",
     "timestamp": 1752686235975,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "far8kjSi9Gyr"
   },
   "outputs": [],
   "source": [
    "# Export the full ASOM to an Excel file\n",
    "formatted_df.to_excel(\"test_asom_full.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1752686235985,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "kZ4kXEif5ITK"
   },
   "outputs": [],
   "source": [
    "def get_representative_ccirs_by_tactic_simplified(df_with_ccirs: pd.DataFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Groups CCIRs by MITRE Tactic and generates a representative CCIR string for each group\n",
    "    using a simplified templating logic.\n",
    "\n",
    "    Args:\n",
    "        df_with_ccirs (pd.DataFrame): DataFrame containing a 'CCIR' column with the\n",
    "                                     CCIR strings.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping each Tactic ID (str) to its representative\n",
    "              CCIR string (str).\n",
    "    \"\"\"\n",
    "    if 'CCIR' not in df_with_ccirs.columns:\n",
    "        print(\"Error: DataFrame must contain a 'CCIR' column.\")\n",
    "        return {}\n",
    "\n",
    "    df = df_with_ccirs.copy()\n",
    "\n",
    "    def extract_tactic_details_from_ccir(ccir_string: str):\n",
    "        \"\"\"\n",
    "        Extracts Tactic ID, Tactic Name, and the full original signature from a CCIR string.\n",
    "        \"\"\"\n",
    "        if pd.isna(ccir_string):\n",
    "            return None, None, None  # tactic_id, tactic_name, original_signature\n",
    "\n",
    "        # Regex to capture \"(TAXXXX - Tactic Name)\"\n",
    "        match_full = re.search(r\"\\((TA\\d{4})\\s*-\\s*([^)]+?)\\)\", ccir_string)\n",
    "        if match_full:\n",
    "            tactic_id = match_full.group(1)      # e.g., TA0001\n",
    "            tactic_name = match_full.group(2).strip()  # e.g., Initial Access\n",
    "            original_signature = match_full.group(0) # e.g., (TA0001 - Initial Access)\n",
    "            return tactic_id, tactic_name, original_signature\n",
    "\n",
    "        # Fallback for patterns like \"(TAXXXX)\" if name is missing in signature\n",
    "        match_simple = re.search(r\"\\((TA\\d{4})\\)\", ccir_string)\n",
    "        if match_simple:\n",
    "            tactic_id = match_simple.group(1)\n",
    "            original_signature = match_simple.group(0)\n",
    "            # Tactic name is not present in this signature type\n",
    "            return tactic_id, None, original_signature\n",
    "\n",
    "        return None, None, None\n",
    "\n",
    "    # Apply extraction to get Tactic ID, Tactic Name, and original signature\n",
    "    extracted_info = df['CCIR'].apply(\n",
    "        lambda x: pd.Series(extract_tactic_details_from_ccir(x),\n",
    "                            index=['Tactic_ID_Extracted', 'Tactic_Name_Extracted', 'Original_Signature'])\n",
    "    )\n",
    "    df = pd.concat([df, extracted_info], axis=1)\n",
    "\n",
    "    representative_ccirs_map = {}\n",
    "\n",
    "    # Group by extracted Tactic ID\n",
    "    # Consider only rows where Tactic_ID_Extracted is not NaN\n",
    "    valid_tactic_groups = df[df['Tactic_ID_Extracted'].notna()].groupby('Tactic_ID_Extracted')\n",
    "\n",
    "    for tactic_id, group in valid_tactic_groups:\n",
    "        unique_ccirs = group['CCIR'].unique().tolist()\n",
    "\n",
    "        # Attempt to get a consistent Tactic Name for the group\n",
    "        # Prioritize non-null Tactic Names if there's variation (shouldn't be if signature is consistent)\n",
    "        tactic_names_in_group = group['Tactic_Name_Extracted'].dropna().unique()\n",
    "        tactic_name_for_template = tactic_names_in_group[0] if len(tactic_names_in_group) > 0 else None\n",
    "\n",
    "        if len(unique_ccirs) == 1:\n",
    "            representative_ccirs_map[tactic_id] = unique_ccirs[0]\n",
    "        else:  # More than one unique CCIR for this Tactic ID\n",
    "            if tactic_name_for_template: # Check if we have a tactic name for the template\n",
    "                lowercase_tactic_name = tactic_name_for_template.lower()\n",
    "                # Construct the standard signature part for the template\n",
    "                standard_signature_for_template = f\"({tactic_id} - {tactic_name_for_template})\"\n",
    "                templated_ccir = f\"Did the adversary conduct {lowercase_tactic_name}? {standard_signature_for_template}\"\n",
    "                representative_ccirs_map[tactic_id] = templated_ccir\n",
    "            else:\n",
    "                # Fallback if Tactic Name is not available for the template, use the first unique CCIR\n",
    "                representative_ccirs_map[tactic_id] = unique_ccirs[0]\n",
    "                print(f\"Warning: Tactic Name not found for Tactic ID {tactic_id} with multiple CCIRs. Using original CCIR as representative.\")\n",
    "\n",
    "    return representative_ccirs_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752686235986,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "QwcjPk8FlSfr"
   },
   "outputs": [],
   "source": [
    "representative_ccirs_map = get_representative_ccirs_by_tactic_simplified(formatted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752686235988,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "2yu_nZjNlGu7"
   },
   "outputs": [],
   "source": [
    "def update_ccirs(original_df, representative_ccirs_map):\n",
    "    \"\"\"\n",
    "    Replaces CCIR strings in a DataFrame with their generalized versions.\n",
    "\n",
    "    Args:\n",
    "        original_df (pd.DataFrame): The DataFrame with an 'CCIR' column\n",
    "                                     containing original CCIR strings.\n",
    "        representative_ccirs_map (dict): A dictionary mapping Tactic IDs (e.g., 'TA0001')\n",
    "                                        to their generalized CCIR strings.\n",
    "\n",
    "    Returns:\n",
    "        final_df (pd.DataFrame): The DataFrame with updated CCIRs.\n",
    "    \"\"\"\n",
    "    if 'CCIR' not in original_df.columns:\n",
    "        print(\"Error: DataFrame must contain an 'CCIR' column.\")\n",
    "        return original_df, None\n",
    "\n",
    "    final_df = original_df.copy()\n",
    "\n",
    "    # Helper function to extract Tactic ID from a CCIR string\n",
    "    def extract_tactic_id(ccir_string):\n",
    "        if pd.isna(ccir_string):\n",
    "            return None\n",
    "        # This regex aims to find (TAXXXX) within the string\n",
    "        match = re.search(r\"\\((TA\\d{4}).*?\\)\", ccir_string)\n",
    "        if match:\n",
    "            return match.group(1) # Returns TAXXXX\n",
    "        return None\n",
    "\n",
    "    # 1. Extract Tactic ID from original CCIRs to use for mapping\n",
    "    final_df['Tactic_ID_for_mapping'] = final_df['CCIR'].apply(extract_tactic_id)\n",
    "\n",
    "    # 2. Replace the 'CCIR' column with the generalized CCIRs\n",
    "    # The .map() function looks up each 'Tactic_ID_for_mapping' in the representative_ccirs_map\n",
    "    # .fillna(final_df['CCIR']) ensures that if a Tactic ID doesn't have a corresponding\n",
    "    # generalized CCIR in the map, the original CCIR string is retained.\n",
    "    final_df['CCIR'] = final_df['Tactic_ID_for_mapping'].map(representative_ccirs_map).fillna(final_df['CCIR'])\n",
    "\n",
    "    # Clean up the temporary mapping column\n",
    "    final_df = final_df.drop(columns=['Tactic_ID_for_mapping'])\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1752686236007,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "fbdTWLTdl6kJ"
   },
   "outputs": [],
   "source": [
    "# Perform the update and grouping\n",
    "updated_df = update_ccirs(formatted_df, representative_ccirs_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752686236025,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "i97sqDTv8G9-"
   },
   "outputs": [],
   "source": [
    "def update_sequential_ccir_index(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Updates the 'CCIR Index' column in the DataFrame to sequentially number\n",
    "    groups of adjacent identical strings in the 'CCIR' column.\n",
    "\n",
    "    The DataFrame should already have its 'CCIR' column populated with the\n",
    "    strings that need to be grouped (e.g., generalized CCIRs).\n",
    "    Any existing 'CCIR Index' column will be overwritten.\n",
    "\n",
    "    Args:\n",
    "        input_df (pd.DataFrame): The DataFrame with a 'CCIR' column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the 'CCIR Index' column updated.\n",
    "    \"\"\"\n",
    "    if 'CCIR' not in input_df.columns:\n",
    "        print(\"Error: DataFrame must contain a 'CCIR' column to generate the new CCIR Index.\")\n",
    "        # Return a copy or original df if CCIR column is missing\n",
    "        return input_df.copy() if isinstance(input_df, pd.DataFrame) else input_df\n",
    "\n",
    "\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Ensure consistent handling of NaNs if they exist in CCIR column,\n",
    "    # though ideally CCIRs are strings. For this logic, direct comparison works.\n",
    "    # If NaNs need specific grouping (e.g., all NaNs are one group, or each is distinct),\n",
    "    # df['CCIR'] = df['CCIR'].fillna('__NAN_PLACEHOLDER__') # might be one strategy before comparison.\n",
    "    # However, the current logic (ccir_series != ccir_series.shift()) handles NaNs by\n",
    "    # typically starting a new group for/after a NaN, as NaN != NaN is True.\n",
    "\n",
    "    # Identify rows where the 'CCIR' value changes from the previous row.\n",
    "    # The first row will always mark a change (as shift() produces NaN).\n",
    "    ccir_value_changed = (df['CCIR'] != df['CCIR'].shift())\n",
    "\n",
    "    # The cumsum() of this boolean series creates a unique sequential ID for each\n",
    "    # block of adjacent identical CCIRs. True becomes 1, False becomes 0 in sum.\n",
    "    # This will naturally start the 'CCIR Index' from 1.\n",
    "    df['CCIR Index'] = ccir_value_changed.cumsum()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1752686236031,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "lE_oJoEK_b-d"
   },
   "outputs": [],
   "source": [
    "def update_hierarchical_indicator_index(input_df: pd.DataFrame,\n",
    "                                        ccir_index_col: str = 'CCIR Index',\n",
    "                                        indicator_text_col: str = 'Indicator', # Updated default\n",
    "                                        output_indicator_index_col: str = 'Indicator Index') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Updates or creates a hierarchical 'Indicator Index' column in the DataFrame.\n",
    "    The index is in the format 'CCIR Index.Sub-Index'. The Sub-Index restarts\n",
    "    for each new 'CCIR Index' group and increments for blocks of adjacent\n",
    "    identical values in the 'indicator_text_col' within that CCIR Index group.\n",
    "\n",
    "    Args:\n",
    "        input_df (pd.DataFrame): The input DataFrame.\n",
    "        ccir_index_col (str): Name of the column containing the main CCIR group index.\n",
    "        indicator_text_col (str): Name of the column containing the indicator text\n",
    "                                  strings (e.g., \"T1190 - Exploit Public-Facing Application\")\n",
    "                                  to be grouped for sub-indexing. Default is 'Indicator'.\n",
    "        output_indicator_index_col (str): Name of the column where the new\n",
    "                                          hierarchical indicator index will be stored.\n",
    "                                          Default is 'Indicator Index'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the 'Indicator Index' column updated or created.\n",
    "    \"\"\"\n",
    "    df = input_df.copy()\n",
    "\n",
    "    if ccir_index_col not in df.columns:\n",
    "        print(f\"Error: DataFrame must contain the CCIR group index column '{ccir_index_col}'.\")\n",
    "        return df\n",
    "    if indicator_text_col not in df.columns:\n",
    "        print(f\"Error: DataFrame must contain the indicator text column '{indicator_text_col}'.\")\n",
    "        return df\n",
    "\n",
    "    # --- Data Cleaning & Preparation for 'indicator_text_col' ---\n",
    "    # This is crucial if strings that should group together have subtle differences\n",
    "    # (e.g., extra whitespace, case differences if they should be ignored).\n",
    "    processed_indicator_text_col = '_processed_' + indicator_text_col\n",
    "\n",
    "    # Convert to string and strip whitespace as a basic cleaning step.\n",
    "    # NaNs become \"nan\", \"None\" becomes \"None\". If specific NaN handling is needed,\n",
    "    # it should be done here (e.g., fillna with a placeholder).\n",
    "    df[processed_indicator_text_col] = df[indicator_text_col].astype(str).str.strip()\n",
    "    # Example for case-insensitive grouping (optional):\n",
    "    # df[processed_indicator_text_col] = df[indicator_text_col].astype(str).str.strip().str.lower()\n",
    "\n",
    "\n",
    "    # Helper function to calculate the sub-index within each CCIR Index group\n",
    "    def calculate_sub_index_within_group(indicator_series: pd.Series) -> pd.Series:\n",
    "        \"\"\"\n",
    "        For a series of indicator texts within a single CCIR Index group,\n",
    "        this calculates a sub-index (1, 2, 3...) for blocks of identical indicators.\n",
    "        \"\"\"\n",
    "        indicator_changed_in_group = (indicator_series != indicator_series.shift())\n",
    "        return indicator_changed_in_group.cumsum()\n",
    "\n",
    "    temp_sub_index_col = '_temp_indicator_sub_index'\n",
    "\n",
    "    # Apply sub-index calculation to each group formed by 'CCIR Index',\n",
    "    # using the (potentially processed) 'indicator_text_col'.\n",
    "    df[temp_sub_index_col] = df.groupby(ccir_index_col)[processed_indicator_text_col].transform(calculate_sub_index_within_group)\n",
    "\n",
    "    # Construct the final hierarchical 'Indicator Index' string\n",
    "    df[output_indicator_index_col] = df[ccir_index_col].astype(str) + '.' + df[temp_sub_index_col].astype(str)\n",
    "\n",
    "    # Drop temporary columns\n",
    "    df = df.drop(columns=[temp_sub_index_col, processed_indicator_text_col])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752686236041,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "CjeQiyJIAIWe"
   },
   "outputs": [],
   "source": [
    "def update_final_evidence_index(input_df: pd.DataFrame,\n",
    "                                indicator_index_col: str = 'Indicator Index',\n",
    "                                output_evidence_index_col: str = 'Evidence Index') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Updates or creates the 'Evidence Index' column in the DataFrame.\n",
    "    The index is hierarchical, in the format 'Indicator Index.n'\n",
    "    (e.g., \"1.1.1\", \"1.1.2\"), where 'n' is the 1-based sequential\n",
    "    position of the evidence row within its parent 'Indicator Index' group.\n",
    "\n",
    "    Args:\n",
    "        input_df (pd.DataFrame): The input DataFrame which must contain the\n",
    "                                 column specified by `indicator_index_col`.\n",
    "                                 Each row is assumed to be a distinct piece of evidence.\n",
    "        indicator_index_col (str): Name of the column containing the hierarchical\n",
    "                                   indicator index (e.g., a column with values\n",
    "                                   like \"1.1\", \"1.2\" from the previous step).\n",
    "        output_evidence_index_col (str): Name of the column where the new,\n",
    "                                         most granular evidence index will be stored.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the 'Evidence Index' column updated or created.\n",
    "    \"\"\"\n",
    "    df = input_df.copy()\n",
    "\n",
    "    if indicator_index_col not in df.columns:\n",
    "        print(f\"Error: DataFrame must contain the '{indicator_index_col}' column to generate Evidence Index.\")\n",
    "        return df\n",
    "\n",
    "    # Calculate 'n', the sequential position of each evidence item (row)\n",
    "    # within its group defined by the 'indicator_index_col'.\n",
    "    # pandas.core.groupby.GroupBy.cumcount() is 0-based, so we add 1 for a 1-based sequence.\n",
    "    # This assumes each row at this stage is a unique piece of evidence to be numbered.\n",
    "    df['evidence_sequence_n'] = df.groupby(indicator_index_col).cumcount() + 1\n",
    "\n",
    "    # Construct the final 'Evidence Index' string by appending '.n'\n",
    "    # to the existing 'Indicator Index' string.\n",
    "    df[output_evidence_index_col] = df[indicator_index_col].astype(str) + '.' + df['evidence_sequence_n'].astype(str)\n",
    "\n",
    "    # Drop the temporary sequence helper column\n",
    "    df = df.drop(columns=['evidence_sequence_n'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752686236050,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "QiqzQXlu76-Y"
   },
   "outputs": [],
   "source": [
    "# Now that we have re-written the CCIR names, update the CCIR indexes .\n",
    "updated_df = update_sequential_ccir_index(updated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1752686236054,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "dB-oK4ZpCiQC"
   },
   "outputs": [],
   "source": [
    "# Next, update the indicator index based on the new CCIR indexes.\n",
    "updated_df = update_hierarchical_indicator_index(updated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1752686236087,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "JGSt-q1BCkNp"
   },
   "outputs": [],
   "source": [
    "# Finally, update the evidence index based on the new CCIR and indicator indexes.\n",
    "updated_df = update_final_evidence_index(updated_df, indicator_index_col = \"Indicator Index\", output_evidence_index_col = \"Evidence Index\")\n",
    "# display(updated_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 82,
     "status": "ok",
     "timestamp": 1752686236165,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "FyBNHwYmf3SA"
   },
   "outputs": [],
   "source": [
    "def create_visually_spanned_df(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Transforms a DataFrame by setting a MultiIndex on specified hierarchical\n",
    "    columns to achieve a visual row-spanning effect when displayed.\n",
    "\n",
    "    The \"merging\" of cells is a visual effect provided by Pandas' MultiIndex\n",
    "    display. The underlying DataFrame data remains in a 2D structure.\n",
    "\n",
    "    Args:\n",
    "        input_df (pd.DataFrame): The input DataFrame. Expected to have columns\n",
    "                                 like 'CCIR Index', 'CCIR', 'Tactic ID',\n",
    "                                 'Technique Index', 'Technique', 'Technique ID',\n",
    "                                 followed by more granular data columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame ('final_df') with a MultiIndex set on the\n",
    "                      hierarchical columns, sorted for proper visual spanning.\n",
    "    \"\"\"\n",
    "    df = input_df.copy()\n",
    "\n",
    "    # Define the columns that will form the hierarchical MultiIndex.\n",
    "    # The order of these columns is crucial as it defines the levels of the hierarchy\n",
    "    # and how the visual spanning will appear.\n",
    "    hierarchical_cols = [\n",
    "        'CCIR Index',\n",
    "        'CCIR',\n",
    "        'Indicator Index',\n",
    "        'Indicator',\n",
    "    ]\n",
    "\n",
    "    # Verify that these columns exist in the input DataFrame.\n",
    "    # If any are missing, they will be excluded from the MultiIndex.\n",
    "    existing_hierarchical_cols = [col for col in hierarchical_cols if col in df.columns]\n",
    "\n",
    "    if not existing_hierarchical_cols:\n",
    "        print(\"Warning: None of the specified hierarchical columns for indexing \"\n",
    "              \"were found in the DataFrame. Returning the original DataFrame.\")\n",
    "        return df\n",
    "\n",
    "    # The remaining columns will be the data columns associated with the\n",
    "    # most granular level of the hierarchy.\n",
    "    # data_cols = [col for col in df.columns if col not in existing_hierarchical_cols] # Not strictly needed for set_index\n",
    "\n",
    "    # For the visual spanning to work correctly, the DataFrame MUST be sorted\n",
    "    # by the columns that will form the MultiIndex, in the specified order.\n",
    "    # This ensures that identical values are adjacent before set_index is called.\n",
    "    df = df.sort_values(by=existing_hierarchical_cols)\n",
    "\n",
    "    # Set the MultiIndex.\n",
    "    # The columns listed in existing_hierarchical_cols will be moved from\n",
    "    # the DataFrame's columns to its index.\n",
    "    final_df = df.set_index(existing_hierarchical_cols)\n",
    "\n",
    "    # While sort_values before set_index is the primary sorting,\n",
    "    # sorting the index itself can ensure canonical order if needed,\n",
    "    # though usually redundant if sorted before.\n",
    "    # final_df = final_df.sort_index()\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1752686236185,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "iAaWhrd48dqQ",
    "outputId": "fcc86673-5df3-401b-922c-126e4cd5afba"
   },
   "outputs": [],
   "source": [
    "# Now we can perform the final transformation on the ASOM, merging like cells to\n",
    "# produce the finished ASOM.\n",
    "final_df = create_visually_spanned_df(updated_df)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, # Show all rows to see full effect\n",
    "                        'display.width', 1200,    # Adjust width as needed\n",
    "                        'display.max_colwidth', 30,\n",
    "                        'display.expand_frame_repr', False # Prevent wrapping if too wide for console\n",
    "                        ):\n",
    "    # display(final_df)\n",
    "    # Here we will display only a specific subset of the columns, rather than the full set.\n",
    "    display(final_df.filter(items=[\"CCIR Index\", \"CCIR\", \"Indicator Index\", \"Indicator \", \"Evidence Index\", \"Evidence\", \"Data\", \"NAI\", \"Action\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1752686236187,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "Av-5sysv8id_"
   },
   "outputs": [],
   "source": [
    "# Export the finished ASOM to an Excel file\n",
    "final_df.to_excel(\"test_asom_merged.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166
    },
    "executionInfo": {
     "elapsed": 50,
     "status": "error",
     "timestamp": 1752686236238,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "j1fX5iTQVrF4",
    "outputId": "e27a623a-7b5d-49c2-f78b-0255071732ef"
   },
   "outputs": [],
   "source": [
    "# Automatically halt execution after the test ASOM is generated\n",
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mvOHovhW84Lr"
   },
   "source": [
    "## Example Analytic Scheme of Maneuver Generation\n",
    "\n",
    "This section generates an example analytic scheme of maneuver for a real threat actor based on information from Crowdstrike's threat intelligence platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 61550,
     "status": "aborted",
     "timestamp": 1752686236288,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "yXcEXqdkf28w"
   },
   "outputs": [],
   "source": [
    "def generate_attack_chain_data(actor_data_list):\n",
    "    \"\"\"\n",
    "    Transforms a list of actor data objects into a nested dictionary\n",
    "    organizing techniques under tactics.\n",
    "\n",
    "    Args:\n",
    "        actor_data_list (list): A list of dictionaries, where each dictionary\n",
    "                                represents an entry with tactic and technique info.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where keys are formatted tactic strings\n",
    "              (e.g., \"TA0001 - Initial Access\") and values are lists of\n",
    "              formatted technique strings (e.g., \"T1078 - Default Accounts\").\n",
    "    \"\"\"\n",
    "    attack_chain_data = defaultdict(list)\n",
    "\n",
    "    if not isinstance(actor_data_list, list):\n",
    "        print(\"Error: Input actor_data must be a list.\")\n",
    "        return {}\n",
    "\n",
    "    for item in actor_data_list:\n",
    "        if not isinstance(item, dict):\n",
    "            print(f\"Warning: Skipping non-dictionary item in actor_data_list: {item}\")\n",
    "            continue\n",
    "\n",
    "        tactic_id = item.get('tactic_id')\n",
    "        tactic_name = item.get('tactic_name')\n",
    "        technique_id_full = item.get('technique_id')\n",
    "        technique_name = item.get('technique_name')\n",
    "\n",
    "        # Ensure all necessary fields are present\n",
    "        if not all([tactic_id, tactic_name, technique_id_full, technique_name]):\n",
    "            print(f\"Warning: Skipping item due to missing essential fields (tactic_id, tactic_name, technique_id, technique_name): {item}\")\n",
    "            continue\n",
    "\n",
    "        # Format the Tactic Key: \"TAXXXX - Tactic Name\"\n",
    "        try:\n",
    "            formatted_tactic_id = str(tactic_id).upper()\n",
    "            tactic_key = f\"{formatted_tactic_id} - {str(tactic_name)}\"\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not format tactic key for item {item}. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Format the Technique Value: \"TXXXX - Technique Name\"\n",
    "        try:\n",
    "            formatted_technique_id_full = str(technique_id_full).upper()\n",
    "            technique_value = f\"{formatted_technique_id_full} - {str(technique_name)}\"\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not format technique value for item {item}. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Add the technique to the list for the corresponding tactic, avoiding duplicates\n",
    "        if technique_value not in attack_chain_data[tactic_key]:\n",
    "            attack_chain_data[tactic_key].append(technique_value)\n",
    "\n",
    "    # Convert defaultdict to a regular dict for the final output (optional, but common)\n",
    "    return dict(attack_chain_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMDiz4459hIK"
   },
   "source": [
    "This is an export of the ATT&CK data from Crowdstrike's threat intelligence platform. Crowdstrike supplies this in a format for MITRE ATT&CK Navigator overlays, but we can repurpose it to our use case here by processing it with `generate_attack_chain_data`, defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 61553,
     "status": "aborted",
     "timestamp": 1752686236291,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "zU6yiqNFogNR"
   },
   "outputs": [],
   "source": [
    "actor_data = [\n",
    "  {\n",
    "    \"id\": \"ta0001_t1078.001\",\n",
    "    \"tactic_id\": \"ta0001\",\n",
    "    \"tactic_name\": \"Initial Access\",\n",
    "    \"technique_id\": \"t1078.001\",\n",
    "    \"technique_name\": \"Default Accounts\",\n",
    "    \"observables\": [\n",
    "      \"Access to victims via compromised accounts\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0001_t1133\",\n",
    "    \"tactic_id\": \"ta0001\",\n",
    "    \"tactic_name\": \"Initial Access\",\n",
    "    \"technique_id\": \"t1133\",\n",
    "    \"technique_name\": \"External Remote Services\",\n",
    "    \"observables\": [\n",
    "      \"Use of VPN services\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0001_t1189\",\n",
    "    \"tactic_id\": \"ta0001\",\n",
    "    \"tactic_name\": \"Initial Access\",\n",
    "    \"technique_id\": \"t1189\",\n",
    "    \"technique_name\": \"Drive-by Compromise\",\n",
    "    \"reports\": [\n",
    "      \"CSMR-20006\"\n",
    "    ],\n",
    "    \"observables\": [\n",
    "      \"Unspecified use of drive-by compromise\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0001_t1190\",\n",
    "    \"tactic_id\": \"ta0001\",\n",
    "    \"tactic_name\": \"Initial Access\",\n",
    "    \"technique_id\": \"t1190\",\n",
    "    \"technique_name\": \"Exploit Public-Facing Application\",\n",
    "    \"observables\": [\n",
    "      \"Exploitation of unidentified public-facing applications\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0001_t1566.001\",\n",
    "    \"tactic_id\": \"ta0001\",\n",
    "    \"tactic_name\": \"Initial Access\",\n",
    "    \"technique_id\": \"t1566.001\",\n",
    "    \"technique_name\": \"Spearphishing Attachment\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has reportedly used spear phishing messages to deliver weaponized document files\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0001_t1566.002\",\n",
    "    \"tactic_id\": \"ta0001\",\n",
    "    \"tactic_name\": \"Initial Access\",\n",
    "    \"technique_id\": \"t1566.002\",\n",
    "    \"technique_name\": \"Spearphishing Link\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA may use malicious hyperlinks to weaponized document files \"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0002_t1047\",\n",
    "    \"tactic_id\": \"ta0002\",\n",
    "    \"tactic_name\": \"Execution\",\n",
    "    \"technique_id\": \"t1047\",\n",
    "    \"technique_name\": \"Windows Management Instrumentation\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used WMI based scripts to deploy GreenCrash RAT. The WMI script mof.txt configures a persistence mechanism using an event-consumer binding. The event is a timer set to five minute intervals, and the consumer is a JavaScript function that will execute the command regsvr32 /s %systemroot%\\\\conhost.dll\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0002_t1059\",\n",
    "    \"tactic_id\": \"ta0002\",\n",
    "    \"tactic_name\": \"Execution\",\n",
    "    \"technique_id\": \"t1059\",\n",
    "    \"technique_name\": \"Command and Scripting Interpreter\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA GreenCrash RAT provides remote shell functionality either by:\\ncopying cmd.exe to %TEMP%\\\\svchost.exe and using this to execute received commands - or - copying cmd.exe to %WINDIR%\\\\Temp\\\\system and executing it as remote shell\\nKRYPTONITE PANDA has used command line interaction to execute GreenCrash RAT loader executables\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0002_t1059.001\",\n",
    "    \"tactic_id\": \"ta0002\",\n",
    "    \"tactic_name\": \"Execution\",\n",
    "    \"technique_id\": \"t1059.001\",\n",
    "    \"technique_name\": \"PowerShell\",\n",
    "    \"reports\": [\n",
    "      \"CSA-17205\",\n",
    "      \"CSA-200976\",\n",
    "      \"CSMR-20008\",\n",
    "      \"CSWR-19046\"\n",
    "    ],\n",
    "    \"observables\": [\n",
    "      \"\\\"KRYPTONITE PANDA has used VBA macros contained within .dotm files to load the DADSTACHE and DADJOKE implants. Malicious macros have Decoded base64-encoded URLs hosting a second-stage downloaders and used the URLDownloadToFileA function to retrieve externally hosted content. Retrieved content has been written to the %APPDATA%\\\\Microsoft\\\\Office\\\\ directory\\nKRYPTONITE PANDA has used WMI based scripts to deploy GreenCrash RAT\\nKRYPTONITE PANDA has used Visual basic macros to deploy secondary payloads\\nUsed PowerShell\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0002_t1106\",\n",
    "    \"tactic_id\": \"ta0002\",\n",
    "    \"tactic_name\": \"Execution\",\n",
    "    \"technique_id\": \"t1106\",\n",
    "    \"technique_name\": \"Native API\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used the Scripting.FileSystemObject function to initialize a DLL search order hijacking chain\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0002_t1203\",\n",
    "    \"tactic_id\": \"ta0002\",\n",
    "    \"tactic_name\": \"Execution\",\n",
    "    \"technique_id\": \"t1203\",\n",
    "    \"technique_name\": \"Exploitation for Client Execution\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has targeted known client software vulnerabilities including CVE-2017-0199, CVE-2017-8759, and CVE-2018-0802\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0002_t1204.002\",\n",
    "    \"tactic_id\": \"ta0002\",\n",
    "    \"tactic_name\": \"Execution\",\n",
    "    \"technique_id\": \"t1204.002\",\n",
    "    \"technique_name\": \"Malicious File\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used weaponized malicious documents which require user interaction in order to deploy additional payloads\\nKRYPTONITE PANDA has used weaponized malicious documents with embedded Visual Basic macros\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0003_t1053.002\",\n",
    "    \"tactic_id\": \"ta0003\",\n",
    "    \"tactic_name\": \"Persistence\",\n",
    "    \"technique_id\": \"t1053.002\",\n",
    "    \"technique_name\": \"At\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used at.exe and schtasks.exe to persist GreenCrash RAT on compromised systems\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0003_t1053.005\",\n",
    "    \"tactic_id\": \"ta0003\",\n",
    "    \"tactic_name\": \"Persistence\",\n",
    "    \"technique_id\": \"t1053.005\",\n",
    "    \"technique_name\": \"Scheduled Task\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used scheduleded tasks with the filename AdobeSvc to execute legitimate executables as part of DLL search order hijacking \"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0003_t1505.003\",\n",
    "    \"tactic_id\": \"ta0003\",\n",
    "    \"tactic_name\": \"Persistence\",\n",
    "    \"technique_id\": \"t1505.003\",\n",
    "    \"technique_name\": \"Web Shell\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used multiple webshells including China Chopper and Angel Shell on compromised web servers for persistence\\nKRYPTONITE PANDA has used a JScript evaluator webshell with the filename app_offline.DISABLED.aspx\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0003_t1574.001\",\n",
    "    \"tactic_id\": \"ta0003\",\n",
    "    \"tactic_name\": \"Persistence\",\n",
    "    \"technique_id\": \"t1574.001\",\n",
    "    \"technique_name\": \"DLL Search Order Hijacking\"\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0003_t1574.002\",\n",
    "    \"tactic_id\": \"ta0003\",\n",
    "    \"tactic_name\": \"Persistence\",\n",
    "    \"technique_id\": \"t1574.002\",\n",
    "    \"technique_name\": \"DLL Side-Loading\",\n",
    "    \"reports\": [\n",
    "      \"CSA-250446\"\n",
    "    ],\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used legitimate applications to side-load malicious DLLs\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1027\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1027\",\n",
    "    \"technique_name\": \"Obfuscated Files or Information\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used AES-128 to encode a DADSTACHE payload\\nKRYPTONITE PANDA has used Base64 encoding to obfuscate VBScript loaders\\nKRYPTONITE PANDA has obfuscated GreenCrash RAT payloads using XOR\\nKRYPTONITE PANDA has used the single-byte XOR key 0xD7 to obfuscate downloader configurations\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1027.002\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1027.002\",\n",
    "    \"technique_name\": \"Software Packing\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used the .NET packer ConfuserEx to obfuscate .NET binaries\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1027.003\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1027.003\",\n",
    "    \"technique_name\": \"Steganography\",\n",
    "    \"observables\": [\n",
    "      \"Stored stolen data on GitHub disguised as benign images\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1027.004\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1027.004\",\n",
    "    \"technique_name\": \"Compile After Delivery\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used Base64 encoded second stage loaders run after retrieval on host\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1036\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1036\",\n",
    "    \"technique_name\": \"Masquerading\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has renamed DADSTACHE DLLs using the filename LogiMail.dll\\nKRYPTONITE PANDA has placed DADSTACHE implant files in the %APPDATA%\\\\Microsoft\\\\Office\\\\ directory\\nKRYPTONITE PANDA has renamed DADJOKE DLLs using the filename mpsvc.dll\\nKRYPTONITE PANDA has placed a GreenCrash loader in the C:\\\\Temp\\\\dell\\\\ directory\\nKRYPTONITE PANDA has placed implant files in the c:\\\\ProgramData\\\\VMware\\\\logs directory\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1070.004\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1070.004\",\n",
    "    \"technique_name\": \"File Deletion\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA JJDOOR dropper delpys a secondary VBScript which contains functionality to delete installer files\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1070.006\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1070.006\",\n",
    "    \"technique_name\": \"Timestomp\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA multitool contains functionality to modify file timestamps\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1140\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1140\",\n",
    "    \"technique_name\": \"Deobfuscate/Decode Files or Information\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used VBA macros to decode base-64 encoded URLs hosting second stage content\\nKRYPTONITE PANDA has used an AES-128 key based on the sample SHA256 hash to decode a DADSTACHE payload\\nKRYPTONITE PANDA has used Base64 to decode VBScript loaders\\nKRYPTONITE PANDA has  decoded GreenCrash RAT payload files with the XOR key 43 72 CD 1D 01 65 9F 7A D0 47 65 1D 9A 60 3C 5F\\nKRYPTONITE PANDA GreenCrash RAT loader uses XXTEA algorithm to decode a configuration file\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1218.005\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1218.005\",\n",
    "    \"technique_name\": \"Mshta\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used malicious HTA files to load secondary payloads including Cobalt Strike and JJDOOR\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1221\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1221\",\n",
    "    \"technique_name\": \"Template Injection\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used weaponized Microsoft Office document which take advantage of the .docx hyperlink feature to retrieve and execute additional payloads\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1574.001\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1574.001\",\n",
    "    \"technique_name\": \"DLL Search Order Hijacking\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used search order hijacking in order to execute DADSTACHE DLL payloads\\nKRYPTONITE PANDA has used search order hijacking to execute a custom keylogger via the legitimate executable debug.exe, and the DLL dbgeng.dll\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0005_t1620\",\n",
    "    \"tactic_id\": \"ta0005\",\n",
    "    \"tactic_name\": \"Defense Evasion\",\n",
    "    \"technique_id\": \"t1620\",\n",
    "    \"technique_name\": \"Reflective Code Loading\",\n",
    "    \"reports\": [\n",
    "      \"CSA-250446\"\n",
    "    ],\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA likely loaded .NET assemblies for in-memory execution\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0006_t1003.003\",\n",
    "    \"tactic_id\": \"ta0006\",\n",
    "    \"tactic_name\": \"Credential Access\",\n",
    "    \"technique_id\": \"t1003.003\",\n",
    "    \"technique_name\": \"NTDS\",\n",
    "    \"reports\": [\n",
    "      \"CSA-250446\"\n",
    "    ],\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA obtained the AD domain database NTDS.dit to access credential hashes\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0006_t1040\",\n",
    "    \"tactic_id\": \"ta0006\",\n",
    "    \"tactic_name\": \"Credential Access\",\n",
    "    \"technique_id\": \"t1040\",\n",
    "    \"technique_name\": \"Network Sniffing\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA deployed the publicly available Responder credential sniffing tool, with the filename Intel.exe\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0007_t1016\",\n",
    "    \"tactic_id\": \"ta0007\",\n",
    "    \"tactic_name\": \"Discovery\",\n",
    "    \"technique_id\": \"t1016\",\n",
    "    \"technique_name\": \"System Network Configuration Discovery\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA GreenCrash RAT contains network enumeration functionality\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0007_t1046\",\n",
    "    \"tactic_id\": \"ta0007\",\n",
    "    \"tactic_name\": \"Discovery\",\n",
    "    \"technique_id\": \"t1046\",\n",
    "    \"technique_name\": \"Network Service Discovery\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used a freely available PHP based port scanning tool\\nKRYPTONITE PANDA multitool contains network port scanning functionality\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0007_t1082\",\n",
    "    \"tactic_id\": \"ta0007\",\n",
    "    \"tactic_name\": \"Discovery\",\n",
    "    \"technique_id\": \"t1082\",\n",
    "    \"technique_name\": \"System Information Discovery\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA JJDOOR captures host enumeration data\\nKRYPTONITE PANDA GreenCrash RAT contains host enumeration functionality\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0008_t1021.002\",\n",
    "    \"tactic_id\": \"ta0008\",\n",
    "    \"tactic_name\": \"Lateral Movement\",\n",
    "    \"technique_id\": \"t1021.002\",\n",
    "    \"technique_name\": \"SMB/Windows Admin Shares\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA multitool contains functionality to administer Windows administrative functions over SMB\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0009_t1056.001\",\n",
    "    \"tactic_id\": \"ta0009\",\n",
    "    \"tactic_name\": \"Collection\",\n",
    "    \"technique_id\": \"t1056.001\",\n",
    "    \"technique_name\": \"Keylogging\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA deployed a custom keylogger tool with the filename dbgeng.dll \"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0009_t1074.001\",\n",
    "    \"tactic_id\": \"ta0009\",\n",
    "    \"tactic_name\": \"Collection\",\n",
    "    \"technique_id\": \"t1074.001\",\n",
    "    \"technique_name\": \"Local Data Staging\",\n",
    "    \"observables\": [\n",
    "      \"Data staged in unspecified locations for data exfil\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0009_t1074.002\",\n",
    "    \"tactic_id\": \"ta0009\",\n",
    "    \"tactic_name\": \"Collection\",\n",
    "    \"technique_id\": \"t1074.002\",\n",
    "    \"technique_name\": \"Remote Data Staging\",\n",
    "    \"observables\": [\n",
    "      \"Data moved from compromised hosts to central host prior to exfil\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0009_t1560\",\n",
    "    \"tactic_id\": \"ta0009\",\n",
    "    \"tactic_name\": \"Collection\",\n",
    "    \"technique_id\": \"t1560\",\n",
    "    \"technique_name\": \"Archive Collected Data\",\n",
    "    \"observables\": [\n",
    "      \"Archived data for exfiltration\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0010_t1041\",\n",
    "    \"tactic_id\": \"ta0010\",\n",
    "    \"tactic_name\": \"Exfiltration\",\n",
    "    \"technique_id\": \"t1041\",\n",
    "    \"technique_name\": \"Exfiltration Over C2 Channel\",\n",
    "    \"observables\": [\n",
    "      \"Unspecified use\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0010_t1567.002\",\n",
    "    \"tactic_id\": \"ta0010\",\n",
    "    \"tactic_name\": \"Exfiltration\",\n",
    "    \"technique_id\": \"t1567.002\",\n",
    "    \"technique_name\": \"Exfiltration to Cloud Storage\",\n",
    "    \"reports\": [\n",
    "      \"CSIT-22252\"\n",
    "    ],\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA exfiltrated stolen data to GitHub and Dropbox \"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0011_t1001.003\",\n",
    "    \"tactic_id\": \"ta0011\",\n",
    "    \"tactic_name\": \"Command and Control\",\n",
    "    \"technique_id\": \"t1001.003\",\n",
    "    \"technique_name\": \"Protocol Impersonation\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA JJDOOR implant uses Base64 to encode content within command and control traffic\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0011_t1043\",\n",
    "    \"tactic_id\": \"ta0011\",\n",
    "    \"tactic_name\": \"Command and Control\",\n",
    "    \"technique_id\": \"t1043\",\n",
    "    \"technique_name\": \"Commonly Used Port\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA Green Rash RAT has used TCP ports 443 and 8080 for command and control communications\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0011_t1071.001\",\n",
    "    \"tactic_id\": \"ta0011\",\n",
    "    \"tactic_name\": \"Command and Control\",\n",
    "    \"technique_id\": \"t1071.001\",\n",
    "    \"technique_name\": \"Web Protocols\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA JJDOOR implant uses HTTP for command and control communications\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0011_t1095\",\n",
    "    \"tactic_id\": \"ta0011\",\n",
    "    \"tactic_name\": \"Command and Control\",\n",
    "    \"technique_id\": \"t1095\",\n",
    "    \"technique_name\": \"Non-Application Layer Protocol\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA GreenCrash RAT uses the Windows Socket Library to send and receive a PLib8-compressed data messages between the RAT and the C2 server.\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0011_t1102\",\n",
    "    \"tactic_id\": \"ta0011\",\n",
    "    \"tactic_name\": \"Command and Control\",\n",
    "    \"technique_id\": \"t1102\",\n",
    "    \"technique_name\": \"Web Service\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used Simple Object Access Protocol (SOAP) to retrieve additional payloads\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0011_t1102.001\",\n",
    "    \"tactic_id\": \"ta0011\",\n",
    "    \"tactic_name\": \"Command and Control\",\n",
    "    \"technique_id\": \"t1102.001\",\n",
    "    \"technique_name\": \"Dead Drop Resolver\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used wordpress services as dead drop resolvers for GreenCrash RAT tasking data\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0011_t1105\",\n",
    "    \"tactic_id\": \"ta0011\",\n",
    "    \"tactic_name\": \"Command and Control\",\n",
    "    \"technique_id\": \"t1105\",\n",
    "    \"technique_name\": \"Ingress Tool Transfer\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used the URLDownloadToFileA function to retrieve externally hosted content\\nKRYPTONITE PANDA has used Simple Object Access Protocol (SOAP) to retrieve additional payloads\\nKRYPTONITE PANDA has used a custom downloader with the filename rcdll.dll to retrieve external payloads\\nKRYPTONITE PANDA has used a custom downloader JavaScript downloader with the filename 0.js\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0011_t1571\",\n",
    "    \"tactic_id\": \"ta0011\",\n",
    "    \"tactic_name\": \"Command and Control\",\n",
    "    \"technique_id\": \"t1571\",\n",
    "    \"technique_name\": \"Non-Standard Port\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA Green Rash RAT has used TCP port 8084 for command and control communications\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0011_t1572\",\n",
    "    \"tactic_id\": \"ta0011\",\n",
    "    \"tactic_name\": \"Command and Control\",\n",
    "    \"technique_id\": \"t1572\",\n",
    "    \"technique_name\": \"Protocol Tunneling\",\n",
    "    \"observables\": [\n",
    "      \"Unspecified use\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0042_t1583.001\",\n",
    "    \"tactic_id\": \"ta0042\",\n",
    "    \"tactic_name\": \"Resource Development\",\n",
    "    \"technique_id\": \"t1583.001\",\n",
    "    \"technique_name\": \"Domains\",\n",
    "    \"observables\": [\n",
    "      \"Creation of typosquatting domains\",\n",
    "      \"KRYPTONITE PANDA has registered domain names relevant to target scope for use as command-and-control and hosting infrastructure including: \\nairbusocean[.]com, teledynegroup[.]com, scsnewstoday[.]com, www.thyssenkrupp-marinesystems[.]org\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0042_t1583.002\",\n",
    "    \"tactic_id\": \"ta0042\",\n",
    "    \"tactic_name\": \"Resource Development\",\n",
    "    \"technique_id\": \"t1583.002\",\n",
    "    \"technique_name\": \"DNS Server\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA employs multiple DNS name servers as part of infrastructure management including:\\nGoDaddy, Namecheap, CloudFlare\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0042_t1583.003\",\n",
    "    \"tactic_id\": \"ta0042\",\n",
    "    \"tactic_name\": \"Resource Development\",\n",
    "    \"technique_id\": \"t1583.003\",\n",
    "    \"technique_name\": \"Virtual Private Server\",\n",
    "    \"reports\": [\n",
    "      \"CSA-250446\"\n",
    "    ],\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA typically hosts VPS infrastructure at Vultr (AS20473) and Digital Ocean (AS14061)\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0042_t1587.003\",\n",
    "    \"tactic_id\": \"ta0042\",\n",
    "    \"tactic_name\": \"Resource Development\",\n",
    "    \"technique_id\": \"t1587.003\",\n",
    "    \"technique_name\": \"Digital Certificates\",\n",
    "    \"observables\": [\n",
    "      \"KRYPTONITE PANDA has used self signed certificates with the subject and issuer field set to C=US, ST=Texas, L=Austin, O=Development, CN=localhost\"\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"id\": \"ta0043_t1589.001\",\n",
    "    \"tactic_id\": \"ta0043\",\n",
    "    \"tactic_name\": \"Reconnaissance\",\n",
    "    \"technique_id\": \"t1589.001\",\n",
    "    \"technique_name\": \"Credentials\",\n",
    "    \"observables\": [\n",
    "      \"Stole credentials\"\n",
    "    ]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYbWde1j-GdO"
   },
   "source": [
    "Using the processed attack chain data, generate an ASOM for KRYPTONITE PANDA. This code exports both  the full ASOM where all rows are distinct, better suited for further machine processing, as well as the finished ASOM where like cells are merged to create the nested structure depicted in TC 3-12.2.4.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 61554,
     "status": "aborted",
     "timestamp": 1752686236293,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "6mBR99oyocMb"
   },
   "outputs": [],
   "source": [
    "attack_chain_data = generate_attack_chain_data(actor_data)\n",
    "\n",
    "log(\"Building ASOM...\")\n",
    "resulting_asom = build_asom(attack_chain_data)\n",
    "log(\"Finished.\")\n",
    "\n",
    "formatted_df = format_asom(resulting_asom)\n",
    "\n",
    "representative_ccirs_map = get_representative_ccirs_by_tactic_simplified(formatted_df)\n",
    "\n",
    "# Perform the update and grouping\n",
    "updated_df = update_ccirs(formatted_df, representative_ccirs_map)\n",
    "\n",
    "updated_df = update_sequential_ccir_index(updated_df)\n",
    "updated_df = update_hierarchical_indicator_index(updated_df)\n",
    "updated_df = update_final_evidence_index(updated_df, indicator_index_col = \"Indicator Index\", output_evidence_index_col = \"Evidence Index\")\n",
    "\n",
    "# Export the full ASOM\n",
    "updated_df.to_excel(\"kryptonite-panda_full.xlsx\")\n",
    "\n",
    "final_df = create_visually_spanned_df(updated_df)\n",
    "\n",
    "print(\"final_df (with MultiIndex for visual spanning):\")\n",
    "# Displaying the DataFrame with to_string() often shows the MultiIndex spanning.\n",
    "# In Jupyter notebooks, just `display(final_df)` or `final_df` would also work well.\n",
    "with pd.option_context('display.max_rows', None, # Show all rows to see full effect\n",
    "                        'display.width', 1200,    # Adjust width as needed\n",
    "                        'display.max_colwidth', 30,\n",
    "                        'display.expand_frame_repr', False # Prevent wrapping if too wide for console\n",
    "                        ):\n",
    "    # display(final_df)\n",
    "    display(final_df.filter(items=[\"CCIR Index\", \"CCIR\", \"Indicator Index\", \"Indicator\", \"Evidence Index\", \"Evidence\", \"Data\", \"NAI\", \"Action\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 61556,
     "status": "aborted",
     "timestamp": 1752686236295,
     "user": {
      "displayName": "Zac Szewczyk",
      "userId": "04745897818059392175"
     },
     "user_tz": 240
    },
    "id": "SzxfUXfTq46Z"
   },
   "outputs": [],
   "source": [
    "# Export the merged ASOM\n",
    "final_df.to_excel(\"kryptonite-panda_merged.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
