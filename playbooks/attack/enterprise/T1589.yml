name: T1589: Gather Victim Identity Information
id: f47ac10b-58cc-4372-a567-0e02b2c3d479
description: Is an adversary actively gathering our organization's identity information for targeting? This playbook helps detect reconnaissance activity focused on harvesting credentials and identity data. It identifies threats from known malicious sources (scanners, proxies, TOR nodes), unusual authentication patterns like credential testing and username enumeration, the use of automated reconnaissance tools, web scraping of employee information, and large-scale attacks such as password spraying and credential stuffing.
type: technique
related:
  - TA0043: Reconnaissance
contributors: Zachary Szewczyk, Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Are we observing network or authentication activity from known malicious IP addresses (scanners, proxies, TOR nodes)?
    context: This question helps identify initial reconnaissance attempts. Adversaries often use compromised infrastructure, open proxies, or TOR to obscure their origin. Correlating inbound traffic with high-confidence threat intelligence feeds provides an early warning that an unknown entity is probing the organization's perimeter for weaknesses.
    answer_sources:
      - Zeek conn.log
      - Zeek http.log
      - Windows Event ID 4625
      - Windows Event ID 4624
      - Externally-facing authentication services (e.g., VPN, OWA, M365), public web servers, network firewalls/gateways
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each event in (conn.log, http.log, auth.log)
          IF event.source_ip is in (threat_intel_feed['scanner', 'proxy', 'TOR'])
          THEN CREATE alert

  - question: Is any external IP address exhibiting a statistically high ratio of failed to successful authentications?
    context: This question helps detect credential testing or brute-force attempts. By establishing a baseline for the normal ratio of failed-to-successful logins from external IPs, analysts can spot significant deviations. An IP with a failure ratio in the 95th percentile or higher is a strong indicator of an automated attack trying to validate credentials.
    answer_sources:
      - Zeek conn.log
      - Zeek http.log
      - Windows Event ID 4625
      - Windows Event ID 4624
      - Externally-facing authentication services (e.g., VPN, OWA, M365), public web servers, network firewalls/gateways
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          DEFINE baseline_failure_ratio = 95th_percentile(failed_auths / total_auths) FOR all external_ips
          FOR each external_ip in last 1 hour
            current_ratio = count(event_id=4625) / count(event_id IN [4624, 4625])
            IF current_ratio > baseline_failure_ratio
            THEN CREATE alert

  - question: Can we classify external authentication attempts in real-time to identify high-risk activity?
    context: This question moves beyond simple thresholds to a more sophisticated, risk-based approach. A machine learning model can analyze multiple features simultaneously (IP reputation, ASN, geolocation, time of day) to assign a risk score to each login. This helps reduce false positives from simple heuristics and can uncover more subtle or slow-paced attacks.
    answer_sources:
      - Zeek conn.log
      - Zeek http.log
      - Windows Event ID 4625
      - Windows Event ID 4624
      - Externally-facing authentication services (e.g., VPN, OWA, M365), public web servers, network firewalls/gateways
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each external_authentication_event
            features = [ip_reputation, asn_info, geo_rarity, time_of_day]
            risk_score = classification_model.predict(features)
            IF risk_score > 0.9
            THEN CREATE alert

  - question: Are we detecting HTTP requests with User-Agent strings indicative of automated reconnaissance tools?
    context: This question focuses on identifying the adversary's toolkit. Many automated scanning and exploitation tools use default or easily identifiable User-Agent strings. Maintaining a list of these signatures and matching them against web logs is a simple and effective way to detect active reconnaissance.
    answer_sources:
      - Zeek http.log
      - Public web servers, application load balancers, web application firewalls (WAFs)
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          DEFINE tool_signatures = ['nmap', 'sqlmap', 'feroxbuster', 'gobuster', 'dirbuster']
          FOR each event in http.log
            IF event.user_agent MATCHES any in tool_signatures
            THEN CREATE alert

  - question: Is any source IP showing an anomalously low User-Agent entropy combined with a high request count?
    context: This question helps differentiate automated tools from human users based on behavior. A human user's browser might present slightly different User-Agent strings over time or use multiple browsers, while an automated tool will typically use the exact same string for thousands of requests. A low entropy (low variety) in User-Agents, combined with a high request volume, is a strong signal of automation.
    answer_sources:
      - Zeek http.log
      - Public web servers, application load balancers, web application firewalls (WAFs)
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each source_ip in a 5-minute window
            ua_entropy = shannon_entropy(unique(user_agents))
            request_count = count(requests)
            IF ua_entropy < 5th_percentile AND request_count > 95th_percentile
            THEN CREATE alert

  - question: Are there web traffic sequences from any IP that are statistically improbable for a human user?
    context: This question aims to detect non-human browsing patterns that signature-based methods might miss. By modeling normal user navigation paths (e.g., home -> about -> contact), a sequence analysis model can identify when a source IP is making requests in an order that is highly unlikely for a person, such as systematically crawling every single API endpoint.
    answer_sources:
      - Zeek http.log
      - Public web servers, application load balancers, web application firewalls (WAFs)
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each source_ip
            uri_sequence = get_sequence_of_uris(last_10_minutes)
            sequence_probability = rnn_model.predict_probability(uri_sequence)
            IF sequence_probability is LOW
            THEN CREATE alert

  - question: Has any single IP address generated a high volume of failed logins due to non-existent usernames in a short time frame?
    context: This question is designed to detect username enumeration. When adversaries have a list of potential usernames, they often test them against a login portal. This generates a large number of failed authentications with the specific error 'user name does not exist'. A simple threshold rule can effectively catch this brute-force discovery technique.
    answer_sources:
      - Windows Event ID 4625
      - Domain Controllers, Active Directory Federation Services (ADFS), RADIUS servers, any centralized authentication server
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each source_ip
            count = count(event_id=4625 AND status_code='0xC0000064') in last 10 minutes
            IF count > 20
            THEN CREATE alert

  - question: Is any source IP attempting to log in with a set of usernames that has an unusually high entropy?
    context: This question provides another way to detect username enumeration, particularly when the attacker is guessing or generating usernames rather than using a pre-compiled list. A high entropy (high randomness) in the set of attempted usernames from a single source suggests the names are not due to user typos but are programmatically generated, indicating a discovery attempt.
    answer_sources:
      - Windows Event ID 4625
      - Domain Controllers, Active Directory Federation Services (ADFS), RADIUS servers, any centralized authentication server
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each source_ip in a 15-minute window
            username_entropy = shannon_entropy(unique(target_usernames))
            IF username_entropy > 98th_percentile_of_baseline
            THEN CREATE alert

  - question: Can we use clustering algorithms to automatically identify dense groups of failed authentications that represent username enumeration campaigns?
    context: This question offers a more advanced, unsupervised machine learning approach to finding enumeration. Unlike fixed thresholds, a density-based clustering algorithm like DBSCAN can dynamically identify clusters of activity where one IP is responsible for a high density of failed logins against many accounts, effectively separating attack campaigns from sparse, legitimate login failures.
    answer_sources:
      - Windows Event ID 4625
      - Domain Controllers, Active Directory Federation Services (ADFS), RADIUS servers, any centralized authentication server
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          features = [source_ip, timestamp, target_username] from failed_auth_logs
          clusters = dbscan_algorithm.fit(features)
          FOR each cluster identified as an outlier/attack
          THEN CREATE alert

  - question: Is any external IP accessing an unusually high number of sensitive pages containing identity information?
    context: This question is aimed at detecting web scraping of employee or identity information. By defining a list of sensitive URIs (e.g., team pages, staff directories, user profile APIs), an organization can monitor for and alert on any single IP that accesses an abnormally high number of these pages in a short period, which is indicative of automated harvesting.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Public-facing corporate website, employee directory pages, API gateways
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          DEFINE sensitive_uris = ['/api/users/*', '/about/staff']
          FOR each source_ip
            count = count(requests to sensitive_uris) in last 5 minutes
            IF count > 25
            THEN CREATE alert

  - question: Is any source IP exhibiting a web request pattern with both a high request rate and an unnaturally consistent timing between requests?
    context: This question helps to identify automated scraping by analyzing its cadence. Human browsing is typically bursty and irregular. In contrast, a script or tool will often make requests at a high, consistent rate. Alerting on the combination of a high request rate (99th percentile) and a very low standard deviation in inter-request timing (1st percentile) effectively fingerprints this robotic behavior.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Public-facing corporate website, employee directory pages, API gateways
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each source_ip in a 10-minute window
            rate = requests / minute
            timing_std_dev = std_dev(time_between_requests)
            IF rate > 99th_percentile AND timing_std_dev < 1st_percentile
            THEN CREATE alert

  - question: Are we observing anomalous spikes in request volume to sensitive directories that deviate from normal traffic patterns?
    context: This question uses time-series analysis to detect scraping against a dynamic baseline. A forecasting model can learn the normal ebb and flow of traffic to sensitive pages (e.g., higher during business hours, lower at night). An alert is triggered only when the observed traffic significantly exceeds the model's prediction, allowing it to catch unusual spikes that might be missed by static thresholds.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Public-facing corporate website, employee directory pages, API gateways
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          model = arima_model.train(historical_request_volume_to_sensitive_dirs)
          predicted_volume, confidence_interval = model.forecast(current_time)
          IF observed_volume > confidence_interval.upper_bound
          THEN CREATE alert

  - question: Are we detecting authentication patterns consistent with Password Spraying (one IP, many accounts) or Credential Stuffing (many IPs, one account)?
    context: This question uses simple thresholds to detect two of the most common large-scale authentication attacks. Password Spraying involves trying one password against many accounts from a single source. Credential Stuffing involves trying many stolen credentials for one account from many sources. By counting the number of distinct accounts per IP and distinct IPs per account, we can create specific rules to detect each attack type.
    answer_sources:
      - Windows Event ID 4625
      - Windows Event ID 4624
      - Externally-facing authentication services (e.g., VPN, OWA, M365), Domain Controllers
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          // Password Spraying
          IF count(distinct_accounts) > 15 FOR a single_source_ip in 30 mins
          THEN CREATE alert
          // Credential Stuffing
          IF count(distinct_source_ips) > 10 FOR a single_account in 30 mins
          THEN CREATE alert

  - question: Are there anomalous ratios of unique accounts per source IP, or unique source IPs per account, in our authentication logs?
    context: This question provides a more robust, statistical method for detecting password spraying and credential stuffing. In a password spray, the ratio of unique accounts to total attempts from one IP will be close to 1.0. In credential stuffing, the ratio of unique source IPs to total attempts on one account will be high. By baselining these ratios, we can alert on statistically significant deviations.
    answer_sources:
      - Windows Event ID 4625
      - Windows Event ID 4624
      - Externally-facing authentication services (e.g., VPN, OWA, M365), Domain Controllers
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          // Password Spraying
          ratio_spray = unique_accounts / total_attempts BY source_ip
          IF ratio_spray > 99th_percentile_of_baseline
          THEN CREATE alert
          // Credential Stuffing
          ratio_stuff = unique_source_ips / total_attempts BY target_account
          IF ratio_stuff > 99th_percentile_of_baseline
          THEN CREATE alert

  - question: Can we automatically classify bursts of authentication activity as normal, brute force, password spraying, or credential stuffing?
    context: This question represents the most advanced detection method, using a multi-class classification model. By training a model on features aggregated over time windows (e.g., unique IP count, unique account count, success/fail ratio), the system can learn to automatically distinguish between different types of malicious authentication patterns and normal user activity, providing specific and high-fidelity alerts.
    answer_sources:
      - Windows Event ID 4625
      - Windows Event ID 4624
      - Externally-facing authentication services (e.g., VPN, OWA, M365), Domain Controllers
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each 15-minute window of authentication activity
            features = [count(unique_ips), count(unique_accounts), success_ratio, geo_entropy]
            attack_type = classification_model.predict(features)
            IF attack_type is not 'normal'
            THEN CREATE alert with attack_type