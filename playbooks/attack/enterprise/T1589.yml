name: "T1589: Gather Victim Identity Information"
id: "f47ac10b-58cc-4372-a567-0e02b2c3d479"
description: "This playbook helps determine if an adversary is actively gathering identity information from the organization for targeting purposes. It focuses on identifying reconnaissance activities such as probing from known malicious IP addresses (scanners, proxies, TOR nodes), the use of automated scanning tools identified by their User-Agent strings, username enumeration through high volumes of failed logins, web scraping of public-facing employee directories, and large-scale authentication anomalies like password spraying and credential stuffing."
type: "technique"
related:
  - "TA0043: Reconnaissance"
contributors:
  - "Zachary Szewczyk"
  - "Ask Sage"
created: "2025-10-01"
modified: "2025-10-01"
version: "1.0"
tags: "none"
questions:
  - question: "Have any recent network connections, web requests, or authentication attempts originated from IP addresses known to be scanners, open proxies, or TOR exit nodes?"
    context: "This question aims to identify reconnaissance activity from sources with a pre-established malicious reputation. Matching traffic against threat intelligence feeds is a high-fidelity method to detect the earliest stages of an attack, where adversaries use automated tools or anonymizing networks to probe for vulnerabilities without revealing their true origin."
    answer_sources:
      - "Zeek conn.log"
      - "Zeek http.log"
      - "Windows Event ID 4625"
      - "Windows Event ID 4624"
      - "Externally-facing authentication services (e.g., VPN, OWA, M365)"
      - "Public web servers"
      - "Network firewalls/gateways"
      - "Threat Intelligence Feeds"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          FOR each event in (conn.log, http.log, auth_logs):
            IF event.source_ip is in threat_intel_feed('scanner', 'proxy', 'TOR'):
              RETURN event
  - question: "Are any external IP addresses exhibiting an anomalously high ratio of failed to successful authentications compared to our established baseline?"
    context: "This question helps detect brute-force or credential testing attempts that may not use known malicious IPs. By establishing a statistical baseline for normal authentication failure rates, we can spot outliers. An IP address with a failure ratio in the 95th percentile or higher is behaving abnormally, suggesting an automated attempt to guess credentials or validate usernames."
    answer_sources:
      - "Windows Event ID 4625"
      - "Windows Event ID 4624"
      - "Externally-facing authentication services (e.g., VPN, OWA, M365)"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          DEFINE baseline_failure_ratio = 95th_percentile(failed_auth / total_auth) FOR all external IPs
          FOR each source_ip in 1_hour_window:
            current_ratio = count(event_id=4625) / count(event_id in [4624, 4625])
            IF current_ratio > baseline_failure_ratio:
              RETURN source_ip, current_ratio
  - question: "Have any external authentication attempts been assigned a high risk score by our machine learning model based on features like IP reputation, ASN, geolocation, and time of day?"
    context: "This question leverages a machine learning model to perform a more nuanced risk assessment than simple rules can provide. The model considers multiple factors simultaneously (IP reputation, ASN, location rarity, time) to identify suspicious authentication attempts that might individually appear benign. A high risk score indicates a combination of factors that strongly correlates with malicious reconnaissance behavior."
    answer_sources:
      - "Windows Event ID 4625"
      - "Windows Event ID 4624"
      - "Externally-facing authentication services (e.g., VPN, OWA, M365)"
      - "Threat Intelligence Feeds"
      - "Geolocation Database"
      - "ASN Database"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          FOR each auth_event from external IP:
            features = (ip_rep, asn_info, geo_rarity, time_of_day)
            risk_score = ml_model.predict(features)
            IF risk_score > 0.9:
              RETURN auth_event, risk_score
  - question: "Have we observed any web requests with User-Agent strings matching known reconnaissance tools like nmap, sqlmap, or gobuster?"
    context: "This question focuses on identifying adversaries by the tools they use. Many automated reconnaissance tools use unique, identifiable User-Agent strings. Searching for these strings in web logs is a straightforward and effective way to detect scanning and probing activities against public-facing web applications."
    answer_sources:
      - "Zeek http.log"
      - "Public web servers"
      - "Application load balancers"
      - "Web application firewalls (WAFs)"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          DEFINE recon_tool_signatures = ['nmap', 'sqlmap', 'feroxbuster', 'gobuster', 'dirbuster']
          FOR each event in http.log:
            IF event.user_agent matches any in recon_tool_signatures:
              RETURN event
  - question: "Are any source IPs exhibiting unusually low User-Agent diversity combined with a high request count, suggesting a single automated tool is in use?"
    context: "This question helps to identify automated activity that may not use a known malicious User-Agent. A normal human user might use a few different browsers or devices, resulting in some User-Agent variety. An automated script or tool will typically use the exact same User-Agent for thousands of requests, resulting in near-zero diversity (entropy). This combination of low entropy and high activity is a strong indicator of reconnaissance."
    answer_sources:
      - "Zeek http.log"
      - "Public web servers"
      - "Application load balancers"
      - "Web application firewalls (WAFs)"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          DEFINE low_entropy_threshold = 5th_percentile(shannon_entropy(user_agents))
          DEFINE high_request_threshold = 95th_percentile(request_count)
          FOR each source_ip in 5_minute_window:
            entropy = shannon_entropy(source_ip.user_agents)
            requests = count(source_ip.requests)
            IF entropy < low_entropy_threshold AND requests > high_request_threshold:
              RETURN source_ip
  - question: "Has our sequence analysis model detected any user navigation paths with a low probability of occurrence, indicating automated or non-human browsing?"
    context: "This question uses advanced analytics to detect sophisticated scanning that mimics human behavior. By modeling normal user navigation paths (sequences of web page visits), a Recurrent Neural Network (RNN) can identify sequences that are statistically unlikely for a human user. This can reveal automated tools that are systematically crawling a site for information, even if they vary their User-Agent and request timing."
    answer_sources:
      - "Zeek http.log"
      - "Public web servers"
      - "Application load balancers"
      - "Web application firewalls (WAFs)"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          FOR each ip_session:
            uri_sequence = get_ordered_uris(ip_session)
            probability = rnn_model.predict_probability(uri_sequence)
            IF probability is below anomaly_threshold:
              RETURN ip_session, probability
  - question: "Has any single IP address generated more than 20 failed login attempts due to a non-existent username within a 10-minute window?"
    context: "This question aims to detect username enumeration. When an adversary has a list of potential usernames, they may try to validate them against an authentication endpoint. A high count of failed logins with the specific error 'user name does not exist' from a single source is a strong indicator of this activity. This is a simple but powerful threshold-based alert."
    answer_sources:
      - "Windows Event ID 4625"
      - "Domain Controllers"
      - "Active Directory Federation Services (ADFS)"
      - "RADIUS servers"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          GROUP events by source_ip over 10_minute_window:
            failed_logins = count(event_id=4625 AND status_code='0xC0000064')
            IF failed_logins > 20:
              RETURN source_ip, failed_logins
  - question: "Are any source IPs attempting to log in with a set of usernames that has an anomalously high entropy, suggesting programmatic username generation?"
    context: "This question seeks to identify username enumeration that uses randomly generated or algorithmically derived usernames rather than a pre-compiled list. Normal login failures (e.g., typos) have low username entropy. A high entropy value for the set of attempted usernames from a single IP suggests the usernames are not random typos but are being generated systematically, which is a hallmark of an automated attack."
    answer_sources:
      - "Windows Event ID 4625"
      - "Domain Controllers"
      - "Active Directory Federation Services (ADFS)"
      - "RADIUS servers"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          DEFINE high_entropy_threshold = 98th_percentile(shannon_entropy(usernames))
          FOR each source_ip in 15_minute_window:
            entropy = shannon_entropy(source_ip.attempted_usernames)
            IF entropy > high_entropy_threshold:
              RETURN source_ip, entropy
  - question: "Has our clustering algorithm identified any high-density groups of failed login attempts originating from a single source against multiple accounts?"
    context: "This question uses unsupervised machine learning (DBSCAN) to automatically find username enumeration campaigns without pre-defined thresholds. The algorithm groups authentication failures based on their features (source IP, timestamp, username). It will naturally identify dense clusters of activity, such as one IP rapidly trying many usernames, and separate them from the sparse, random noise of legitimate failed logins."
    answer_sources:
      - "Windows Event ID 4625"
      - "Domain Controllers"
      - "Active Directory Federation Services (ADFS)"
      - "RADIUS servers"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          features = select(source_ip, timestamp, target_username) FROM auth_failures
          clusters = dbscan.fit_predict(features)
          RETURN events in high-density_clusters
  - question: "Has any single external IP address requested more than 25 sensitive URIs (e.g., employee directories, user APIs) within a 5-minute window?"
    context: "This question is designed to detect web scraping of pages known to contain identity information. By defining a list of sensitive URIs (like 'About Us' pages or staff directories) and setting a request threshold, we can quickly identify when a single source is attempting to harvest this information in bulk."
    answer_sources:
      - "Zeek http.log"
      - "Zeek conn.log"
      - "Public-facing corporate website"
      - "Employee directory pages"
      - "API gateways"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          DEFINE sensitive_uris = ['/api/users/*', '/about/staff', '/team']
          GROUP requests by source_ip over 5_minute_window:
            sensitive_requests = count(uri in sensitive_uris)
            IF sensitive_requests > 25:
              RETURN source_ip, sensitive_requests
  - question: "Are any source IPs exhibiting both a very high request rate and a very low standard deviation in the time between requests, characteristic of automated web scraping?"
    context: "This question identifies automated scraping by its behavioral fingerprint. Unlike humans, who browse at irregular intervals, automated scripts often make requests at a very consistent, rapid pace. This results in a high number of requests per minute and a very low standard deviation of the time between those requests. Finding an IP that matches both criteria is a strong signal of automation."
    answer_sources:
      - "Zeek http.log"
      - "Zeek conn.log"
      - "Public-facing corporate website"
      - "Employee directory pages"
      - "API gateways"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          DEFINE high_rate = 99th_percentile(requests_per_minute)
          DEFINE low_std_dev = 1st_percentile(std_dev(inter_request_time))
          FOR each source_ip in 10_minute_window:
            rate = source_ip.requests_per_minute
            timing_std_dev = std_dev(source_ip.inter_request_times)
            IF rate > high_rate AND timing_std_dev < low_std_dev:
              RETURN source_ip
  - question: "Has our time series model detected a request volume to sensitive directories that significantly exceeds the predicted normal patterns?"
    context: "This question uses a forecasting model to find anomalous spikes in traffic to sensitive pages. The model learns the normal rhythm of the business, including daily and weekly access patterns. When the actual observed traffic volume dramatically exceeds the model's prediction, it signals an abnormal event, such as a large-scale scraping campaign, that warrants investigation."
    answer_sources:
      - "Zeek http.log"
      - "Zeek conn.log"
      - "Public-facing corporate website"
      - "Employee directory pages"
      - "API gateways"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          FOR each time_interval for sensitive URIs:
            observed_volume = count(requests)
            predicted_volume, confidence_interval = arima_model.predict()
            IF observed_volume > confidence_interval.upper_bound:
              RETURN time_interval, observed_volume
  - question: "Have we detected password spraying (one IP, >15 failed accounts in 30 mins) or credential stuffing (one account, >10 IPs with failed logins in 30 mins)?"
    context: "This question looks for two common large-scale authentication attacks. Password spraying is a one-to-many attack (one IP, many accounts), while credential stuffing is a many-to-one attack (many IPs, one account). Using simple, distinct thresholds for each allows for the clear detection and differentiation of these two attack patterns."
    answer_sources:
      - "Windows Event ID 4625"
      - "Windows Event ID 4624"
      - "Externally-facing authentication services (e.g., VPN, OWA, M365)"
      - "Domain Controllers"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          // Password Spraying Detection
          GROUP failed_logins by source_ip over 30_min_window:
            IF count(distinct user_accounts) > 15:
              RETURN 'Password Spraying Detected', source_ip
          
          // Credential Stuffing Detection
          GROUP failed_logins by user_account over 30_min_window:
            IF count(distinct source_ips) > 10:
              RETURN 'Credential Stuffing Detected', user_account
  - question: "Are we observing anomalous ratios indicative of password spraying (unique accounts to total attempts approaches 1.0) or credential stuffing (unique IPs to total attempts is high)?"
    context: "This question provides a more dynamic way to detect password spraying and credential stuffing by analyzing ratios instead of fixed counts. For password spraying, an attacker tries one password against many accounts, so the ratio of unique accounts to attempts will be near 1.0. For credential stuffing, many sources try to log into one account, so the ratio of unique IPs to attempts will be high. Comparing these ratios to a historical baseline can detect attacks of varying scales."
    answer_sources:
      - "Windows Event ID 4625"
      - "Windows Event ID 4624"
      - "Externally-facing authentication services (e.g., VPN, OWA, M365)"
      - "Domain Controllers"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          // Password Spraying
          GROUP auth_events by source_ip over 1_hour_window:
            ratio = unique_accounts / total_attempts
            IF ratio > 99th_percentile_baseline_for_spraying:
              RETURN 'Possible Password Spraying', source_ip
          
          // Credential Stuffing
          GROUP auth_events by user_account over 1_hour_window:
            ratio = unique_source_ips / total_attempts
            IF ratio > 99th_percentile_baseline_for_stuffing:
              RETURN 'Possible Credential Stuffing', user_account
  - question: "Has our multi-class classification model identified any recent bursts of authentication activity as password spraying or credential stuffing?"
    context: "This question employs a sophisticated machine learning model to classify bursts of authentication activity in near-real-time. By training the model on features that characterize different attack types (e.g., number of unique IPs, number of unique accounts, success/failure ratio), it can distinguish between normal behavior, credential stuffing, and password spraying with greater accuracy than individual rules, reducing false positives."
    answer_sources:
      - "Windows Event ID 4625"
      - "Windows Event ID 4624"
      - "Externally-facing authentication services (e.g., VPN, OWA, M365)"
      - "Domain Controllers"
    range: "last 90 days"
    queries:
      - technology: "pseudocode"
        query: |
          FOR each 15_minute_window:
            features = aggregate(unique_ips, unique_accounts, success_ratio, geo_entropy)
            prediction = ml_model.predict(features)
            IF prediction in ['password_spraying', 'credential_stuffing']:
              RETURN window, prediction