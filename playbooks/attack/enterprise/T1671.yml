name: T1671: Cloud Application Integration
id: 5a8a183d-3a70-4f5e-a4b3-96898160424b
description: This playbook helps determine if an adversary is maintaining persistence
  by leveraging cloud application integrations. It investigates several key indicators,
  such as cloud application registrations that match known-bad threat intelligence,
  the use of impersonation or typosquatting in application names, or applications
  from unverified publishers with newly registered domains. The playbook also looks
  for consents to applications with high-risk permissions, consents from geographically
  anomalous locations, deviations in a service principal's data access patterns from
  an established baseline, and the close temporal link between the creation of a service
  principal on an endpoint and its first use in the cloud.
type: technique
related:
- TA0003: Persistence
contributors:
- Zachary Szewczyk
- Ask Sage
created: '2025-10-01'
modified: '2025-10-01'
version: 1.0
tags: none
investigative_questions:
- question: Have any cloud applications been registered or consented to that match
    known-bad indicators from our threat intelligence feeds?
  context: This question seeks to identify overtly malicious applications by comparing
    their attributes (Application ID, publisher name, redirect URI) against a curated
    list of known IoCs. A match provides a high-confidence signal of a compromise
    attempt, allowing for immediate response.
  answer_sources:
  - Microsoft 365 Unified Audit Logs
  - Azure Active Directory Audit Logs
  - Threat Intelligence Platform Data
  - Microsoft Entra ID tenant
  - Threat intelligence platforms
  range: last 90 days
  queries:
  - 'QUERY audit logs for ''Add application'' or ''Consent to application'' events.
    FOR each event, EXTRACT AppID, Publisher, RedirectURI. CHECK if AppID, Publisher,
    or RedirectURI exist in threat intel feed. IF match, ALERT.'
- question: Has any user consented to an application from a publisher that is statistically
    rare or new to the organization?
  context: Adversaries often use applications from new or obscure publishers that
    have no legitimate business purpose in the target environment. This question
    helps identify these outliers by calculating the historical frequency of application
    consents per publisher domain. Consents to rarely seen publishers are flagged
    as suspicious, as they deviate from established organizational norms.
  answer_sources:
  - Microsoft 365 Unified Audit Logs
  - Azure Active Directory Audit Logs
  - Threat Intelligence Platform Data
  - Microsoft Entra ID tenant
  - Threat intelligence platforms
  range: last 180 days
  queries:
  - 'QUERY ''Consent to application'' events for the last 180 days. GROUP by publisher
    domain and COUNT consents. CALCULATE frequency percentile for each domain. QUERY
    for new consent events. IF new consent''s publisher domain is in <5th percentile,
    FLAG for review.'
- question: Can we use a machine learning model to predict whether a new application
    consent event is likely to be malicious?
  context: This question leverages a trained classification model to proactively
    identify malicious consent events that may evade simpler detection methods. By
    analyzing a combination of features like publisher details, redirect URI domain
    age, and requested permissions, the model provides a probabilistic risk score,
    enabling analysts to focus on the highest-risk events.
  answer_sources:
  - Microsoft 365 Unified Audit Logs
  - Azure Active Directory Audit Logs
  - Threat Intelligence Platform Data
  - Microsoft Entra ID tenant
  - Threat intelligence platforms
  range: last 90 days
  queries:
  - 'FOR new ''Consent to application'' event, EXTRACT features (publisher name properties,
    redirect URI domain age, permission scopes). INPUT features into trained classification
    model. IF model output probability > 0.85, ALERT.'
- question: Are there any new application registrations or consents with display
    names that appear to be impersonating legitimate applications through typosquatting
    or similar techniques?
  context: This question aims to detect a common adversary tactic: creating malicious
    applications with names that mimic well-known, trusted software to trick users
    into granting consent. By using regular expressions to search for common impersonation
    patterns (e.g., 'M.crosoft', 'Goog1e'), we can flag these suspicious applications
    for review.
  answer_sources:
  - Microsoft 365 Unified Audit Logs
  - Azure Active Directory Audit Logs
  - Public WHOIS Data
  - Zeek dns.log
  - Microsoft Entra ID tenant
  - Public DNS and WHOIS services
  - Network egress points
  range: last 90 days
  queries:
  - 'QUERY ''Add application'' or ''Consent to application'' events. FOR each event,
    APPLY regex patterns for typosquatting/impersonation to the application display
    name. IF pattern matches, ALERT.'
- question: Have any applications from unverified publishers with recently registered
    domains been introduced, or do any new applications have names very similar to
    existing legitimate applications?
  context: Adversaries often use newly created domains for their malicious infrastructure
    to evade reputation-based blocking. This question identifies two suspicious signals:
    applications from unverified publishers using domains created within the last
    90 days, and applications whose names are only slightly different (low Levenshtein
    distance) from known, trusted apps, suggesting an attempt to impersonate them.
  answer_sources:
  - Microsoft 365 Unified Audit Logs
  - Azure Active Directory Audit Logs
  - Public WHOIS Data
  - Zeek dns.log
  - Microsoft Entra ID tenant
  - Public DNS and WHOIS services
  - Network egress points
  range: last 90 days
  queries:
  - 'FOR new unverified publisher app, GET publisher domain. QUERY WHOIS for domain
    creation date. IF date < 90 days ago, FLAG. SEPARATELY, CALCULATE Levenshtein
    distance between new app name and list of known app names. IF distance is 1 or
    2, FLAG.'
- question: Can we use unsupervised machine learning to identify clusters of anomalous
    application names that might represent sophisticated impersonation attempts?
  context: This question applies clustering algorithms like DBSCAN to application
    name characteristics (n-grams, character types) to find outliers and small, dense
    clusters. This approach can uncover novel or complex impersonation techniques
    that don't match predefined rules or simple distance metrics, highlighting sophisticated
    adversary tradecraft.
  answer_sources:
  - Microsoft 365 Unified Audit Logs
  - Azure Active Directory Audit Logs
  - Public WHOIS Data
  - Zeek dns.log
  - Microsoft Entra ID tenant
  - Public DNS and WHOIS services
  - Network egress points
  range: last 90 days
  queries:
  - EXTRACT feature vectors from application names (n-grams, char frequencies). APPLY
    DBSCAN clustering model to the vectors. INVESTIGATE applications identified as
    noise points or belonging to small, isolated clusters.
- question: Have any applications been granted a predefined high-risk permission?
  context: This question focuses on detecting the granting of overly permissive access.
    Certain permissions (e.g., 'Mail.ReadWrite.All', 'Directory.ReadWrite.All') provide
    broad access to sensitive data and are highly sought after by adversaries. By
    maintaining a static list of these high-risk permissions and alerting whenever
    they are granted, we can quickly investigate potentially dangerous application
    consents.
  answer_sources:
  - Microsoft 365 Unified Audit Logs
  - Azure Active Directory Audit Logs
  - Zeek conn.log
  - Windows Security Event ID 4624
  - Microsoft Entra ID tenant
  - Network gateways and proxies
  - VPN concentrators
  range: last 90 days
  queries:
  - 'MAINTAIN a list of high-risk permissions. QUERY ''Consent to application'' events.
    FOR each event, CHECK if any granted permission is in the high-risk list. IF
    yes, generate HIGH-PRIORITY alert.'
- question: Has an application consent been granted from a statistically unusual
    geographic location for that user, or does an application request an unusually
    diverse set of permissions?
  context: This question identifies two types of statistical anomalies. First, it
    flags consents from geographic locations that are outliers for a given user, which
    could indicate a compromised account. Second, it uses Shannon entropy to measure
    the diversity of requested permissions, flagging applications that ask for an
    abnormally broad set of permissions, a potential indicator of a malicious, multi-purpose
    tool.
  answer_sources:
  - Microsoft 365 Unified Audit Logs
  - Azure Active Directory Audit Logs
  - Zeek conn.log
  - Windows Security Event ID 4624
  - Microsoft Entra ID tenant
  - Network gateways and proxies
  - VPN concentrators
  range: last 90 days
  queries:
  - 'FOR consent event, GET user and source IP. LOOKUP IP geolocation. COMPARE location
    to user''s historical location profile. IF outlier, FLAG. SEPARATELY, CALCULATE
    Shannon entropy of requested permissions. IF entropy is unusually high, FLAG.'
- question: Can we use an anomaly detection model to identify suspicious application
    consent events based on a combination of factors?
  context: This question aims to detect suspicious consents by looking at the event
    in its entirety. An anomaly detection model like Isolation Forest can identify
    events that are unusual across multiple dimensions simultaneously (e.g., a low-privilege
    user granting high-risk permissions at 3 AM from an IP with a poor reputation).
    This holistic view helps catch threats that might not seem suspicious if each
    factor were considered in isolation.
  answer_sources:
  - Microsoft 365 Unified Audit Logs
  - Azure Active Directory Audit Logs
  - Zeek conn.log
  - Windows Security Event ID 4624
  - Microsoft Entra ID tenant
  - Network gateways and proxies
  - VPN concentrators
  range: last 90 days
  queries:
  - 'FOR new consent event, EXTRACT features (user role, permission risk score, time
    of day, IP reputation). INPUT features into trained Isolation Forest model. IF
    model returns a high anomaly score, FLAG for investigation.'
- question: Has any service principal activity originated from a known malicious
    IP address, TOR exit node, or anonymizing proxy?
  context: This question seeks to identify high-confidence malicious activity by
    correlating service principal sign-ins and data access events with threat intelligence.
    Any activity from an IP address on a deny list is a strong indicator of compromise
    and requires immediate investigation, as it suggests the service principal's credentials
    have been stolen and are being used by an adversary.
  answer_sources:
  - Microsoft 365 Unified Audit Logs (e.g., SharePointFileOperation, ExchangeItem)
  - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
  - Azure Active Directory Audit Logs
  - Microsoft 365 services (Exchange Online, SharePoint Online, OneDrive)
  - Microsoft Entra ID tenant
  range: last 90 days
  queries:
  - 'QUERY service principal sign-in and data access logs. FOR each event, EXTRACT
    source IP. CHECK if source IP exists in threat intel feed of malicious IPs/proxies.
    IF match, generate HIGH-SEVERITY alert.'
- question: Has a service principal exhibited an anomalous volume of data access
    or accessed an unusually high number of unique user mailboxes compared to its
    historical baseline?
  context: This question helps detect data theft or reconnaissance by identifying
    deviations from normal behavior. By establishing a baseline of hourly data access
    volume and daily mailbox access for each service principal, we can alert on significant
    spikes (e.g., exceeding three standard deviations) that could indicate an adversary
    using the principal for bulk data exfiltration or discovery.
  answer_sources:
  - Microsoft 365 Unified Audit Logs (e.g., SharePointFileOperation, ExchangeItem)
  - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
  - Azure Active Directory Audit Logs
  - Microsoft 365 services (Exchange Online, SharePoint Online, OneDrive)
  - Microsoft Entra ID tenant
  range: last 30 days
  queries:
  - 'FOR each service principal, CALCULATE 30-day baseline (mean, std dev) of hourly
    data access volume. IF current hour''s volume > mean + 3*std_dev, ALERT. ALSO,
    check if unique mailboxes accessed > 99th percentile of historical daily activity,
    then ALERT.'
- question: Can a time-series model detect anomalous sequences of resource access
    events for a service principal?
  context: Adversaries often follow a predictable pattern enumerate resources, then
    access or exfiltrate data. This question uses a sophisticated model like an LSTM
    autoencoder to learn the normal sequence and timing of a service principal's actions.
    It can then flag deviations from this learned behavior, such as a rapid series
    of discovery actions followed by bulk downloads, which would have a high reconstruction
    error and indicate likely malicious activity.
  answer_sources:
  - Microsoft 365 Unified Audit Logs (e.g., SharePointFileOperation, ExchangeItem)
  - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
  - Azure Active Directory Audit Logs
  - Microsoft 365 services (Exchange Online, SharePoint Online, OneDrive)
  - Microsoft Entra ID tenant
  range: last 90 days
  queries:
  - INPUT sequence of resource access events (resource type, operation, time delta)
    for a service principal into a trained LSTM autoencoder. IF the model's reconstruction
    error for the sequence is high, ALERT as anomalous behavior.
- question: Has a service principal been created via a command-line tool on an endpoint
    and then immediately used for the first time?
  context: This question correlates host-level activity with cloud activity to detect
    'just-in-time' credential creation, a common adversary tactic. An alert is triggered
    if a command-line tool (like Azure CLI) is used to create a service principal,
    and that same principal is registered in the cloud within a short time window
    (e.g., 5 minutes). This tight temporal link suggests scripted, hands-on-keyboard
    activity.
  answer_sources:
  - Windows Security Event ID 4688
  - Azure Active Directory Audit Logs
  - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
  - Enterprise workstations and servers
  - Microsoft Entra ID tenant
  range: last 90 days
  queries:
  - 'CORRELATE process creation logs (Event ID 4688) with Azure AD audit logs. TRIGGER
    when (Process is ''az.cmd'' or ''pwsh.exe'' AND command line contains ''ad sp create-for-rbac'')
    is followed within 5 minutes by (''Add service principal'' event for same principal
    name). IF true, generate MEDIUM-SEVERITY alert.'
- question: Has there been a statistically significant spike in the number of service
    principals created in a 24-hour period?
  context: This question aims to detect automated or scripted creation of multiple
    service principals, which is abnormal behavior in most environments. By baselining
    the daily creation rate, we can flag days where the number of new principals exceeds
    a high percentile (e.g., 99th), indicating a potential large-scale persistence
    or access creation attempt. Correlating these spikes with host data can help pinpoint
    the source.
  answer_sources:
  - Windows Security Event ID 4688
  - Azure Active Directory Audit Logs
  - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
  - Enterprise workstations and servers
  - Microsoft Entra ID tenant
  range: last 90 days
  queries:
  - 'CALCULATE daily service principal creation count over last 90 days to establish
    a baseline. IF current 24-hour count > 99th percentile of baseline, ALERT. CORRELATE
    spike with process creation logs to find source hosts.'
- question: Can a machine learning model assign a risk score to a new service principal's
    initial activity pattern?
  context: This question uses a classification model to assess the risk of a new
    service principal immediately after its creation. By feeding the model features
    of its initial activity—such as the time until its first sign-in, the location
    of that sign-in, and its granted permissions—we can identify high-risk patterns
    (e.g., immediate sign-in from an unusual location with high privileges) that are
    strongly indicative of malicious intent.
  answer_sources:
  - Windows Security Event ID 4688
  - Azure Active Directory Audit Logs
  - Azure Active Directory Sign-in Logs (ServicePrincipalSignIn)
  - Enterprise workstations and servers
  - Microsoft Entra ID tenant
  range: last 90 days
  queries:
  - 'ON new service principal creation, EXTRACT features (time-to-first-signin, geolocation
    of first sign-in, permissions). INPUT features into trained classifier. IF model
    outputs high risk score, FLAG for review.'