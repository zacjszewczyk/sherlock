name: T1580: Cloud Infrastructure Discovery
id: a1b2c3d4-e5f6-4a7b-8c9d-0e1f2a3b4c5d
description: This playbook focuses on detecting Cloud Infrastructure Discovery (T1580), where an adversary attempts to understand an organization's cloud environment to map available resources and identify high-value targets. Key indicators include network connections to cloud API endpoints from suspicious sources (threat intel matches, rare geolocations), execution of known cloud discovery tools (like Pacu or CloudMapper) on endpoints, unauthorized users or systems running discovery commands (like 'aws describe-instances'), an abnormally high volume of discovery API calls from a single identity, and queries spanning an unusual breadth of services or geographic regions. This playbook provides questions and queries to investigate these activities across network, endpoint, and cloud audit logs.
type: technique
related:
  - TA0007: Discovery
contributors:
  - Zachary Szewczyk
  - Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Are there any connections to our cloud API endpoints originating from IP addresses known to be malicious?
    context: Adversaries often use compromised infrastructure or anonymizing services to hide their location when performing reconnaissance. Checking connection sources against threat intelligence feeds is a high-fidelity way to detect the initial stages of a targeted attack against cloud environments. A match indicates a strong possibility of malicious reconnaissance.
    answer_sources:
      - Zeek conn.log
      - Zeek ssl.log
      - Zeek dns.log
      - Internet Egress Points
      - DNS Resolvers
      - Network Security Monitoring (NSM) sensor locations
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          search Zeek_ssl_logs
          | join uid with Zeek_conn_logs
          | where server_name matches cloud_api_patterns
          | lookup threat_intel_feed on source_ip
          | where is_malicious = true
          | alert
  - question: Are connections to our cloud API endpoints originating from geographically or network-wise unusual locations?
    context: Threat actors may operate from locations that are not typical for legitimate users or services. By baselining the normal geographic and network origins (ASNs) of connections, we can spot outliers. A connection from a rare country or a previously unseen ASN could indicate an adversary attempting to discover our cloud assets.
    answer_sources:
      - Zeek conn.log
      - Zeek ssl.log
      - Zeek dns.log
      - Internet Egress Points
      - DNS Resolvers
      - Network Security Monitoring (NSM) sensor locations
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          search cloud_api_connection_logs last 30 days
          | calculate frequency of source_country, source_asn
          | determine 5th_percentile_threshold
          search cloud_api_connection_logs last 24 hours
          | enrich with geoip and asn
          | compare against historical_frequency
          | where frequency < 5th_percentile_threshold
          | alert
  - question: Can we use a machine learning model to proactively identify suspicious connections to cloud APIs based on their network characteristics?
    context: Simple rules may miss nuanced or novel attack patterns. A machine learning model, such as a Random Forest classifier, can learn complex patterns from various network features (e.g., ASN, country, duration, data volume) to distinguish between normal and suspicious activity. This allows for the detection of subtle reconnaissance attempts that might otherwise go unnoticed.
    answer_sources:
      - Zeek conn.log
      - Zeek ssl.log
      - Zeek dns.log
      - Internet Egress Points
      - DNS Resolvers
      - Network Security Monitoring (NSM) sensor locations
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          // Training
          collect labeled_connection_data (benign/suspicious)
          extract features (asn, country, duration, bytes, etc.)
          train RandomForest model
          // Inference
          stream live_connection_data
          extract features
          apply trained_model
          if prediction == 'suspicious'
          | alert
  - question: Is known cloud discovery tooling being executed on our endpoints?
    context: Adversaries frequently use open-source or custom tools designed for cloud reconnaissance (e.g., Pacu, CloudMapper, ScoutSuite). Searching for the execution of these tools by name, module, or unique command-line arguments in process logs is a direct way to detect active discovery attempts.
    answer_sources:
      - Windows Event ID 4688
      - Administrator and developer workstations
      - CI/CD pipeline runners
      - Bastion hosts
      - Virtual Desktop Infrastructure (VDI) instances
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          search process_creation_logs (EventID 4688)
          | where command_line matches regex_for_discovery_tools
          | alert
  - question: Are cloud CLI tools being used with unusually complex or random-looking command-line arguments?
    context: Automated discovery scripts often generate long, complex command-line invocations that differ significantly from typical, interactive administrative commands. By calculating the entropy of command-line arguments and baselining it per user, we can detect outliers that may represent the execution of a malicious script rather than a manually typed command.
    answer_sources:
      - Windows Event ID 4688
      - Administrator and developer workstations
      - CI/CD pipeline runners
      - Bastion hosts
      - Virtual Desktop Infrastructure (VDI) instances
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          search process_creation_logs for cloud_cli_tools
          | calculate shannon_entropy of command_line
          | compare with user_baseline_entropy
          | where entropy > 98th_percentile_for_user
          | alert
  - question: Are there statistically anomalous cloud CLI command executions that deviate from established user behavior?
    context: Machine learning can identify subtle deviations in command-line usage. By vectorizing command-line arguments (e.g., with TF-IDF) and training a one-class SVM on known-good activity, we can create a model that detects novel or outlier commands, which could indicate the use of unauthorized or malicious discovery techniques.
    answer_sources:
      - Windows Event ID 4688
      - Administrator and developer workstations
      - CI/CD pipeline runners
      - Bastion hosts
      - Virtual Desktop Infrastructure (VDI) instances
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          // Training
          collect baseline_cloud_cli_commands
          vectorize commands with TF-IDF
          train one-class_SVM model
          // Inference
          stream new_cloud_cli_commands
          vectorize new_command
          apply trained_model
          if prediction == 'outlier'
          | alert
  - question: Are users who are not authorized cloud administrators executing cloud discovery commands?
    context: Enforcing role-based access control is fundamental to security. Discovery commands should only be run by a small, defined set of users or service accounts. Detecting executions by any other user is a high-fidelity indicator of misconfiguration, privilege escalation, or lateral movement.
    answer_sources:
      - Windows Event ID 4688
      - Active Directory Security Logs
      - All corporate endpoints
      - Active Directory domain controllers (for group membership lookups)
      - Privileged Access Management (PAM) systems
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          search process_creation_logs for cloud_cli_tools
          | lookup executing_user in Active_Directory
          | check user_group_membership against allow_list
          | if user_group not in 'G_CloudAdmins'
          | alert
  - question: Is any user executing an unusual number or type of discovery commands compared to their own history?
    context: Individuals typically have consistent patterns of behavior. A sudden spike in the volume of discovery commands or the use of a command a user has never run before can indicate that their account has been compromised or that they are performing an unauthorized action. Baselining individual activity helps to spot these personal anomalies.
    answer_sources:
      - Windows Event ID 4688
      - Active Directory Security Logs
      - All corporate endpoints
      - Active Directory domain controllers (for group membership lookups)
      - Privileged Access Management (PAM) systems
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          search cloud_cli_logs by user
          | compare command to user's historical_command_set
          | count daily discovery_commands
          | compare daily_count to user's 90-day_average_and_stddev
          | if command is new OR daily_count > (avg + 3*stddev)
          | alert
  - question: Is any user's cloud command-line activity causing them to shift their behavioral profile?
    context: Clustering algorithms like DBSCAN can group users into roles (e.g., 'Admins', 'Developers') based on their command-line activity. An alert can be triggered if a user's behavior changes so significantly that they are re-classified into a different cluster or flagged as an outlier, indicating a potential role change or account takeover.
    answer_sources:
      - Windows Event ID 4688
      - Active Directory Security Logs
      - All corporate endpoints
      - Active Directory domain controllers (for group membership lookups)
      - Privileged Access Management (PAM) systems
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          collect user_command_profiles (frequency, variety, etc.)
          run DBSCAN to cluster users
          monitor user activity over time
          if user shifts_cluster OR becomes_outlier
          | alert
  - question: Is a single user or IP address making an excessive number of discovery API calls in a short time?
    context: Automated reconnaissance scripts often generate a high volume of API calls in a short period to quickly map out the environment. A simple threshold-based rule can be an effective first line of defense to detect this brute-force enumeration activity.
    answer_sources:
      - AWS CloudTrail
      - Azure Monitor Logs
      - Google Cloud Audit Logs
      - Windows Event ID 4688
      - Zeek conn.log
      - Cloud provider management plane (API logging)
      - Administrator workstations
      - Network egress points
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          search cloud_audit_logs for discovery_events ('describe*', 'list*', 'get*')
          | count by source_ip, user_identity over 10min window
          | where count > 100
          | alert
  - question: Is any user making discovery API calls at a rate that is anomalous for them?
    context: A static threshold for API call rates can be noisy. A more sophisticated approach is to baseline the rate of calls for each user. A sudden burst of activity that exceeds the 99th percentile of a user's own history is a much stronger signal. Combining this with the variety (entropy) of calls can further increase fidelity, as broad enumeration is more suspicious.
    answer_sources:
      - AWS CloudTrail
      - Azure Monitor Logs
      - Google Cloud Audit Logs
      - Windows Event ID 4688
      - Zeek conn.log
      - Cloud provider management plane (API logging)
      - Administrator workstations
      - Network egress points
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          search discovery_api_calls by user_identity
          | calculate rate over 10min window
          | compare rate to user's historical_baseline
          | if current_rate > 99th_percentile_of_baseline
          | alert
  - question: Is a user's API call volume statistically anomalous based on time-series forecasting?
    context: Time-series models like ARIMA can learn a user's normal rhythm of activity, including daily or weekly patterns. These models can then forecast an expected range for their activity. If the actual number of discovery calls significantly exceeds the forecasted upper bound, it indicates a statistically significant anomaly that warrants investigation.
    answer_sources:
      - AWS CloudTrail
      - Azure Monitor Logs
      - Google Cloud Audit Logs
      - Windows Event ID 4688
      - Zeek conn.log
      - Cloud provider management plane (API logging)
      - Administrator workstations
      - Network egress points
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          // For each user
          train ARIMA model on historical discovery_call_volume
          // In real-time
          forecast expected_volume_with_confidence_interval
          if actual_volume > upper_confidence_bound
          | alert
  - question: Is any user attempting to discover resources across all geographic regions?
    context: Legitimate administrators and developers typically work within a limited set of geographic regions. An adversary, however, may not know this and will often perform discovery across all available regions to get a complete picture. Detecting API calls that loop through regions or use wildcards for regions is a high-fidelity indicator of reconnaissance.
    answer_sources:
      - AWS CloudTrail
      - Azure Monitor Logs
      - Google Cloud Audit Logs
      - Windows Event ID 4688
      - Cloud provider management plane (API logging)
      - Administrator and developer workstations
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          search cloud_audit_logs
          | inspect api_request_parameters
          | if parameter indicates all_regions_query
          | alert
  - question: Is a user querying cloud services or regions they have never interacted with before?
    context: Users typically have a defined role that involves a specific set of cloud services and regions. By tracking the historical set of services/regions for each user, we can detect when they deviate from their established scope. A first-time query to a new service or region can be an early indicator of an account compromise or insider threat exploring outside their normal duties.
    answer_sources:
      - AWS CloudTrail
      - Azure Monitor Logs
      - Google Cloud Audit Logs
      - Windows Event ID 4688
      - Cloud provider management plane (API logging)
      - Administrator and developer workstations
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          // For each user, maintain a set of historical services/regions
          search new_discovery_api_calls
          | if call_target_service not in user_historical_service_set
          | alert
          | if call_target_region not in user_historical_region_set
          | alert
  - question: Is a user making discovery calls to services that are highly improbable based on their peer group's behavior?
    context: Graph analysis and link prediction can model the "expected" behavior of a user based on the behavior of their peers. If a developer, whose peers only use EC2 and S3, suddenly starts making discovery calls to the RDS service, a link prediction model would flag this as a low-probability, and therefore suspicious, event. This detects unusual activity that breaks from established roles.
    answer_sources:
      - AWS CloudTrail
      - Azure Monitor Logs
      - Google Cloud Audit Logs
      - Windows Event ID 4688
      - Cloud provider management plane (API logging)
      - Administrator and developer workstations
    range: last 90 days
    queries:
      - search: pseudocode
        query: |
          // Build user-service interaction graph
          // Train link prediction model (e.g., Adamic-Adar)
          for each new user-service_interaction
          | score probability of this link
          | if probability is very low
          | alert