name: T1585.001: Social Media Accounts
id: 9c7a8b4f-8e5a-4e2d-8f0c-1b9a7c6d5e4a
description: This playbook helps determine if an adversary is developing social media accounts for targeting an organization or its personnel. It provides investigative steps to detect impersonation accounts by matching profile artifacts against cyber threat intelligence, analyzing for typosquatting, and using machine learning models. It also outlines methods to identify clusters of similar accounts through content analysis, detect automated account creation via internal process and network monitoring, and spot coordinated campaigns by analyzing mass connection requests and synchronized posting behavior.
type: technique
related:
- TA0042: Resource Development
contributors:
- Zachary Szewczyk
- Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
- question: Has a social media profile impersonating our organization or employees been found to contain a URL, email, or username matching known-malicious indicators from our threat intelligence feeds?
  context: This question aims to detect the most direct evidence of malicious infrastructure being linked to impersonation accounts. A match with a Cyber Threat Intelligence (CTI) feed provides a high-confidence signal that an impersonation account is part of a known adversary's campaign, enabling rapid response and takedown requests.
  answer_sources:
  - Zeek dns.log
  - Zeek http.log
  - Cyber Threat Intelligence Feeds
  - External Social Media Platforms
  - Threat Intelligence Platform
  - DNS Resolvers
  - Web Proxies
  range: last 90 days
  queries:
  - pseudocode: SEARCH CTI_feed for (URL OR email OR username) from (impersonating_social_media_profiles)
- question: Are there domains found in suspect social media profiles that exhibit characteristics of typosquatting, such as being newly registered and visually similar to our organization's legitimate domains?
  context: Adversaries often use typosquatted domains to lend credibility to their impersonation accounts or to host phishing pages. This question helps identify these domains by checking their registration age (WHOIS data) and calculating the Levenshtein distance to legitimate domains, which measures the "edit distance" or similarity between two strings.
  answer_sources:
  - Zeek dns.log
  - Zeek http.log
  - Cyber Threat Intelligence Feeds
  - External Social Media Platforms
  - Threat Intelligence Platform
  - DNS Resolvers
  - Web Proxies
  - WHOIS data
  range: last 90 days
  queries:
  - pseudocode: FOR domain IN suspect_profiles | GET WHOIS_creation_date | CALCULATE Levenshtein_distance(domain, company_domain) | IF creation_date < 90_days AND distance <= 2 THEN ALERT
- question: Can we use a machine learning model to classify newly discovered, potentially impersonating social media accounts as malicious based on their profile characteristics?
  context: This question focuses on proactively identifying malicious accounts using a data-driven approach. By training a model on features like account age, follower-to-following ratio, and post frequency, we can automate the detection of suspicious profiles that might otherwise be missed by manual analysis, allowing analysts to focus on high-confidence alerts.
  answer_sources:
  - Zeek dns.log
  - Zeek http.log
  - Cyber Threat Intelligence Feeds
  - External Social Media Platforms
  - Threat Intelligence Platform
  - DNS Resolvers
  - Web Proxies
  range: last 90 days
  queries:
  - pseudocode: SCORE new_accounts WITH classification_model | IF confidence_score > 0.9 THEN ALERT
- question: Are we observing clusters of social media profiles using identical or programmatically generated assets, such as official logos, executive photos, or patterned usernames?
  context: This question helps to identify coordinated inauthentic behavior where an adversary creates multiple accounts using a template. Perceptual hashing (pHash) finds visually similar images even if they've been slightly modified, while regular expressions can detect common username patterns used in botnets or large-scale impersonation campaigns.
  answer_sources:
  - Publicly available social media data
  - Corporate brand monitoring service data
  - External Social Media Platforms (e.g., LinkedIn, Twitter, Facebook)
  - Corporate Brand Monitoring Service
  - Internal HR/Employee Directory Database
  range: last 90 days
  queries:
  - pseudocode: SCAN profile_images WITH pHash_library FOR matches | SEARCH usernames WITH regex_patterns FOR matches
- question: Do suspected impersonation accounts exhibit unusually high text similarity in their biographies or low-entropy usernames, suggesting automated or templated creation?
  context: This question aims to quantify the similarity within a group of suspect accounts. Jaccard similarity measures the overlap between sets of words in their biographies, with a high score indicating copy-pasted text. Low character entropy in usernames suggests a lack of randomness, a common trait of machine-generated account names.
  answer_sources:
  - Publicly available social media data
  - Corporate brand monitoring service data
  - External Social Media Platforms (e.g., LinkedIn, Twitter, Facebook)
  - Corporate Brand Monitoring Service
  - Internal HR/Employee Directory Database
  range: last 90 days
  queries:
  - pseudocode: CALCULATE Jaccard_similarity for profile_bios | CALCULATE entropy for usernames | IF similarity > 0.85 OR entropy is low THEN ALERT
- question: Does the topical content of posts from a suspected cluster of accounts diverge significantly from the topics discussed by legitimate employee accounts?
  context: This question uses Natural Language Processing (NLP) to uncover the underlying themes in the text generated by suspect accounts. Using a topic modeling technique like Latent Dirichlet Allocation (LDA), we can compare the topics from the suspect cluster (e.g., 'crypto') to legitimate topics. A significant divergence indicates inauthentic activity.
  answer_sources:
  - Publicly available social media data
  - Corporate brand monitoring service data
  - External Social Media Platforms (e.g., LinkedIn, Twitter, Facebook)
  - Corporate Brand Monitoring Service
  - Internal HR/Employee Directory Database
  range: last 90 days
  queries:
  - pseudocode: RUN LDA on suspect_account_posts | RUN LDA on legitimate_account_posts | COMPARE topic_distributions | IF divergent THEN ALERT
- question: Are scripting engines or browser automation tools being launched on internal endpoints with command-line arguments targeting social media sites, by users not authorized for such activity?
  context: This question seeks to detect the tools an adversary might use inside the network to automate social media account management. By monitoring for specific processes (like chromedriver.exe, python.exe) that interact with social media domains and filtering out legitimate users (e.g., marketing team), we can pinpoint unauthorized automation.
  answer_sources:
  - Windows Event ID 4688
  - Sysmon Event ID 1
  - Employee Workstations
  - Marketing Department Servers
  - Virtual Desktop Infrastructure (VDI)
  range: last 90 days
  queries:
  - pseudocode: SEARCH process_events WHERE process_name IN (automation_tools) AND command_line CONTAINS (social_media_domains) AND user NOT IN (allow_list) | ALERT
- question: Is any user executing an anomalously high number of script or browser automation processes, especially outside of normal business hours?
  context: This question focuses on detecting an anomalous volume of activity. By baselining a user's normal hourly count of automation processes, we can identify when their account starts running an unusual number of scripts, which could indicate a compromise being used to manage malicious social media activities.
  answer_sources:
  - Windows Event ID 4688
  - Sysmon Event ID 1
  - Employee Workstations
  - Marketing Department Servers
  - Virtual Desktop Infrastructure (VDI)
  range: last 90 days
  queries:
  - pseudocode: FOR each_user | CALCULATE baseline_hourly_count(automation_processes) | IF current_hourly_count > 99th_percentile(baseline) THEN ALERT
- question: Can we use a machine learning model to detect anomalous process execution chains related to social media automation, such as a browser being launched by an email client?
  context: This question leverages machine learning to identify suspicious causal relationships between processes. A model trained on features like parent-child process relationships can detect abnormal chains (e.g., outlook.exe -> powershell.exe -> chromedriver.exe with social media arguments) that deviate from learned benign patterns.
  answer_sources:
  - Windows Event ID 4688
  - Sysmon Event ID 1
  - Employee Workstations
  - Marketing Department Servers
  - Virtual Desktop Infrastructure (VDI)
  range: last 90 days
  queries:
  - pseudocode: SCORE real_time_process_events WITH classifier_model | IF score indicates anomalous_chain THEN ALERT
- question: Are internal hosts that are not part of our authorized infrastructure (e.g., marketing servers) making direct connections to social media API endpoints?
  context: This question aims to detect unauthorized programmatic access to social media platforms from within the network. While some servers are expected to use these APIs, a connection from a standard employee workstation to an API endpoint (e.g., api.twitter.com) is highly suspicious and could indicate a malicious script is running on that machine.
  answer_sources:
  - Zeek conn.log
  - Zeek dns.log
  - Zeek http.log
  - Network Egress Points
  - DNS Resolvers
  - Web Proxies
  range: last 90 days
  queries:
  - pseudocode: SEARCH DNS_requests OR network_connections FOR (social_media_API_endpoints) WHERE source_host NOT IN (allow_list) | ALERT
- question: Do network connections from any internal host to social media domains show a highly repetitive, non-human pattern, such as an extremely low standard deviation in connection timing?
  context: This question is designed to identify the robotic signature of automated tools. Human browsing creates network connections at irregular intervals, while a script often makes connections at fixed, predictable times. A very low standard deviation in the time between connections (inter-arrival time) is a strong indicator of automation.
  answer_sources:
  - Zeek conn.log
  - Zeek dns.log
  - Zeek http.log
  - Network Egress Points
  - DNS Resolvers
  - Web Proxies
  range: last 90 days
  queries:
  - pseudocode: FOR each_host | GET connection_timestamps to social_media_domains | CALCULATE stdev(inter_arrival_times) | IF stdev < 1_second THEN ALERT
- question: Is any internal host exhibiting a sustained and anomalous volume of data being sent to social media domains, when compared to its own forecasted behavior?
  context: This question uses time-series forecasting to detect unusual data transfer volumes. A model like ARIMA or Prophet learns a host's normal pattern of data uploads to social media sites. An alert is triggered when the actual data sent significantly exceeds the model's prediction, indicating bulk activity.
  answer_sources:
  - Zeek conn.log
  - Zeek dns.log
  - Zeek http.log
  - Network Egress Points
  - DNS Resolvers
  - Web Proxies
  range: last 90 days
  queries:
  - pseudocode: FOR each_host | TRAIN forecast_model on sent_bytes_to_social_media | IF observed_bytes > forecast_upper_bound FOR >2 intervals THEN ALERT
- question: Has a newly created social media account sent connection requests to multiple employees, especially high-value targets like executives or system administrators?
  context: This question targets a common reconnaissance tactic where an adversary uses a new account to quickly build a network within the target organization. By identifying new accounts (< 60 days old) that contact multiple employees, particularly those with privileged access, we can spot and investigate these attempts early.
  answer_sources:
  - Publicly available social media data
  - Employee-reported phishing/contact attempts
  - External Social Media Platforms
  - Employee Inboxes
  - Corporate Brand Monitoring Platform
  range: last 90 days
  queries:
  - pseudocode: IDENTIFY new_accounts (<60 days) | COUNT connection_requests_to_employees | IF count > 5 AND any_employee is high_value_target THEN ALERT
- question: Are any external social media accounts sending an anomalously high number of connection requests to our employees or targeting an unusually broad range of departments?
  context: This question uses statistical anomaly detection to find aggressive reconnaissance activity. An account sending more requests than 99.5% of all other requesters is an outlier. Measuring the "departmental blast radius"—the number of unique business units targeted—adds context, as this suggests a broad intelligence-gathering effort.
  answer_sources:
  - Publicly available social media data
  - Employee-reported phishing/contact attempts
  - External Social Media Platforms
  - Employee Inboxes
  - Corporate Brand Monitoring Platform
  range: last 90 days
  queries:
  - pseudocode: FOR each_external_account | COUNT requests_to_employees | IF count > 99.5th_percentile THEN ALERT | CALCULATE unique_departments_targeted
- question: Are any external accounts attempting to connect with employees in a way that strategically bridges otherwise separate communities or departments within our organization?
  context: This question applies graph theory to understand the adversary's strategy. By modeling employee connections as a network, we can identify distinct communities (e.g., engineering vs. sales). An external account trying to connect to key people in different, unconnected communities may be acting as a "bridge node" to spread influence or gather information.
  answer_sources:
  - Publicly available social media data
  - Employee-reported phishing/contact attempts
  - External Social Media Platforms
  - Employee Inboxes
  - Corporate Brand Monitoring Platform
  range: last 90 days
  queries:
  - pseudocode: MODEL employee_connections as graph | RUN community_detection | IDENTIFY external_accounts connecting multiple communities | ALERT
- question: Does a group of suspected inauthentic accounts share common static artifacts, such as all posting links to the same domain, following the same central accounts, or using the same URL shortener?
  context: This question looks for shared infrastructure or TTPs (Tactics, Techniques, and Procedures) across a set of suspicious accounts. If a high percentage of accounts are all directed to post the same link or follow the same accounts, this coordinated use of resources is a strong indicator of a centrally managed campaign.
  answer_sources:
  - Publicly available social media data
  - External Social Media Platforms
  range: last 90 days
  queries:
  - pseudocode: FOR group_of_suspect_accounts | CHECK for common(link_domains, followed_accounts, url_shorteners) | IF >75% share artifact THEN ALERT
- question: Is there a high temporal correlation in the posting activity across a cluster of suspected malicious accounts, suggesting they are acting in a synchronized, automated manner?
  context: This question seeks to detect coordination through timing analysis. Unrelated users post at random times relative to each other. A botnet or a group of accounts managed by a single operator will often post content at nearly the same time. High cross-correlation with a near-zero time lag is a mathematical proof of this synchronized behavior.
  answer_sources:
  - Publicly available social media data
  - External Social Media Platforms
  range: last 90 days
  queries:
  - pseudocode: FOR each_pair in suspect_cluster | CALCULATE cross_correlation(post_timestamps) | IF average_correlation is high AND time_lag is near zero THEN ALERT
- question: Using graph embedding and clustering, can we identify a dense cluster of suspected malicious accounts that is structurally separate from the cluster of legitimate accounts?
  context: This advanced machine learning technique finds "guilt by association." Graph embedding algorithms (e.g., Node2Vec) create a mathematical vector for each account based on its network structure. Clustering algorithms (e.g., DBSCAN) can then group these vectors. A tight cluster of suspicious accounts that is far from the "normal" cluster of legitimate users indicates a coordinated, inauthentic network.
  answer_sources:
  - Publicly available social media data
  - External Social Media Platforms
  range: last 90 days
  queries:
  - pseudocode: CREATE graph_embeddings (Node2Vec) for all_accounts | RUN clustering (DBSCAN) on vectors | IF dense_cluster of suspect_accounts is found THEN ALERT