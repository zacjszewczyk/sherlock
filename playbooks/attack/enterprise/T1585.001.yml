name: "T1585.001: Social Media Accounts"
id: "f47ac10b-58cc-4372-a567-0e02b2c3d479"
description: "This playbook helps determine if an adversary is developing social media accounts for targeting the organization or its personnel. It focuses on detecting profiles impersonating the organization or employees by matching profile data (URLs, emails) against Cyber Threat Intelligence (CTI), analyzing domains for typosquatting, and using machine learning to classify suspicious accounts. The playbook also identifies clusters of similar profiles by checking for identical text, images, or programmatic naming conventions, and looks for synchronized activity like coordinated posting times. It also addresses internal threats by searching for unauthorized automation tools interacting with social media sites from the corporate network, analyzing for anomalous network traffic patterns, and monitoring for suspicious process creation events related to social media automation."
type: "technique"
related:
  - "TA0042: Resource Development"
contributors:
  - "Zachary Szewczyk"
  - "Ask Sage"
created: "2025-10-01"
modified: "2025-10-01"
version: 1.0
tags: "none"
questions:
  - question: "Are social media profiles impersonating our organization or employees using infrastructure (URLs, emails) known to be malicious?"
    context: "Adversaries often reuse infrastructure across campaigns. A match between an impersonating profile's contact information or linked URL and a known-malicious indicator from a threat intelligence feed is a high-confidence signal of malicious intent. This question aims to find these direct links between impersonation attempts and known adversarial infrastructure."
    answer_sources:
      - "Zeek dns.log"
      - "Zeek http.log"
      - "Cyber Threat Intelligence Feeds"
      - "External Social Media Platforms"
      - "Threat Intelligence Platform"
      - "DNS Resolvers"
      - "Web Proxies"
    range: "last 90 days"
    queries:
      - "SEARCH social_media_profiles for metadata (URLs, emails)"
      - "JOIN metadata with threat_intelligence_feed on indicator"
      - "ALERT on match"
  - question: "Are impersonating social media profiles leveraging newly registered or typosquatted domains to appear legitimate?"
    context: "Typosquatting is a common tactic where adversaries register domains that are slight variations of a legitimate domain to trick users. Newly registered domains are also highly suspicious. This question seeks to identify these high-risk domains associated with potential impersonation accounts by analyzing domain age and similarity to the organization's legitimate domains."
    answer_sources:
      - "Zeek dns.log"
      - "Zeek http.log"
      - "Cyber Threat Intelligence Feeds"
      - "External Social Media Platforms"
      - "Threat Intelligence Platform"
      - "DNS Resolvers"
      - "Web Proxies"
      - "WHOIS registration data"
    range: "last 90 days"
    queries:
      - "FOR each domain in suspect_profile:"
      - "  GET WHOIS creation_date"
      - "  CALCULATE Levenshtein_distance(domain, company_domain)"
      - "  IF creation_date < 90 days AND Levenshtein_distance <= 2:"
      - "    FLAG as suspicious"
  - question: "Can we use machine learning to proactively identify and classify potentially malicious impersonation accounts based on their profile characteristics?"
    context: "Manually reviewing every potential impersonation account is not scalable. A machine learning model can analyze features like account age, follower-to-following ratios, post frequency, and profile completeness to automatically score and prioritize the most suspicious accounts for analyst review, improving efficiency and response time."
    answer_sources:
      - "Zeek dns.log"
      - "Zeek http.log"
      - "Cyber Threat Intelligence Feeds"
      - "External Social Media Platforms"
      - "Threat Intelligence Platform"
      - "DNS Resolvers"
      - "Web Proxies"
    range: "last 90 days"
    queries:
      - "EXTRACT features (account_age, follower_count, etc.) from new_impersonation_accounts"
      - "INPUT features into trained_classification_model"
      - "IF confidence_score > 0.9:"
      - "  ALERT for analyst_review"
  - question: "Are adversaries using our official corporate logos, executive photos, or programmatic usernames to create clusters of inauthentic accounts?"
    context: "Adversaries often create multiple fake accounts in a coordinated manner. These accounts might reuse official branding to look legitimate or follow a predictable username pattern. This question aims to detect these clusters by looking for identical images (via perceptual hashing) and structured usernames (via regular expressions)."
    answer_sources:
      - "Publicly available social media data"
      - "Corporate brand monitoring service data"
      - "External Social Media Platforms (e.g., LinkedIn, Twitter, Facebook)"
      - "Corporate Brand Monitoring Service"
      - "Internal HR/Employee Directory Database"
    range: "last 90 days"
    queries:
      - "SCAN impersonating_account_images with pHash_library of official_logos"
      - "SEARCH impersonating_account_usernames with regex for adversarial_patterns"
      - "ALERT on match"
  - question: "Do suspected impersonation accounts share unusually similar biography text or have algorithmically generated usernames?"
    context: "To scale their operations, attackers may use templates for profile descriptions or generate usernames programmatically. High text similarity (e.g., Jaccard score) or low username randomness (entropy) across a group of accounts are strong indicators of inauthentic, coordinated activity. This question aims to quantify and detect this templated behavior."
    answer_sources:
      - "Publicly available social media data"
      - "Corporate brand monitoring service data"
      - "External Social Media Platforms (e.g., LinkedIn, Twitter, Facebook)"
      - "Corporate Brand Monitoring Service"
      - "Internal HR/Employee Directory Database"
    range: "last 90 days"
    queries:
      - "FOR a cluster of suspect_accounts:"
      - "  CALCULATE Jaccard_similarity on profile_bios"
      - "  CALCULATE entropy on usernames"
      - "  IF avg_similarity > 0.85 OR avg_entropy is low:"
      - "    FLAG cluster as coordinated"
  - question: "Are the topics discussed by a cluster of suspected accounts significantly different from the topics discussed by legitimate employees?"
    context: "Inauthentic accounts created for a specific campaign (e.g., crypto scams, fake giveaways) will often post about topics unrelated to the professional roles they are impersonating. This question uses Natural Language Processing (NLP) topic modeling to detect this thematic divergence from a baseline of genuine employee content, highlighting accounts that do not fit the expected narrative."
    answer_sources:
      - "Publicly available social media data"
      - "Corporate brand monitoring service data"
      - "External Social Media Platforms (e.g., LinkedIn, Twitter, Facebook)"
      - "Corporate Brand Monitoring Service"
      - "Internal HR/Employee Directory Database"
    range: "last 90 days"
    queries:
      - "RUN LDA topic_modeling on posts from suspect_cluster -> get suspect_topics"
      - "RUN LDA topic_modeling on posts from legitimate_employees -> get baseline_topics"
      - "COMPARE suspect_topics to baseline_topics"
      - "IF significant_divergence:"
      - "  FLAG as inauthentic"
  - question: "Are unauthorized automation tools or scripting engines being executed on endpoints to interact with social media sites?"
    context: "Adversaries might compromise internal machines to run bots that create or manage social media accounts. This question looks for direct evidence of this activity by detecting the execution of automation tools (like chromedriver.exe or pwsh.exe) with social media domains in their command-line arguments, especially from user accounts not authorized for such activity (e.g., outside the marketing team)."
    answer_sources:
      - "Windows Event ID 4688"
      - "Sysmon Event ID 1"
      - "Employee Workstations"
      - "Marketing Department Servers"
      - "Virtual Desktop Infrastructure (VDI)"
    range: "last 90 days"
    queries:
      - "SEARCH process_creation_events WHERE process_name in (automation_tools) AND command_line contains (social_media_domains)"
      - "FILTER OUT events from users in marketing_allow_list"
      - "ALERT on remaining events"
  - question: "Is any user executing an anomalously high number of script or browser automation processes, especially outside of business hours?"
    context: "Automated activity, whether malicious or not, often involves a higher frequency of process executions than manual user activity. This question aims to detect outliers by baselining normal user behavior and alerting when a user's activity significantly exceeds their typical pattern, which could indicate a compromised account or insider threat."
    answer_sources:
      - "Windows Event ID 4688"
      - "Sysmon Event ID 1"
      - "Employee Workstations"
      - "Marketing Department Servers"
      - "Virtual Desktop Infrastructure (VDI)"
    range: "last 90 days"
    queries:
      - "FOR each user:"
      - "  CALCULATE hourly_count of script_process_creation"
      - "  COMPARE count to 99th_percentile_baseline"
      - "  IF count > baseline OR outside_business_hours:"
      - "    ALERT for review"
  - question: "Can we use machine learning to distinguish between benign and malicious script execution on endpoints in real-time?"
    context: "Simple SIEM rules can be noisy. A machine learning model can analyze multiple features of a process event (e.g., parent process, command line entropy, user context) to more accurately identify anomalous and potentially malicious process chains, such as Outlook launching PowerShell which then launches a browser automation tool to interact with a social media site."
    answer_sources:
      - "Windows Event ID 4688"
      - "Sysmon Event ID 1"
      - "Employee Workstations"
      - "Marketing Department Servers"
      - "Virtual Desktop Infrastructure (VDI)"
    range: "last 90 days"
    queries:
      - "EXTRACT features (process, parent_process, cmd_line_entropy) from real_time_process_events"
      - "SCORE event with trained_classifier_model"
      - "IF event is flagged as malicious:"
      - "  ALERT on anomalous_process_chain"
  - question: "Are internal hosts that are not part of our authorized infrastructure making connections to social media APIs?"
    context: "Programmatic interaction with social media platforms is often done via their official APIs. Only specific servers (e.g., marketing automation tools) should be accessing these. This question seeks to identify unauthorized clients on the network that are communicating with social media APIs, which could indicate a bot running on a compromised workstation."
    answer_sources:
      - "Zeek conn.log"
      - "Zeek dns.log"
      - "Zeek http.log"
      - "Network Egress Points"
      - "DNS Resolvers"
      - "Web Proxies"
    range: "last 90 days"
    queries:
      - "SEARCH DNS_requests or network_connections TO domains in social_media_api_watchlist"
      - "FILTER OUT requests from hosts in infrastructure_allow_list"
      - "ALERT on remaining connections"
  - question: "Are network connections from any internal host to social media sites occurring with a robotic, non-human regularity?"
    context: "Human browsing behavior is irregular, with varying time between clicks and page loads. Automated scripts, however, often make connections at very regular, predictable intervals. This question aims to detect this machine-like pattern by measuring the time between connections (inter-arrival time) and alerting when it's unnaturally consistent (low standard deviation)."
    answer sources:
      - "Zeek conn.log"
      - "Zeek dns.log"
      - "Zeek http.log"
      - "Network Egress Points"
      - "DNS Resolvers"
      - "Web Proxies"
    range: "last 90 days"
    queries:
      - "FOR each host:"
      - "  GET timestamps of connections to social_media_domains"
      - "  CALCULATE std_dev of inter_arrival_times"
      - "  IF std_dev < 1 second:"
      - "    ALERT on robotic_behavior"
  - question: "Is any host sending an anomalously large volume of data to social media domains?"
    context: "While regular browsing involves data transfer, automated tools used for bulk account creation or information scraping might result in unusual data upload patterns. This question uses time-series forecasting to model normal behavior and detect when a host's data transfer volume significantly exceeds its predicted range, indicating a potential automation or exfiltration anomaly."
    answer_sources:
      - "Zeek conn.log"
      - "Zeek dns.log"
      - "Zeek http.log"
      - "Network Egress Points"
      - "DNS Resolvers"
      - "Web Proxies"
    range: "last 90 days"
    queries:
      - "FOR each host:"
      - "  MODEL time_series of bytes_sent to social_media_domains"
      - "  IF observed_bytes > forecasted_upper_bound for >2 intervals:"
      - "    ALERT on anomalous_data_transfer"
  - question: "Are newly created social media accounts sending connection requests to a large number of employees, especially high-value targets?"
    context: "A common reconnaissance tactic is to send connection requests from a new, inauthentic account to multiple employees to map the organization or target specific individuals. This question aims to detect these broad or targeted campaigns, prioritizing alerts for those that involve executives or privileged users."
    answer_sources:
      - "Publicly available social media data"
      - "Employee-reported phishing/contact attempts"
      - "External Social Media Platforms"
      - "Employee Inboxes"
      - "Corporate Brand Monitoring Platform"
    range: "last 90 days"
    queries:
      - "IDENTIFY new_accounts (<60 days) sending >5 connection_requests to employees"
      - "CROSS-REFERENCE targeted_employees with high_value_target_list"
      - "IF high_value_target is contacted:"
      - "  ESCALATE for immediate_investigation"
  - question: "Is a single external account attempting to connect with an unusually high number of employees or employees across many different departments?"
    context: "An adversary trying to build a broad network for influence or phishing might send requests indiscriminately. This question seeks to identify such outlier accounts by flagging those with a statistically unusual number of requests (e.g., >99.5th percentile) or those whose requests span multiple, distinct business units (a large 'departmental blast radius')."
    answer_sources:
      - "Publicly available social media data"
      - "Employee-reported phishing/contact attempts"
      - "External Social Media Platforms"
      - "Employee Inboxes"
      - "Corporate Brand Monitoring Platform"
    range: "last 90 days"
    queries:
      - "FOR each external_account:"
      - "  COUNT connection_requests to employees in 24h"
      - "  COUNT unique departments of targeted_employees"
      - "  IF request_count > 99.5th_percentile OR department_count is high:"
      - "    FLAG account"
  - question: "Are external accounts attempting to strategically connect with employees who bridge different social or departmental groups within the organization?"
    context: "Sophisticated adversaries may not connect randomly, but may strategically target individuals who act as 'bridge nodes' between otherwise disconnected groups of employees. This question uses graph analysis to identify such accounts, as their behavior is indicative of a more advanced reconnaissance effort to efficiently map or influence the organization."
    answer_sources:
      - "Publicly available social media data"
      - "Employee-reported phishing/contact attempts"
      - "External Social Media Platforms"
      - "Employee Inboxes"
      - "Corporate Brand Monitoring Platform"
    range: "last 90 days"
    queries:
      - "MODEL employee_connections as a graph"
      - "IDENTIFY communities within the graph"
      - "ANALYZE connection_requests from new_external_accounts"
      - "IF account acts as a 'bridge_node' between communities:"
      - "  FLAG as strategic_reconnaissance"
  - question: "Do suspected inauthentic accounts share common artifacts, like linking to the same domain or following the same core accounts?"
    context: "Botnets or groups of manually-operated fake accounts often share infrastructure or follow a central command-and-control account. This question aims to find this coordination by looking for overlaps in the links they post, the specific accounts they follow, or the URL shortener services they use. A high degree of overlap is a strong sign of coordination."
    answer_sources:
      - "Publicly available social media data"
      - "External Social Media Platforms"
    range: "last 90 days"
    queries:
      - "FOR a cluster of suspect_accounts:"
      - "  CHECK for common posted_domains, followed_accounts, or URL_shorteners"
      - "  IF overlap > 75%:"
      - "    ALERT on coordinated_artifacts"
  - question: "Is a cluster of suspected malicious accounts posting content at almost the exact same time?"
    context: "A strong indicator of automation is synchronized action. If multiple accounts are posting, liking, or commenting within seconds of each other, it is highly probable they are controlled by a single script or platform. This question uses time-series cross-correlation to detect this synchronized posting behavior, which is nearly impossible for uncoordinated humans to replicate."
    answer_sources:
      - "Publicly available social media data"
      - "External Social Media Platforms"
    range: "last 90 days"
    queries:
      - "FOR each pair of accounts in suspect_cluster:"
      - "  CALCULATE cross-correlation of posting_timestamps"
      - "  IF avg_correlation is high AND time_lag is near zero:"
      - "    FLAG as synchronized_activity"
  - question: "Can we use graph-based machine learning to identify coordinated networks of inauthentic accounts based on their behavior and connections?"
    context: "Graph machine learning can uncover complex relationships that are not obvious from individual data points. By representing accounts and their interactions as a graph and generating vector embeddings (e.g., Node2Vec), this technique can identify dense clusters of suspected bots that are structurally separate from the network of legitimate users, indicating a likely botnet."
    answer_sources:
      - "Publicly available social media data"
      - "External Social Media Platforms"
    range: "last 90 days"
    queries:
      - "GENERATE graph_embeddings (Node2Vec) for all accounts"
      - "APPLY clustering (DBSCAN) to embeddings"
      - "ANALYZE clusters for high density of suspect_accounts"
      - "IF dense_suspect_cluster is isolated from legitimate_users:"
      - "  FLAG as coordinated_inauthentic_network"