name: 'T1538: Cloud Service Dashboard'
id: f5d8e9c0-a1b2-4c3d-8e4f-5a6b7c8d9e0f
description: This playbook focuses on detecting adversaries who have gained access to a cloud environment and are using the cloud service dashboard or management console for discovery. It aims to identify malicious reconnaissance activities by analyzing cloud console login events and subsequent API activity for various anomalies. These include logins from suspicious locations or with unusual user agents, high-volume/high-variety read-only API calls indicative of automated scanning, and attempts to access sensitive resources like secrets, encryption keys, or identity and access management (IAM) configurations.
type: technique
related:
  - 'TA0007: Discovery'
contributors:
  - Zachary Szewczyk
  - Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Is a cloud console login originating from a known malicious IP address, TOR exit node, or anonymizing proxy?
    context: This question aims to identify logins from sources with a pre-existing negative reputation. An adversary might use compromised infrastructure or anonymizing services to hide their true origin, and a match against threat intelligence is a strong indicator of malicious activity.
    answer_sources:
      - AWS CloudTrail logs (ConsoleLogin event)
      - Azure SignIn Logs
      - Google Cloud Audit Logs (Admin Activity)
      - Zeek conn.log
      - Windows Security Event ID 4624
      - Cloud IAM infrastructure
      - Internet gateways and proxies
      - Endpoint devices of privileged users
      - Threat Intelligence Feeds
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_login_events | EXTRACT source_ip | LOOKUP threat_intel_feeds ON source_ip | WHERE is_malicious=true | ALERT
  - question: Has a user logged into the cloud console from a geographic location, Autonomous System (AS), or at a time of day that is statistically rare for them?
    context: This question seeks to detect deviations from a user's established behavioral baseline. Adversaries, especially external ones, are unlikely to perfectly mimic a legitimate user's typical location, network, and working hours. A login that is an outlier in these aspects could indicate a compromised account.
    answer_sources:
      - AWS CloudTrail logs (ConsoleLogin event)
      - Azure SignIn Logs
      - Google Cloud Audit Logs (Admin Activity)
      - Zeek conn.log
      - Windows Security Event ID 4624
      - Cloud IAM infrastructure
      - Internet gateways and proxies
      - Endpoint devices of privileged users
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_login_events | BASELINE user, source_country, source_asn, login_hour over 90d | COMPARE new_login to baseline | WHERE frequency < 5th_percentile | ALERT
  - question: Did a user's cloud console logins occur from geographically distant locations in a time frame that would be physically impossible?
    context: This question identifies a classic indicator of account compromise known as "impossible travel." If a user logs in from one location and then minutes later from a location thousands of miles away, it's a strong sign that at least one of the sessions is fraudulent, as two different entities are likely using the same credentials.
    answer_sources:
      - AWS CloudTrail logs (ConsoleLogin event)
      - Azure SignIn Logs
      - Google Cloud Audit Logs (Admin Activity)
      - Zeek conn.log
      - Windows Security Event ID 4624
      - Cloud IAM infrastructure
      - Internet gateways and proxies
      - Endpoint devices of privileged users
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_login_events by user | SORT by time | FOR each consecutive_login | CALCULATE distance_km / time_delta_hours | WHERE speed_kph > 800 | ALERT
  - question: Is a cloud console session associated with a User-Agent string matching known offensive security tools, unauthorized scripts, or headless browsers?
    context: This question looks for specific toolmarks left by adversaries. Attackers often use specialized tools (like Pacu) or automation scripts for reconnaissance and exploitation. Their User-Agent strings are often distinct from those of standard web browsers and can be a direct indicator of malicious intent.
    answer_sources:
      - AWS CloudTrail logs
      - Azure Activity Logs
      - Google Cloud Audit Logs (Admin Activity)
      - Zeek http.log
      - Cloud management consoles (e.g., AWS Management Console, Azure Portal)
      - Internet gateways and proxies
      - Cloud API endpoints
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_activity_logs | EXTRACT user_agent | MATCH user_agent against regex_list_of_malicious_tools | WHERE match_found=true | ALERT
  - question: Is a user's cloud console session using a User-Agent string that is both new for that specific user and rare across the entire organization?
    context: This question helps detect anomalous activity that might not match a known malicious signature. A User-Agent that a user has never used before, and which is also uncommon organization-wide, suggests the use of a non-standard client, which could be an adversary's tool or an unauthorized script.
    answer_sources:
      - AWS CloudTrail logs
      - Azure Activity Logs
      - Google Cloud Audit Logs (Admin Activity)
      - Zeek http.log
      - Cloud management consoles (e.g., AWS Management Console, Azure Portal)
      - Internet gateways and proxies
      - Cloud API endpoints
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_activity_logs | BASELINE user_agents by user over 90d | FOR new_login | IF new_user_agent not in user_baseline AND global_prevalence(new_user_agent) < 1% | ALERT
  - question: Does a machine learning model classify the User-Agent from a cloud console session as potentially malicious?
    context: This question leverages machine learning to move beyond simple signature or rarity checks. A trained model can learn the subtle characteristics of malicious User-Agents and identify novel or obfuscated strings that might evade other detection methods, providing a more robust and scalable approach.
    answer_sources:
      - AWS CloudTrail logs
      - Azure Activity Logs
      - Google Cloud Audit Logs (Admin Activity)
      - Zeek http.log
      - Cloud management consoles (e.g., AWS Management Console, Azure Portal)
      - Internet gateways and proxies
      - Cloud API endpoints
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: STREAM cloud_activity_logs | EXTRACT user_agent | INPUT user_agent to ml_model | WHERE model_prediction == 'malicious-tool' | ALERT
  - question: Has a single user session generated an abnormally high volume and variety of read-only API calls across multiple cloud services in a short period?
    context: This question is designed to detect the broad reconnaissance common after an initial compromise. An attacker will often try to enumerate as many resources as possible (users, roles, instances, databases) very quickly. This behavior contrasts sharply with normal administrative activity, which is typically more focused.
    answer_sources:
      - AWS CloudTrail logs (List*, Describe*, Get* events)
      - Azure Activity Logs (Microsoft.Resources/subscriptions/resourceGroups/read)
      - Google Cloud Audit Logs (Data Access)
      - Cloud API endpoints
      - Cloud management consoles
      - Specific cloud service infrastructure (e.g., S3, EC2, RDS)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_api_logs | FILTER event_name matches 'List*', 'Describe*', 'Get*' | GROUPBY session_id, user over 15m_window | COUNT distinct event_name as event_count, COUNT distinct service as service_count | WHERE event_count > 100 AND service_count > 5 | ALERT
  - question: Is the diversity of API calls within a user's session (as measured by Shannon entropy) statistically unusual compared to their historical behavior?
    context: This question provides a more nuanced way to measure the unusualness of a session's activity. High entropy indicates a wide variety of different actions are being taken, which is characteristic of broad reconnaissance. Flagging sessions with abnormally high entropy compared to the user's own baseline can uncover sophisticated enumeration that might not trigger simple volume-based thresholds.
    answer_sources:
      - AWS CloudTrail logs (List*, Describe*, Get* events)
      - Azure Activity Logs (Microsoft.Resources/subscriptions/resourceGroups/read)
      - Google Cloud Audit Logs (Data Access)
      - Cloud API endpoints
      - Cloud management consoles
      - Specific cloud service infrastructure (e.g., S3, EC2, RDS)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_api_logs | GROUPBY session_id, user over 10m_window | CALCULATE shannon_entropy(event_name) | COMPARE current_entropy to user_historical_entropy_baseline | WHERE current_entropy > 99th_percentile | ALERT
  - question: Does the sequence of API calls in a user's session deviate significantly from patterns learned by a sequence-based anomaly detection model?
    context: This question aims to detect anomalies in the order of operations, not just the volume or variety. Legitimate administrative tasks often follow predictable workflows. An attacker's reconnaissance may follow a different, opportunistic path. A sequence model can learn the normal "grammar" of API calls and flag sessions that don't conform.
    answer_sources:
      - AWS CloudTrail logs (List*, Describe*, Get* events)
      - Azure Activity Logs (Microsoft.Resources/subscriptions/resourceGroups/read)
      - Google Cloud Audit Logs (Data Access)
      - Cloud API endpoints
      - Cloud management consoles
      - Specific cloud service infrastructure (e.g., S3, EC2, RDS)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: STREAM cloud_api_logs by session_id | CREATE event_name_sequence | INPUT sequence to lstm_autoencoder_model | CALCULATE reconstruction_error | WHERE reconstruction_error > threshold | ALERT
  - question: Is a user who is not part of an authorized administrative group attempting to discover sensitive resources like secrets, encryption keys, or IAM policies?
    context: This question implements a direct, high-fidelity check based on the principle of least privilege. Access to discover sensitive configuration and data should be tightly controlled. Any attempt by a non-privileged user to list secrets or view detailed authorization policies is highly suspicious and warrants immediate investigation.
    answer_sources:
      - AWS CloudTrail logs (e.g., secretsmanager:ListSecrets, iam:GetAccountAuthorizationDetails)
      - Azure Activity Logs (e.g., Microsoft.KeyVault/vaults/secrets/list/action)
      - Google Cloud Audit Logs (Data Access)
      - Secrets management services (e.g., AWS Secrets Manager, Azure Key Vault)
      - IAM infrastructure
      - Data storage services hosting sensitive information
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_api_logs | FILTER event_name in sensitive_api_watchlist | GET user_group_membership | WHERE user_group NOT IN ('Cloud Security Admin', 'Cloud Auditor') | ALERT
  - question: Has a user made a sensitive API call that has never, or very rarely, been made by anyone with their assigned role?
    context: This question uses role-based access control (RBAC) baselining to find privileged access abuse. Even if a user is an administrator, they may have a specific function. If a database administrator suddenly starts listing IAM policies, it's a deviation from their role's expected behavior and could indicate a compromised privileged account being used for reconnaissance.
    answer_sources:
      - AWS CloudTrail logs (e.g., secretsmanager:ListSecrets, iam:GetAccountAuthorizationDetails)
      - Azure Activity Logs (e.g., Microsoft.KeyVault/vaults/secrets/list/action)
      - Google Cloud Audit Logs (Data Access)
      - Secrets management services (e.g., AWS Secrets Manager, Azure Key Vault)
      - IAM infrastructure
      - Data storage services hosting sensitive information
    range: Last 180 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_api_logs | FILTER event_name in sensitive_api_watchlist | BASELINE role, event_name over 180d | COMPARE new_event to baseline | WHERE invocation_frequency_for_role == 0 | ALERT
  - question: Did a graph-based anomaly detection model identify a low-probability access event between a user and a sensitive resource?
    context: This question applies graph analytics to model complex relationships between users, roles, and resources. This approach can uncover subtle anomalies that are difficult to define with rules. For example, it can learn that "developers" access "dev-keys" but not "prod-keys." A new access event that creates an "unlikely" link in this graph is a powerful indicator of a potential threat.
    answer_sources:
      - AWS CloudTrail logs (e.g., secretsmanager:ListSecrets, iam:GetAccountAuthorizationDetails)
      - Azure Activity Logs (e.g., Microsoft.KeyVault/vaults/secrets/list/action)
      - Google Cloud Audit Logs (Data Access)
      - Secrets management services (e.g., AWS Secrets Manager, Azure Key Vault)
      - IAM infrastructure
      - Data storage services hosting sensitive information
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: STREAM cloud_access_logs | CONSTRUCT user_resource_graph | FOR new_access_event (user, resource) | CALCULATE link_prediction_probability | WHERE probability < low_threshold | ALERT