name: T1114.002: Remote Email Collection
id: f4b8f0a0-6c9a-4e1b-9f2d-7e8a9d0b1c3d
description: |
  This playbook focuses on detecting adversaries collecting sensitive information from remote email services, as outlined in MITRE ATT&CK technique T1114.002. Investigations should focus on several key indicators:
  1. Authentication events (successful or failed) originating from IP addresses known to be malicious, part of anonymizing networks, or TOR exit nodes.
  2. Network traffic containing User-Agent strings or API call sequences associated with known email collection tools like MailSniper or Ruler.
  3. Successful authentications that deviate significantly from a user's established baseline, including factors like geolocation (impossible travel), time of day, or login frequency.
  4. Anomalously large volumes of data being downloaded from a mail service by a single user, exceeding their historical norms.
  5. Session characteristics indicative of automated or programmatic access, such as unusually high request rates or unnaturally consistent timing between requests, as opposed to normal human interaction.
type: technique
related:
  - TA0009: Collection
contributors:
  - Zachary Szewczyk
  - Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Are there any authentication attempts to mail services originating from IP addresses on a Cyber Threat Intelligence (CTI) feed?
    context: |
      This question is crucial for detecting initial access or credential abuse where an adversary uses known malicious infrastructure. By comparing login IPs against a CTI feed, we can quickly identify high-confidence threats, even if the login attempt itself was successful. It's a fundamental check for known bad actors.
    answer_sources:
      - Windows Event ID 4624
      - Windows Event ID 4625
      - Zeek conn.log
      - Azure AD SignInLogs
      - O365 Unified Audit Log
      - Authentication servers (e.g., Active Directory Domain Controllers)
      - Cloud Identity Providers (e.g., Azure AD)
      - Mail Servers (e.g., on-prem Exchange)
      - Network Egress Points
      - VPN Concentrators
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          FOR each authentication_log_event
            source_ip = event.source_ip
            IF source_ip IN cti_feed.ip_list THEN
              GENERATE alert
            END IF
          END FOR
  - question: For logins from known malicious IPs, does the source ASN and country pair represent anomalous behavior for the specific user?
    context: |
      This question adds a layer of statistical validation to a CTI hit. An adversary might use a compromised server within a common cloud provider (common ASN). However, if the specific user has never logged in from that provider or country before, it significantly increases the likelihood of a compromise. This helps prioritize alerts by combining known threat data with user-specific behavioral anomalies.
    answer_sources:
      - Windows Event ID 4624
      - Windows Event ID 4625
      - Zeek conn.log
      - Azure AD SignInLogs
      - O365 Unified Audit Log
      - Authentication servers (e.g., Active Directory Domain Controllers)
      - Cloud Identity Providers (e.g., Azure AD)
      - Mail Servers (e.g., on-prem Exchange)
      - Network Egress Points
      - VPN Concentrators
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          FOR each auth_event with source_ip IN cti_feed.ip_list
            user = event.user
            source_asn_country = enrich(event.source_ip).asn_country
            historical_frequency = calculate_frequency(user, source_asn_country, last 90 days)
            IF historical_frequency < 5th_percentile THEN
              ESCALATE alert
            END IF
          END FOR
  - question: Can a machine learning model predict if a new login attempt is malicious, even if the source IP is not on a CTI feed?
    context: |
      This question aims to proactively identify threats from new or unknown malicious infrastructure. CTI feeds are reactive. A machine learning model trained on the characteristics of past malicious logins (geolocation, time, ASN, etc.) can learn the pattern of an attack and flag new logins that fit this pattern, providing an early warning capability.
    answer_sources:
      - Windows Event ID 4624
      - Windows Event ID 4625
      - Zeek conn.log
      - Azure AD SignInLogs
      - O365 Unified Audit Log
      - Authentication servers (e.g., Active Directory Domain Controllers)
      - Cloud Identity Providers (eg., Azure AD)
      - Mail Servers (e.g., on-prem Exchange)
      - Network Egress Points
      - VPN Concentrators
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          model = train_classifier(historical_logins, cti_labels)
          FOR each new_login_event
            features = extract_features(new_login_event)
            is_malicious_prediction = model.predict(features)
            IF is_malicious_prediction > threshold THEN
              GENERATE alert
            END IF
          END FOR
  - question: Is network traffic to email services showing User-Agent strings or API calls matching known email collection tools?
    context: |
      Adversaries often use specialized tools like MailSniper or Ruler for automated email collection. These tools leave distinct fingerprints, such as unique User-Agent strings or specific sequences of API calls. This question focuses on finding these known-bad signatures in network or cloud logs, which provides high-fidelity evidence of a targeted collection attempt.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - O365 Unified Audit Log
      - Mail Servers (e.g., on-prem Exchange)
      - Web Application Firewalls (WAFs)
      - Network Egress Points
      - Cloud Application Security Broker (CASB)
      - Cloud Mail Tenant (e.g., O365, Google Workspace)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          tool_signatures = ['MailSniper', 'ruler', 'PowerShell']
          FOR each log_event IN (http_logs, o365_audit_logs)
            IF log_event.user_agent MATCHES any in tool_signatures THEN
              GENERATE alert
            END IF
          END FOR
  - question: Has there been a sudden drop in the variety of a user's User-Agent strings, or are they using a very rare User-Agent?
    context: |
      A normal user's activity generates a variety of User-Agent strings from different browsers and devices. When an automated tool is used, it often uses a single, consistent User-Agent, causing the complexity (entropy) of that user's User-Agents to drop. This question seeks to detect this shift from diverse, human-driven activity to monolithic, tool-driven activity. Flagging extremely rare User-Agents also helps find non-standard tools.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - O365 Unified Audit Log
      - Mail Servers (e.g., on-prem Exchange)
      - Web Application Firewalls (WAFs)
      - Network Egress Points
      - Cloud Application Security Broker (CASB)
      - Cloud Mail Tenant (e.g., O365, Google Workspace)
    range: Last 30 days
    queries:
      - technology: pseudocode
        query: |
          FOR each user
            current_ua_entropy = calculate_entropy(user.user_agents, last 30 days)
            IF current_ua_entropy is anomalously low THEN
              GENERATE alert
            END IF
          END FOR
  - question: Are there anomalous sequences of email operations in a user's session that deviate from normal user behavior?
    context: |
      Humans interact with their email in predictable patterns (e.g., open mail, reply, delete). Automated collection tools follow a different, more rigid script (e.g., bind to folder, access item, bind to next folder, access item). This question uses sequence analysis to learn the 'normal' grammar of user actions and flags sessions that follow an unnatural, machine-like sequence, indicating potential tool usage.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - O365 Unified Audit Log
      - Mail Servers (e.g., on-prem Exchange)
      - Web Application Firewalls (WAFs)
      - Network Egress Points
      - Cloud Application Security Broker (CASB)
      - Cloud Mail Tenant (e.g., O365, Google Workspace)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          model = train_sequence_model(benign_o365_sessions)
          FOR each new_user_session
            session_operations = get_operations(new_user_session)
            is_anomalous = model.predict(session_operations)
            IF is_anomalous THEN
              GENERATE alert
            END IF
          END FOR
  - question: Has a user logged in from two locations in a time frame that would require physically impossible travel?
    context: |
      'Impossible travel' is a classic and highly effective indicator of account compromise. If a user logs in from New York and then, one hour later, from London, it is certain that at least one of the logins is fraudulent. This question codifies that logic to detect simultaneous use of an account from geographically distant locations.
    answer_sources:
      - Windows Event ID 4624
      - Zeek conn.log
      - Azure AD SignInLogs
      - Authentication servers (e.g., Active Directory Domain Controllers)
      - Cloud Identity Provider (e.g., Azure AD)
      - VPN Concentrators
      - Network Egress Points
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          FOR each new_successful_login
            user = login.user
            prev_login = get_previous_login(user)
            distance = calculate_distance(login.location, prev_login.location)
            time_delta = login.timestamp - prev_login.timestamp
            speed = distance / time_delta
            IF speed > 1000_kmh THEN
              GENERATE 'Impossible Travel' alert
            END IF
          END FOR
  - question: Is a user logging in from a new country or at an unusual time compared to their established 30-day profile?
    context: |
      Beyond impossible travel, more subtle deviations can indicate a compromise. An adversary might be in the same country, but logging in at 3 AM when the user normally works 9-to-5. This question builds a behavioral baseline for each user (common locations, typical login times) and flags logins that deviate significantly from that personal pattern, catching anomalies that are not physically impossible but are highly improbable for that specific user.
    answer_sources:
      - Windows Event ID 4624
      - Zeek conn.log
      - Azure AD SignInLogs
      - Authentication servers (e.g., Active Directory Domain Controllers)
      - Cloud Identity Provider (e.g., Azure AD)
      - VPN Concentrators
      - Network Egress Points
    range: Last 30 days
    queries:
      - technology: pseudocode
        query: |
          FOR each new_login
            user_profile = build_profile(new_login.user, last 30 days)
            score = 0
            IF new_login.country NOT IN user_profile.countries THEN score += 1
            IF new_login.hour is > 2_stddev from user_profile.mean_hour THEN score += 1
            IF score >= 2 THEN
              GENERATE alert
            END IF
          END FOR
  - question: Is a user's login attempt an outlier when compared to the clusters of their normal login behavior?
    context: |
      This question applies unsupervised machine learning to define 'normal' for a user. By clustering a user's past logins based on features like location and time, we can create a multi-dimensional picture of their typical activity. Any new login that doesn't fit into one of these 'normal' clusters is, by definition, an anomaly. This method is powerful for detecting novel attack patterns that don't match pre-defined rules.
    answer_sources:
      - Windows Event ID 4624
      - Zeek conn.log
      - Azure AD SignInLogs
      LAGs
      - Authentication servers (e.g., Active Directory Domain Controllers)
      - Cloud Identity Provider (e.g., Azure AD)
      - VPN Concentrators
      - Network Egress Points
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          FOR each user
            login_data = get_user_logins(user, last 90 days)
            features = extract_features(login_data)
            clusters = dbscan_cluster(features)
            FOR each new_login
              IF new_login is not in any cluster (is noise) THEN
                GENERATE alert
              END IF
            END FOR
          END FOR
  - question: Is a user downloading an abnormally large amount of data or accessing an unusually high number of items from their email?
    context: |
      This question hunts for volumetric anomalies. An adversary attempting to exfiltrate an entire mailbox will download gigabytes of data or access thousands of items in a short period, whereas a normal user's session involves much smaller amounts. This approach uses simple, static thresholds to catch the most egregious cases of bulk data collection.
    answer_sources:
      - Zeek conn.log
      - O365 Unified Audit Log
      - Mail Servers (e.g., on-prem Exchange)
      - Network Egress Points
      - Cloud Tenant (e.g., O365, Google Workspace)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          IF zeek_session.resp_bytes > 1_GB THEN GENERATE alert
          IF count(o365_log.operation='MailItemsAccessed' BY user in 10_min) > 500 THEN
            GENERATE alert
          END IF
  - question: Is a user's email data download volume or number of accessed items exceeding their own personal 95th percentile baseline?
    context: |
      Static thresholds are brittle; a 1GB download might be normal for a legal team member during e-discovery but highly abnormal for a sales representative. This question improves upon the static threshold by creating a dynamic, per-user baseline. It alerts when a user's activity exceeds their own 'personal best' for data access, resulting in more accurate and context-aware alerts.
    answer_sources:
      - Zeek conn.log
      - O365 Unified Audit Log
      - Mail Servers (e.g., on-prem Exchange)
      - Network Egress Points
      - Cloud Tenant (e.g., O365, Google Workspace)
    range: Last 30 days
    queries:
      - technology: pseudocode
        query: |
          FOR each user
            threshold = calculate_95th_percentile(user.session_bytes, last 30 days)
            FOR each new_user_session
              IF new_user_session.bytes > threshold THEN
                GENERATE alert
              END IF
            END FOR
          END FOR
  - question: Is a user's daily email download volume significantly higher than what a time-series forecast would predict?
    context: |
      This question uses machine learning to forecast a user's expected data usage. Time-series models can capture complex patterns like seasonality (e.g., more activity on weekdays). By alerting only when actual usage exceeds the upper bound of the forecast's prediction interval, this method can detect anomalous spikes in activity while filtering out predictable, benign fluctuations.
    answer_sources:
      - Zeek conn.log
      - O365 Unified Audit Log
      - Mail Servers (e.g., on-prem Exchange)
      - Network Egress Points
      - Cloud Tenant (e.g., O365, Google Workspace)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          FOR each user
            model = train_timeseries_model(user.daily_volume)
            prediction = model.forecast(next_24_hours)
            actual_volume = measure_actual_volume()
            IF actual_volume > prediction.upper_bound THEN
              GENERATE alert
            END IF
          END FOR
  - question: Is a user session exhibiting an extremely high request rate or using privileged administrative commands for bulk operations?
    context: |
      This question looks for clear signs of automation or privilege abuse. A human cannot click 200 times in 10 minutes. Likewise, mailbox export commands are powerful administrative tools that are rarely used in normal day-to-day operations. Alerting on these high-volume or high-privilege activities provides a simple but effective way to detect programmatic collection.
    answer_sources:
      - Zeek conn.log
      - Zeek http.log
      - O365 Unified Audit Log
      - Mail Servers (e.g., on-prem Exchange)
      - Web Application Firewalls (WAFs)
      - Cloud Tenant (e.g., O365, Google Workspace)
    range: Last 24 hours
    queries:
      - technology: pseudocode
        query: |
          IF count(requests in session) / time(session) > high_threshold THEN GENERATE alert
          IF operation IN ('Search-Mailbox', 'New-MailboxExportRequest') AND user is NOT admin THEN
            GENERATE alert
          END IF
  - question: Does a user's session show an unnaturally low variance in the time between requests, suggesting machine-like pacing?
    context: |
      Humans are inconsistent. The time between our clicks and requests varies. A script, however, often executes tasks with near-perfect, metronomic timing. This question seeks to quantify that consistency. By calculating the standard deviation of time between requests in a session, we can identify sessions where the pacing is too regular to be human, pointing strongly to automation.
    answer_sources:
      - Zeek conn.log
      - Zeek http.log
      - O365 Unified Audit Log
      - Mail Servers (e.g., on-prem Exchange)
      - Web Application Firewalls (WAFs)
      - Cloud Tenant (e.g., O365, Google Workspace)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          FOR each user_session
            time_deltas = calculate_inter_request_times(user_session)
            std_dev = calculate_stddev(time_deltas)
            IF std_dev < 1st_percentile_of_all_sessions THEN
              GENERATE alert
            END IF
          END FOR
  - question: Can a machine learning model classify a user session as 'bot' or 'human' based on its overall characteristics?
    context: |
      This is a holistic approach to detecting automation. Instead of relying on a single indicator, it uses a machine learning model to look at a collection of session features at onceâ€”request count, duration, timing variance, URL entropy, etc. By training the model on labeled examples of human and bot activity, it can learn to distinguish between the two and classify new, unseen sessions with a high degree of accuracy.
    answer_sources:
      - Zeek conn.log
      - Zeek http.log
      - O365 Unified Audit Log
      - Mail Servers (e.g., on-prem Exchange)
      - Web Application Firewalls (WAFs)
      - Cloud Tenant (e.g., O365, Google Workspace)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: |
          model = train_classifier(labeled_human_bot_sessions)
          FOR each new_session
            features = extract_session_features(new_session)
            prediction = model.predict(features)
            IF prediction == 'bot' with high_confidence THEN
              GENERATE alert
            END IF
          END FOR