name: T1594: Search Victim-Owned Websites
id: 5e634e2e-2e4f-4d2a-8c6e-8d7b3a9c7b1a
description: >-
  This playbook helps investigate whether an adversary is conducting reconnaissance by searching public-facing websites.
  This involves looking for anomalous activity such as web sessions originating from malicious IPs or using suspicious User-Agents based on threat intelligence;
  scanning for sensitive URIs (e.g., /.git/, /wp-admin/), file types (e.g., .sql, .bak), or using User-Agents associated with automated tools like sqlmap or nikto;
  statistically anomalous request volumes, rates, or diversity of URIs from a single source; unusually high access rates to sensitive sections of a website (e.g., team, investors, careers);
  and requests to deep-linked pages with null or unexpected Referer headers, suggesting direct access that bypasses normal navigation.
type: technique
related:
  - TA0043: Reconnaissance
contributors:
  - Zachary Szewczyk
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Is an HTTP/S session to a public web server originating from a source IP or using a User-Agent known to be malicious based on threat intelligence feeds?
    context: >-
      This question aims to identify straightforward reconnaissance attempts by cross-referencing web traffic logs with curated lists of known malicious indicators,
      such as TOR exit nodes, known scanning infrastructure, or suspicious User-Agent strings. A match provides a high-confidence signal that an adversary
      is probing the organization's web assets.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Public-facing web servers
      - Network perimeter firewalls/proxies
      - Web Application Firewalls (WAFs)
      - Cloud-hosted web applications
      - Threat Intelligence Platforms
    range: last 90 days
    queries:
      - pseudocode: For each web connection, check if source IP or User-Agent exists in threat intelligence list. If match, alert.
  - question: Has there been a statistically significant increase in web traffic from anonymizing services like commercial VPNs or proxies?
    context: >-
      This question seeks to detect less obvious reconnaissance campaigns that use anonymizing services to hide their origin. By establishing a baseline for traffic
      volume from such services (identified via ASN and geolocation), a significant deviation can indicate a coordinated effort to scan the organization's
      web presence under the cover of anonymity.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Public-facing web servers
      - Network perimeter firewalls/proxies
      - Web Application Firewalls (WAFs)
      - Cloud-hosted web applications
      - Threat Intelligence Platforms
    range: last 90 days
    queries:
      - pseudocode: Calculate daily connection volume from anonymizing service ASNs. Compare current volume to historical baseline (mean + 3*std_dev). If exceeds, alert.
  - question: Can we predict if a web session is part of a malicious reconnaissance scan using a machine learning model?
    context: >-
      This question leverages a logistic regression model to proactively identify malicious reconnaissance. By training on features like IP reputation, User-Agent,
      ASN, and session behavior, the model can assign a probability score to new sessions, allowing for the detection of novel or sophisticated scanning
      techniques that may not match known signatures.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Public-facing web servers
      - Network perimeter firewalls/proxies
      - Web Application Firewalls (WAFs)
      - Cloud-hosted web applications
      - Threat Intelligence Platforms
    range: last 90 days
    queries:
      - pseudocode: For each web session, extract features (IP, User-Agent, ASN, geo, time, referer). Input to trained logistic regression model. If probability > threshold (e.g., 0.85), alert.
  - question: Is a source IP scanning for known sensitive URIs, file types, or using a User-Agent associated with automated scanning tools?
    context: >-
      This question focuses on detecting common automated scanning behaviors. Adversaries and their tools often search for specific, well-known paths (e.g., /.git/, /wp-admin/)
      or file extensions (e.g., .sql, .bak) that indicate misconfigurations or exposed data. Identifying these requests provides a strong indication of targeted reconnaissance.
    answer_sources:
      - Zeek http.log
      - Public-facing web servers
      - Content Delivery Network (CDN) edge nodes
      - Web Application Firewalls (WAFs)
    range: last 90 days
    queries:
      - pseudocode: Scan http logs for URI, filename, and User-Agent fields matching a list of regex patterns for known scanner tools and sensitive paths/files. If match, alert.
  - question: Is a source IP exhibiting statistically unusual file-seeking behavior, such as requesting a wide variety of file types or generating a high rate of 'Not Found' errors?
    context: >-
      This question aims to identify directory and file enumeration attempts by analyzing the patterns of requests. A high entropy of file extensions suggests an adversary is
      probing for different types of files, while a high rate of 404 errors indicates they are guessing file and directory names. These are statistical indicators of a brute-force search for content.
    answer_sources:
      - Zeek http.log
      - Public-facing web servers
      - Content Delivery Network (CDN) edge nodes
      - Web Application Firewalls (WAFs)
    range: last 90 days
    queries:
      - pseudocode: For each source IP, calculate Shannon entropy of requested file extensions and rate of 404 responses. If entropy or 404 rate exceeds baseline percentile/std_dev, alert.
  - question: Is the request volume for sensitive public files like robots.txt or sitemap.xml significantly deviating from forecasted norms?
    context: >-
      This question uses time-series forecasting to detect abnormal interest in files that map out a website's structure. Adversaries often start by fetching `robots.txt` or `sitemap.xml`.
      A sudden, unpredicted spike in requests for these files from various sources can signal the beginning of a coordinated reconnaissance campaign.
    answer_sources:
      - Zeek http.log
      - Public-facing web servers
      - Content Delivery Network (CDN) edge nodes
      - Web Application Firewalls (WAFs)
    range: last 90 days
    queries:
      - pseudocode: Use a time-series model (e.g., ARIMA) to forecast request volume for files like robots.txt. If observed volume exceeds forecasted confidence interval, alert.
  - question: Is a non-whitelisted web crawler generating a high rate of requests?
    context: >-
      This question helps to distinguish between legitimate, high-volume web crawlers (like search engine bots) and potentially malicious scanners. By maintaining a whitelist of known-good
      User-Agents, any IP exhibiting high-rate crawling behavior without a matching User-Agent can be flagged for investigation as an unapproved or malicious scanner.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Public-facing web servers
      - Load balancers
      - Web Application Firewalls (WAFs)
      - Network Intrusion Detection Systems (NIDS)
    range: last 90 days
    queries:
      - pseudocode: Check for source IPs with high request rates (>10 req/sec). If the User-Agent is not in the legitimate crawler whitelist, alert.
  - question: Is any single source IP exhibiting both a high request rate and accessing an unusually high number of unique URIs compared to typical users?
    context: >-
      This question identifies aggressive scanning by looking for the combined behavior of rapid requests and broad exploration. A normal user might browse many pages, but not at a machine-gun pace.
      A bot might make rapid requests, but to a limited set of pages. An IP that does both simultaneously is highly likely to be a scanner mapping the website.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Public-facing web servers
      - Load balancers
      - Web Application Firewalls (WAFs)
      - Network Intrusion Detection Systems (NIDS)
    range: last 90 days
    queries:
      - pseudocode: For each source IP, calculate request rate and unique URI count over a 10-min window. If both metrics exceed the 98th percentile of their baselines, alert.
  - question: Can we identify anomalous web sessions that represent scanning activity by clustering them based on their behavioral features?
    context: >-
      This question uses unsupervised machine learning (DBSCAN) to discover patterns of scanning without pre-defined rules. By clustering sessions based on features like duration, request count,
      and URI diversity, the algorithm can automatically group similar behaviors. Sessions that do not fit into 'normal' user clusters are flagged as anomalies, potentially representing novel scanning techniques.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Public-facing web servers
      - Load balancers
      - Web Application Firewalls (WAFs)
      - Network Intrusion Detection Systems (NIDS)
    range: last 90 days
    queries:
      - pseudocode: Apply DBSCAN clustering to web sessions using features like duration, request count, and URI diversity. Alert on sessions classified as noise or belonging to an anomalous cluster.
  - question: Is a single source IP rapidly accessing an excessive number of unique pages within sensitive areas of the website like the team, investors, or careers sections?
    context: >-
      This question is designed to detect targeted enumeration of personnel, financial, or business-related information. By defining sensitive URL paths, we can specifically monitor for and
      alert on rapid, broad access to these areas, which is a strong indicator of an adversary gathering intelligence on the organization's people and structure.
    answer_sources:
      - Zeek http.log
      - Public-facing web servers hosting corporate, HR, or investor relations content
      - Content Management System (CMS) logs
    range: last 90 days
    queries:
      - pseudocode: Define sensitive URL patterns. If a source IP accesses > 20 unique URLs matching these patterns within 5 minutes, alert.
  - question: Is a user session showing an unusually high ratio of sensitive pages visited compared to total pages visited?
    context: >-
      This question identifies users who are disproportionately focused on reconnaissance-rich content. While a normal user might visit one or two team pages, a session where a high percentage of
      activity is concentrated in sensitive sections deviates from typical browsing behavior and suggests a targeted intelligence-gathering effort.
    answer_sources:
      - Zeek http.log
      - Public-facing web servers hosting corporate, HR, or investor relations content
      - Content Management System (CMS) logs
    range: last 90 days
    queries:
      - pseudocode: For each session, calculate ratio of (sensitive pages / total pages). If ratio exceeds 95th percentile of historical session ratios, alert.
  - question: Is a user's navigation path through the website highly improbable when compared to models of normal user navigation?
    context: >-
      This question models user navigation as a sequence (a Markov chain) to detect non-human browsing patterns. Normal users tend to follow predictable paths (e.g., homepage -> products -> product detail).
      A session that jumps between disparate sensitive pages in a way that is statistically unlikely under the model indicates scripted enumeration rather than organic browsing.
    answer_sources:
      - Zeek http.log
      - Public-facing web servers hosting corporate, HR, or investor relations content
      - Content Management System (CMS) logs
    range: last 90 days
    queries:
      - pseudocode: Model normal navigation paths as a Markov chain. Calculate the probability of a new session's path. If the probability is extremely low, alert.
  - question: Are requests being made to sensitive, deep-linked pages with a missing or external Referer header?
    context: >-
      This question aims to find adversaries who are directly accessing internal or sensitive pages, bypassing the intended navigational flow of the website. A legitimate user would typically arrive at
      a deep page from another page on the same site (producing an internal Referer). A null or external Referer suggests the user knew the URL in advance, possibly from a breach or previous reconnaissance.
    answer_sources:
      - Zeek http.log
      - Public-facing web servers
      - Application servers
      - Web Application Firewalls (WAFs)
    range: last 90 days
    queries:
      - pseudocode: Define sensitive URIs. Alert on requests to these URIs where the Referer header is null or not the organization's domain (excluding whitelisted referrers).
  - question: For a given sensitive page, is there a statistical anomaly in the percentage of requests coming from unexpected or null referrers?
    context: >-
      This question looks for shifts in how users are arriving at sensitive pages. Each page has a typical set of referring pages. A sudden increase in traffic from null referrers or referrers
      outside the normal set indicates that a new, direct access method is being used, which could be a sign of a targeted campaign.
    answer_sources:
      - Zeek http.log
      - Public-facing web servers
      - Application servers
      - Web Application Firewalls (WAFs)
    range: last 90 days
    queries:
      - pseudocode: For a sensitive page, baseline its top 10 referrers. Alert if the percentage of traffic from null/non-top-10 referrers exceeds 3 standard deviations above the mean.
  - question: Can a sequence-to-sequence autoencoder detect anomalous user navigation paths that indicate direct access to deep-linked pages?
    context: >-
      This question uses an advanced machine learning model to learn the 'shape' of normal navigation sequences. The autoencoder is trained to reconstruct these normal paths. When it encounters
      an anomalous path, such as a session that starts directly on a deep page, it will fail to reconstruct it accurately. A high reconstruction error serves as a powerful signal for anomalous, and potentially malicious, navigation.
    answer_sources:
      - Zeek http.log
      - Public-facing web servers
      - Application servers
      - Web Application Firewalls (WAFs)
    range: last 90 days
    queries:
      - pseudocode: Train a seq2seq autoencoder on normal navigation sequences. For new sessions, if the reconstruction error is above a threshold, alert.