name: "T1627: Execution Guardrails"
id: "f47ac10b-58cc-4372-a567-0e02b2c3d479"
description: "This playbook is designed to detect if an adversary is using execution guardrails to evade detection and ensure their payload executes only on specifically targeted mobile devices. The technique involves embedding checks for environmental factors—such as device locale, network operator, Wi-Fi SSID, GPS coordinates, or specific device permissions—within a mobile application. The malicious logic remains dormant until these conditions are met, allowing the application to bypass analysis in generic sandboxes or on non-targeted devices. Detection strategies involve both static analysis (inspecting manifest files and decompiled code for suspicious permission combinations and hardcoded values) and dynamic analysis (applying environmental triggers in a sandbox to observe behavioral changes, such as sudden network spikes or calls to sensitive APIs)."
type: "technique"
related:
  - "TA0030: Defense Evasion"
contributors:
  - "Zachary Szewczyk"
  - "Ask Sage"
created: "2025-10-01"
modified: "2025-10-01"
version: 1.0
tags: "none"
questions:
  - question: "Is a mobile application using a high-risk combination of permissions or checking for specific corporate identifiers to selectively execute malicious code?"
    context: "This question focuses on static analysis to identify targeted threats before execution. Adversaries often bundle specific permissions (e.g., `READ_SMS`, `ACCESS_FINE_LOCATION`) that are powerful in combination but unusual for legitimate apps. They may also hardcode target-specific values like internal Wi-Fi SSIDs or corporate domain names directly into their application to ensure it only activates in the target environment, thereby evading generic sandbox analysis. Proactively scanning for these static indicators in new or updated applications is crucial for early detection."
    answer_sources:
      - "Mobile Application Manifest Files (e.g., AndroidManifest.xml)"
      - "Mobile Threat Defense (MTD) permission analysis logs"
      - "Static analysis reports from decompiled application source code (e.g., APK, IPA)"
      - "Corporate-managed mobile devices, Mobile Device Management (MDM) platform, internal application vetting/sandbox environments, and public/private mobile application marketplaces."
    range: "last 90 days"
    queries:
      - "FOR each new/updated app, PARSE manifest for permissions. IF permissions in high-risk watchlist OR decompiled code contains target strings (corporate SSID, domain), THEN ALERT."
  - question: "Does a mobile application request an unusual or statistically rare set of permissions compared to other applications in its category?"
    context: "This question uses statistical methods to find outliers that may indicate evasive behavior. Malware might request a unique combination of permissions that differs significantly from legitimate apps in the same category. By calculating the Jaccard similarity of an app's permissions against the category median and the Shannon entropy of its permission set, we can flag statistically anomalous applications. A low similarity score or a high entropy score suggests the permission set is unusual and warrants deeper investigation."
    answer_sources:
      - "Mobile Application Manifest Files (e.g., AndroidManifest.xml)"
      - "Mobile Threat Defense (MTD) permission analysis logs"
      - "Static analysis reports from decompiled application source code (e.g., APK, IPA)"
      - "Corporate-managed mobile devices, Mobile Device Management (MDM) platform, internal application vetting/sandbox environments, and public/private mobile application marketplaces."
    range: "last 90 days"
    queries:
      - "FOR each app, CALCULATE Jaccard similarity of its permissions vs. category median. CALCULATE Shannon entropy of its permissions. IF similarity < 10th percentile OR entropy > 95th percentile, THEN FLAG for review."
  - question: "Can a machine learning model, trained on known benign and malicious application features, predict if a new application is malicious based on its static properties?"
    context: "This question aims to automate detection using a machine learning classifier. By creating a feature vector for each application—including permissions, exported components, and specific API calls related to guardrailing—we can train a model to distinguish between safe and malicious apps. This approach allows for scalable, automated vetting of new applications, quarantining those with a high probability of being malicious ($$ p(malicious) > 0.90 $$) for further dynamic analysis before they can be deployed."
    answer_sources:
      - "Mobile Application Manifest Files (e.g., AndroidManifest.xml)"
      - "Mobile Threat Defense (MTD) permission analysis logs"
      - "Static analysis reports from decompiled application source code (e.g., APK, IPA)"
      - "Corporate-managed mobile devices, Mobile Device Management (MDM) platform, internal application vetting/sandbox environments, and public/private mobile application marketplaces."
    range: "last 90 days"
    queries:
      - "FOR each new app, GENERATE feature vector (permissions, services, APIs). INPUT vector into trained ML model. IF model predicts $$ p(malicious) > 0.90 $$, THEN QUARANTINE app."
  - question: "Does an application initiate suspicious network connections to low-reputation domains immediately after a specific environmental trigger is applied in a dynamic sandbox?"
    context: "This question focuses on detecting dormant malware that activates only under specific conditions. An adversary's application may appear benign until an environmental trigger (like a specific GPS location or Wi-Fi network) is met. We can test for this by systematically applying potential triggers in a sandbox and monitoring for immediate, subsequent network activity. A DNS query to a domain on a threat intelligence feed or a connection to a low-reputation IP address post-trigger is a strong indicator of compromise."
    answer_sources:
      - "Zeek conn.log"
      - "Zeek dns.log"
      - "Dynamic analysis sandbox logs (API call traces, system call logs, file system access)"
      - "Network egress points for corporate mobile devices (via VPN or proxy), guest Wi-Fi network segments, and dedicated mobile security analysis sandboxes."
    range: "last 90 days"
    queries:
      - "IN sandbox, APPLY environmental triggers sequentially. MONITOR network logs for 60s post-trigger. IF DNS query to threat-intel domain OR connection to low-reputation IP, THEN ALERT."
  - question: "Does an application's network traffic volume or entropy significantly increase beyond its established baseline following an environmental trigger?"
    context: "This question uses behavioral baselining to detect a state change in the application. A malicious app might lay dormant with minimal network traffic, then suddenly begin C2 communication or data exfiltration after its guardrails are satisfied. By establishing a statistical baseline (mean $$ \\mu $$ and standard deviation $$ \\sigma $$) of its network behavior and then applying a trigger, we can alert on any post-trigger activity that significantly deviates from this norm (e.g., exceeding $$ \\mu + 3\\sigma $$). A jump in the entropy of destination ports or DNS queries further confirms a shift to more varied, potentially malicious, network activity."
    answer_sources:
      - "Zeek conn.log"
      - "Zeek dns.log"
      - "Dynamic analysis sandbox logs (API call traces, system call logs, file system access)"
      - "Network egress points for corporate mobile devices (via VPN or proxy), guest Wi-Fi network segments, and dedicated mobile security analysis sandboxes."
    range: "last 90 days"
    queries:
      - "ESTABLISH baseline network traffic (mean $$ \\mu $$, std dev $$ \\sigma $$). APPLY trigger. IF outbound bytes > $$ \\mu + 3\\sigma $$ OR IF entropy of DNS/ports increases significantly, THEN ALERT."
  - question: "Can an LSTM autoencoder model detect a significant anomaly in an application's network behavior after an environmental trigger is applied?"
    context: "This question applies a more advanced machine learning technique for anomaly detection. A Long Short-Term Memory (LSTM) autoencoder can learn the 'normal' sequence and patterns of an application's network flows. After this learning phase, the model is used to reconstruct observed network traffic in real-time. If, after an environmental trigger, the application's behavior changes, the model will struggle to reconstruct it, leading to a high 'reconstruction error.' A spike in this error above a learned threshold indicates a significant behavioral anomaly inconsistent with its previously benign state."
    answer_sources:
      - "Zeek conn.log"
      - "Zeek dns.log"
      - "Dynamic analysis sandbox logs (API call traces, system call logs, file system access)"
      - "Network egress points for corporate mobile devices (via VPN or proxy), guest Wi-Fi network segments, and dedicated mobile security analysis sandboxes."
    range: "last 90 days"
    queries:
      - "TRAIN LSTM autoencoder on baseline network flow data. APPLY environmental trigger. MONITOR real-time traffic. IF model reconstruction error > 99th percentile, THEN ALERT."