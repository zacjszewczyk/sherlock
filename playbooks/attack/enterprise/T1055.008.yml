name: T1055.008: Ptrace System Calls
id: f5b8e9a0-654b-4b1a-8f9c-0d3a7e6b1c2d
description: This playbook helps investigate the malicious use of ptrace system calls for privilege escalation and defense evasion. Adversaries use ptrace to attach to other processes, allowing them to read/write memory, inject code, and hijack execution flow. This is detected by identifying when a ptrace'd process makes suspicious outbound network connections to threat-listed or rare destinations, when unauthorized or rare processes initiate ptrace, when a non-root process targets a root process leading to suspicious activity like shell spawning or loading unusual libraries, or when there are statistical spikes in ptrace volume. It also covers defense evasion, such as ptrace being used to tamper with security tools, hijack trusted system processes to blend in, access sensitive files for credential theft, or establish network backdoors.
type: technique
related:
- TA0004: Privilege Escalation
- TA0005: Defense Evasion
contributors:
- Zachary Szewczyk
- Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
- question: Did a process targeted by ptrace make a network connection to a known malicious indicator?
  context: This question looks for a high-confidence indicator of compromise. After an adversary injects code into a process using ptrace, that code often needs to communicate with a command-and-control (C2) server. This action correlates the ptrace event with subsequent network or DNS activity from the compromised process and checks the destination against a threat intelligence feed. A match strongly suggests the process has been hijacked and is communicating with malicious infrastructure.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - Zeek conn.log
  - Zeek dns.log
  - Critical Linux servers (e.g., web, database), Internet gateway/egress points
  range: Last 90 days
  queries:
  - pseudocode: |
      ON (Linux Auditd event WHERE syscall == "ptrace") AS ptrace_event
      WITHIN 5 minutes ON same host
      JOIN (Zeek conn.log OR Zeek dns.log) AS net_event
        WHERE ptrace_event.target_pid == net_event.pid
      JOIN threat_intel_feed
        WHERE net_event.destination_ip == threat_intel_feed.ip
           OR net_event.resolved_domain == threat_intel_feed.domain
      ALERT on match
- question: Did a process targeted by ptrace make a statistically rare network connection?
  context: This question aims to detect connections to new or unknown malicious infrastructure that may not be on a threat intelligence feed yet. By establishing a historical baseline of normal network connections (destination IP and port pairs) for each process executable, we can flag any connection from a ptrace'd process that is highly unusual (e.g., in the bottom 1st percentile of frequency). This anomalous behavior is a strong indicator that injected code is causing the process to act outside of its normal operational profile.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - Zeek conn.log
  - Critical Linux servers (e.g., web, database), Internet gateway/egress points
  range: Last 90 days
  queries:
  - pseudocode: |
      BASELINE frequency of (dest_ip, dest_port) for each process_name over 30 days.
      ON (Linux Auditd event WHERE syscall == "ptrace") AS ptrace_event
      WITHIN 5 minutes ON same host
      FOR EACH (Zeek conn.log event) AS net_event
        WHERE ptrace_event.target_pid == net_event.pid
        CALCULATE rarity of (net_event.dest_ip, net_event.dest_port) for ptrace_event.target_process_name
        IF rarity < 1st percentile
          ALERT on anomalous connection
- question: Can a machine learning model classify network connections from a ptrace-targeted process as malicious?
  context: This question applies a supervised machine learning model to provide a more nuanced and potentially more accurate detection than simple rules. After a ptrace event is observed, any subsequent network connection from the target process is analyzed. Features of the connection (duration, bytes sent/received, port, protocol, IP reputation) are fed into a pre-trained model (e.g., Random Forest) that outputs a probability score of the connection being malicious. A high score provides a strong, data-driven signal of compromise.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - Zeek conn.log
  - Critical Linux servers (e.g., web, database), Internet gateway/egress points
  range: Last 90 days
  queries:
  - pseudocode: |
      TRAIN Random Forest model on labeled (benign/malicious) network data.
      ON (Linux Auditd event WHERE syscall == "ptrace") AS ptrace_event
      FOR EACH subsequent network connection from ptrace_event.target_pid
        EXTRACT features (duration, bytes, port, protocol, ip_rep, etc.)
        PREDICT probability = model.predict(features)
        IF probability > high_threshold
          ALERT on high-probability malicious connection
- question: Was a ptrace system call initiated by a process not on the approved allowlist?
  context: This question provides a high-fidelity method for detecting potentially malicious ptrace usage. In most environments, only a small, specific set of tools (like debuggers, diagnostics, and container runtimes) legitimately use ptrace. By maintaining an allowlist of these known-good executable paths, any ptrace call from a process not on the list is immediately suspicious and warrants a high-severity alert. This is effective at catching custom or unauthorized tools used by adversaries.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - All Linux hosts (servers and workstations), especially those running production applications.
  range: Last 90 days
  queries:
  - pseudocode: |
      DEFINE allowlist = ["/usr/bin/gdb", "/usr/bin/strace", "/usr/sbin/runc", ...]
      ON (Linux Auditd event WHERE syscall == "ptrace") AS ptrace_event
      IF ptrace_event.source_process_exe NOT IN allowlist
        ALERT on unauthorized ptrace usage
- question: Was a ptrace call made by a process that rarely uses ptrace?
  context: This question uses a behavioral, anomaly-based approach to find suspicious ptrace activity. For each host and for the enterprise as a whole, it establishes a baseline of which processes normally use ptrace. If a ptrace call is suddenly initiated by a process that has historically never (or very rarely) used it, this deviation from the norm is flagged. This can catch an adversary using a legitimate but unexpected process to initiate a ptrace-based attack.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - All Linux hosts (servers and workstations), especially those running production applications.
  range: Last 90 days
  queries:
  - pseudocode: |
      BASELINE frequency of ptrace usage by each source_process_exe over 30 days.
      ON (Linux Auditd event WHERE syscall == "ptrace") AS ptrace_event
      CALCULATE rarity_score for ptrace_event.source_process_exe
      IF rarity_score > 99th percentile
        ALERT on rare ptrace source process
- question: Did an unsupervised clustering model identify a ptrace event as an outlier?
  context: This question uses unsupervised machine learning to find novel or complex attack patterns that might not fit simple rules. A clustering algorithm like DBSCAN is used to group historical ptrace events based on multiple features (source process, parent process, user, arguments). These clusters represent "normal" ptrace behavior. Any new ptrace event that does not fit into an existing cluster is flagged as an outlier or noise, indicating a potentially malicious and previously unseen type of activity.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - All Linux hosts (servers and workstations), especially those running production applications.
  range: Last 90 days
  queries:
  - pseudocode: |
      TRAIN DBSCAN model on historical ptrace events using features (source_exe, parent_exe, uid, args).
      ON (new Linux Auditd event WHERE syscall == "ptrace") AS ptrace_event
      CLASSIFY ptrace_event using DBSCAN model.
      IF classification is "outlier" or "noise"
        ALERT on anomalous ptrace cluster
- question: Did a non-root process use ptrace on a root process, which then loaded a suspicious library or spawned a shell?
  context: This question looks for a classic privilege escalation chain. An attacker with low-privilege access may use ptrace to attach to a process running as root. This multi-stage detection first identifies this low-to-high privilege ptrace event. It then watches the now-tainted root process for immediate follow-on actions indicative of code execution, such as loading a shared library from a non-standard, world-writable directory (e.g., /tmp) or spawning a shell. A full match of this sequence is a strong indicator of successful privilege escalation.
  answer_sources:
  - Linux Auditd (syscall=ptrace, execve)
  - Sysmon for Linux (Event ID 7: Image Loaded)
  - Multi-user Linux systems, servers with privileged service accounts, container orchestration nodes.
  range: Last 90 days
  queries:
  - pseudocode: |
      ON (Auditd ptrace event) WHERE source_uid != 0 AND target_euid == 0 AS stage1
      WITHIN 10 seconds ON same target_pid
      LOOK FOR (Sysmon event 7 WHERE image_path IN ["/tmp", "/var/tmp"])
            OR (Auditd execve event WHERE process_name IN ["/bin/sh", "/bin/bash"]) AS stage2
      IF stage1 AND stage2 are correlated
        ALERT on privilege escalation chain
- question: Following a non-root to root ptrace event, did the target process perform historically unprecedented actions?
  context: This question provides a behavioral check following a suspected privilege escalation attempt. After a non-root process ptrace's a root process, this method analyzes the root process's subsequent actions against its own history. It calculates the probability of it spawning a certain child process or loading a specific library. If the observed action is historically unprecedented or has a very low probability (e.g., <1%), it suggests the process's normal execution has been hijacked by injected code.
  answer_sources:
  - Linux Auditd (syscall=ptrace, execve)
  - Sysmon for Linux (Event ID 7: Image Loaded)
  - Multi-user Linux systems, servers with privileged service accounts, container orchestration nodes.
  range: Last 90 days
  queries:
  - pseudocode: |
      BASELINE P(Child|Parent) and P(Library|Process) for privileged processes.
      ON (Auditd ptrace event) WHERE source_uid != 0 AND target_euid == 0 AS ptrace_event
      FOR EACH subsequent child_process or loaded_library by target_pid
        CALCULATE probability P(action|target_process)
        IF probability < 0.01%
          ALERT on unprecedented behavior post-ptrace
- question: Did a time-series model detect a behavioral deviation in a privileged process's system calls after it was targeted by ptrace?
  context: This question uses an advanced machine learning model (LSTM) to detect subtle changes in a process's core behavior. The model is trained on the normal sequence of system calls made by a specific high-privilege process. After a low-to-high privilege ptrace event occurs, the subsequent stream of system calls from the target process is fed into the model. If the injected code forces the process to execute calls in an abnormal order, the model will generate a high anomaly score, indicating a significant deviation from its learned behavior.
  answer_sources:
  - Linux Auditd (syscall=ptrace, execve)
  - Sysmon for Linux (Event ID 7: Image Loaded)
  - Multi-user Linux systems, servers with privileged service accounts, container orchestration nodes.
  range: Last 90 days
  queries:
  - pseudocode: |
      TRAIN LSTM model on normal syscall sequences for privileged processes.
      ON (Auditd ptrace event) WHERE source_uid != 0 AND target_euid == 0
      CAPTURE subsequent syscall sequence from target_pid.
      CALCULATE anomaly_score = model.predict(sequence)
      IF anomaly_score > threshold
        ALERT on syscall sequence anomaly
- question: Was there a spike in ptrace calls from a single user/host, or was an unknown source-target ptrace pair observed?
  context: This question uses simple but effective heuristics to detect ptrace abuse. It employs two rules. The first is a volume-based threshold that alerts if a single user or host generates an unusually high number of ptrace calls in a short time, which could indicate a brute-force or scanning tool. The second rule maintains a list of known-good (source process, target process) pairs and alerts on any new pair, immediately flagging previously unseen and un-baselined ptrace interactions.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - Fleets of Linux servers with consistent roles (e.g., web server farm), developer workstation subnets.
  range: Last 90 days
  queries:
  - pseudocode: |
      RULE A: COUNT ptrace events by user/host in 1 minute. IF count > 50, ALERT.
      RULE B: DEFINE known_pairs = [("gdb", "my_app"), ("strace", "nginx"), ...]
              ON (ptrace event)
              IF (source_process, target_process) NOT IN known_pairs, ALERT.
- question: Did the rate of ptrace calls on a host exceed its dynamic baseline, or was a new enterprise-wide ptrace pair seen?
  context: This question refines the simple threshold approach by using dynamic baselining. It models the normal rate of ptrace calls for each host over time and alerts when the current rate significantly exceeds the moving average (e.g., by more than 3 standard deviations). This adapts to normal fluctuations and reduces false positives. It complements this host-centric view with an enterprise-wide analysis, creating a frequency map of all ptrace source-target pairs and alerting on the first-ever observation of a new pair anywhere in the environment.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - Fleets of Linux servers with consistent roles (e.g., web server farm), developer workstation subnets.
  range: Last 90 days
  queries:
  - pseudocode: |
      RULE A: For each host, calculate 24-hr moving average and stdev of ptrace rate.
              IF current_rate > (average + 3 * stdev), ALERT.
      RULE B: Maintain enterprise-wide set of observed (source_exe, target_exe) pairs.
              ON (ptrace event)
              IF (source_exe, target_exe) is new to the set, ALERT and add it.
- question: Did a graph-based model detect anomalous structural changes in ptrace activity?
  context: This question uses an advanced graph neural network (GNN) to understand the system-wide relationships of ptrace calls. Processes are nodes and ptrace calls are directed edges. The GNN is trained to recognize the normal structure of this graph. It can then detect anomalous changes, such as a new process appearing and acting as a "hub" (ptrace'ing many other processes) or a "bridge" (connecting previously disconnected groups of processes). This can reveal the operational pattern of a malicious tool that simple per-event analysis would miss.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - Fleets of Linux servers with consistent roles (e.g., web server farm), developer workstation subnets.
  range: Last 90 days
  queries:
  - pseudocode: |
      MODEL ptrace events as a directed graph G = (Processes, Ptrace_Calls).
      TRAIN a GNN model on the structure of G over time.
      DETECT when the GNN flags a new edge or node as a structural anomaly (e.g., new hub).
      ALERT on anomalous graph structure change.
- question: Was a known security tool targeted by a ptrace call from an unauthorized process?
  context: This question addresses a critical defense evasion technique. Adversaries may attempt to disable or blind security software (like an EDR agent, antivirus scanner, or audit daemon) by attaching to its process with ptrace. This rule maintains a watchlist of these critical security agent process names. It generates a high-priority alert if any process on this list is targeted by ptrace, unless the source is a known, authorized helper for that tool. This is a strong indicator of an active attempt to subvert security controls.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - All Linux endpoints and servers with security agents installed.
  range: Last 90 days
  queries:
  - pseudocode: |
      DEFINE security_agents = ["osqueryd", "falco", "auditd", "cbagentd", ...]
      DEFINE exceptions = [("falco-driver-loader", "falco"), ...]
      ON (Linux Auditd event WHERE syscall == "ptrace") AS ptrace_event
      IF ptrace_event.target_process_name IN security_agents
         AND (ptrace_event.source_process_name, ptrace_event.target_process_name) NOT IN exceptions
        HIGH SEVERITY ALERT on security tool tampering.
- question: Did a statistically rare user or process use ptrace to target a security agent?
  context: This question provides a behavioral approach to detecting the tampering of security agents. While some legitimate administrative or system processes might interact with security agents, these interactions are typically predictable. This method baselines all ptrace interactions with security agents over a 30-day period. It then alerts on any new ptrace event where the source user and source process combination is either brand new or occurs with extremely low frequency, suggesting an unauthorized and suspicious interaction.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - All Linux endpoints and servers with security agents installed.
  range: Last 90 days
  queries:
  - pseudocode: |
      DEFINE security_agents = ["osqueryd", "falco", ...]
      BASELINE frequency of (source_user, source_process) pairs that ptrace security_agents.
      ON (ptrace event) WHERE target_process_name IN security_agents
      CALCULATE rarity of (source_user, source_process) pair.
      IF rarity < 1st percentile or never seen before
        ALERT on anomalous interaction with security agent.
- question: Did a machine learning classifier identify a ptrace interaction with a security agent as malicious?
  context: This question uses a supervised learning model to distinguish between benign and malicious ptrace interactions with security tools. A classifier is trained on labeled data, using features like the source process name, user context, and command-line arguments. When a ptrace event targeting a security agent occurs, these features are fed to the model. A high "malicious" probability score from the model provides a high-fidelity alert, indicating that the characteristics of the interaction closely match known malicious tampering techniques rather than legitimate diagnostics.
  answer_sources:
  - Linux Auditd (syscall=ptrace)
  - All Linux endpoints and servers with security agents installed.
  range: Last 90 days
  queries:
  - pseudocode: |
      TRAIN classifier model on labeled (benign/malicious) interactions with security agents.
      ON (ptrace event) WHERE target_process_name IN security_agents
      EXTRACT features (source_process, user, cmdline, etc.)
      PREDICT probability = model.predict(features)
      IF probability > high_threshold
        ALERT on probable malicious tampering.
- question: After being targeted by ptrace, did a trusted server process spawn a shell or connect to a non-standard port?
  context: This question aims to detect process hijacking, a common technique for defense evasion. Adversaries often target legitimate, long-running server processes (like 'nginx' or 'sshd') to inject their code, as this activity can blend in with normal operations. This rule detects this by first identifying when a trusted process is the target of a ptrace call. It then watches for highly suspicious follow-on behavior from that same process, such as spawning an interactive shell or making a network connection to an unusual port, which are actions these processes should never perform.
  answer_sources:
  - Linux Auditd (syscall=ptrace, execve)
  - Zeek conn.log
  - Linux servers hosting public-facing or critical internal services (e.g., web servers, SSH jump boxes).
  range: Last 90 days
  queries:
  - pseudocode: |
      DEFINE trusted_processes = ["nginx", "apache2", "sshd", ...]
      ON (ptrace event) WHERE target_process_name IN trusted_processes AS stage1
      WITHIN 5 minutes ON same PID or child PID
      LOOK FOR (execve of interactive shell) OR (outbound connection to non-standard port) AS stage2
      IF stage1 AND stage2 are correlated
        ALERT on trusted process hijack.
- question: Did a trusted process, after a ptrace event, exhibit behavior (child processes, network destinations) that deviates from its historical baseline?
  context: This question provides a more robust, data-driven version of the trusted process hijack detection. Instead of looking for specific bad actions, it compares all subsequent behavior of a ptrace-targeted trusted process against a detailed historical baseline. This baseline includes all normal child processes, network destination ports, and domains/IPs it communicates with. Any activity that is statistically rare or has never been observed before (e.g., spawning a new type of child process) is flagged as a significant deviation, suggesting its logic has been compromised.
  answer_sources:
  - Linux Auditd (syscall=ptrace, execve)
  - Zeek conn.log
  - Linux servers hosting public-facing or critical internal services (e.g., web servers, SSH jump boxes).
  range: Last 90 days
  queries:
  - pseudocode: |
      FOR each trusted_process, BASELINE normal child processes and network destinations.
      ON (ptrace event) WHERE target_process_name is trusted
      MONITOR subsequent child processes and network connections from target_pid.
      IF child_process is not in baseline OR network_destination is not in baseline
        ALERT on behavioral deviation of trusted process.
- question: Did an autoencoder model detect an anomalous sequence of behavior from a trusted process after it was targeted by ptrace?
  context: This question uses an unsupervised autoencoder model to detect sophisticated process hijacking. The model learns a compressed representation of a trusted process's normal sequences of behavior, including system calls and network activity. After a ptrace event targets the process, its subsequent actions are fed into the autoencoder. If the process's logic has been altered by injected code, the new sequence of actions will not match the learned patterns. This results in a high reconstruction error from the model, serving as a strong indicator of compromise.
  answer_sources:
  - Linux Auditd (syscall=ptrace, execve)
  - Zeek conn.log
  - Linux servers hosting public-facing or critical internal services (e.g., web servers, SSH jump boxes).
  range: Last 90 days
  queries:
  - pseudocode: |
      TRAIN autoencoder model on normal behavior sequences for each trusted process.
      ON (ptrace event) WHERE target_process_name is trusted
      CAPTURE subsequent action sequence from target_pid.
      CALCULATE reconstruction_error = model.predict(sequence)
      IF reconstruction_error > threshold
        ALERT on anomalous behavior sequence.
- question: After being targeted by ptrace, did a process access sensitive files or drop and execute a new file in a world-writable directory?
  context: This question looks for common post-exploitation activities following process injection. After an adversary compromises a process via ptrace, they often use that access to achieve other objectives. This rule detects a sequence where a ptrace'd process either attempts to access sensitive files for credential theft or privilege escalation (e.g., /etc/shadow, ~/.ssh/id_rsa) or attempts to establish persistence by writing a new executable file to a temporary directory (like /tmp) and making it executable (`chmod`).
  answer_sources:
  - Linux Auditd (syscall=ptrace, openat, chmod)
  - File systems on critical Linux servers, user home directories.
  range: Last 90 days
  queries:
  - pseudocode: |
      DEFINE sensitive_files = ["/etc/shadow", "/etc/sudoers", ".ssh/id_rsa"]
      ON (ptrace event) AS stage1
      WITHIN 2 minutes ON same PID
      LOOK FOR (openat syscall for file IN sensitive_files)
            OR (write to "/tmp" followed by chmod +x) AS stage2
      IF stage1 AND stage2 are correlated
        ALERT on post-ptrace malicious file activity.
- question: Did the file access patterns of a ptrace-targeted process show a sudden increase in entropy, suggesting discovery activity?
  context: This question aims to detect file system discovery behavior by injected code. A normal process typically accesses a predictable set of files and directories. However, code injected by an attacker might scan the file system to find valuable data or configuration files. This reconnaissance activity involves accessing many different, unrelated file paths. This behavior can be mathematically quantified by calculating the Shannon entropy of the directory paths accessed by the process in a short window. A sharp spike in entropy after a ptrace event indicates abnormal discovery activity.
  answer_sources:
  - Linux Auditd (syscall=ptrace, openat, chmod)
  - File systems on critical Linux servers, user home directories.
  range: Last 90 days
  queries:
  - pseudocode: |
      BASELINE normal file path entropy for key processes.
      ON (ptrace event)
      WITHIN 5 minutes ON same PID
      CALCULATE entropy of directory paths from 'openat' syscalls.
      IF current_entropy is significantly higher than baseline_entropy
        ALERT on potential file system discovery.
- question: Did a one-class SVM model classify file access by a ptrace-targeted process as an outlier?
  context: This question uses a one-class SVM, an unsupervised machine learning model, to identify abnormal file access. The model is trained on the legitimate file access patterns of a high-value process, learning a boundary that encompasses "normal" behavior. After that process is targeted by a ptrace call, any subsequent file access it makes is classified by the model. If an access is flagged as an outlier (i.e., it falls outside the learned boundary of normal behavior), it is a strong indicator that the process is compromised and performing unauthorized actions.
  answer_sources:
  - Linux Auditd (syscall=ptrace, openat, chmod)
  - File systems on critical Linux servers, user home directories.
  range: Last 90 days
  queries:
  - pseudocode: |
      TRAIN One-Class SVM model on legitimate file access patterns (vectorized paths) for a process.
      ON (ptrace event) targeting that process
      FOR each subsequent file access by target_pid
        CLASSIFY access using the SVM model.
        IF classification is "outlier"
          ALERT on anomalous file access.
- question: Following a ptrace event, did the target process attempt to open a bind shell or initiate a reverse shell?
  context: This question looks for specific syscall sequences that indicate the creation of a network backdoor. After injecting code via ptrace, an adversary may want to open a port for remote access. This rule detects two common patterns. A "Bind Shell" is detected by the sequence of `socket`, `bind`, and `listen` syscalls from the compromised process. A "Reverse Shell" is detected by the `socket` and `connect` syscall sequence, often correlated with an outbound network connection to an external IP.
  answer_sources:
  - Linux Auditd (syscall=ptrace, socket, bind, listen, connect)
  - Zeek conn.log
  - Network interfaces of all Linux hosts, network egress points.
  range: Last 90 days
  queries:
  - pseudocode: |
      ON (ptrace event)
      WITHIN 1 minute on same PID
      LOOK FOR sequence (socket, bind, listen) -> ALERT "Bind Shell"
            OR sequence (socket, connect) -> ALERT "Reverse Shell"
- question: After being targeted by ptrace, did a process open a new listening port that is statistically rare across the enterprise?
  context: This question focuses on identifying backdoors by analyzing the rarity of the listening port itself. While legitimate applications open listening ports, they are typically common and well-known. An attacker's backdoor often uses a high-numbered, arbitrary port. This method maintains a baseline of all listening ports across the enterprise and performs a "stack count" on any new port opened by a ptrace-targeted process. If the port is extremely rare (e.g., active on less than 0.1% of hosts), it is flagged as a highly suspicious potential backdoor.
  answer_sources:
  - Linux Auditd (syscall=ptrace, socket, bind, listen, connect)
  - Zeek conn.log
  - Network interfaces of all Linux hosts, network egress points.
  range: Last 90 days
  queries:
  - pseudocode: |
      BASELINE set of all listening ports across enterprise.
      ON (ptrace event)
      AFTER process opens a new listening port `p`
      CALCULATE prevalence of port `p` across all hosts.
      IF prevalence < 0.1%
        ALERT on rare listening port, potential backdoor.
- question: Did an RNN model, trained on legitimate network syscall sequences, flag the behavior of a ptrace-targeted process as anomalous?
  context: This question uses a Recurrent Neural Network (RNN), a sophisticated time-series model, to detect anomalous network behavior. The RNN is trained on legitimate sequences of network-related syscalls (`socket`, `connect`, `bind`, etc.). This allows it to learn complex patterns of normal network setup. After a process is targeted by ptrace, its subsequent network syscall sequence is analyzed by the model. If the sequence is unlikely or doesn't match learned patterns (e.g., the setup for a custom C2 protocol), the model will flag it as an anomaly.
  answer_sources:
  - Linux Auditd (syscall=ptrace, socket, bind, listen, connect)
  - Zeek conn.log
  - Network interfaces of all Linux hosts, network egress points.
  range: Last 90 days
  queries:
  - pseudocode: |
      TRAIN RNN model on legitimate sequences of network-related syscalls.
      ON (ptrace event)
      CAPTURE subsequent network syscall sequence from target_pid.
      CALCULATE probability of sequence from RNN model.
      IF probability is very low
        ALERT on anomalous network syscall sequence.