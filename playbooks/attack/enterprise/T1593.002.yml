name: T1593.002: Search Engines
id: a1b2c3d4-e5f6-4a7b-8c9d-0e1f2a3b4c5d
description: This playbook helps investigate whether an adversary is using search engines for reconnaissance to find exploitable information about the organization. It focuses on detecting evidence of sensitive organizational data indexed by public search engines, identifying internal process creation events downloading files from non-corporate domains (potentially found via reconnaissance), spotting inbound web traffic from search engines using advanced search operators (dorks) to probe for vulnerabilities, and detecting internal access to known leaked data previously identified through external reconnaissance.
type: technique
related:
  - TA0043: Reconnaissance
contributors:
  - Zachary Szewczyk
  - Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Are automated queries (dorks) against public search engines revealing sensitive organizational data?
    context: This question aims to proactively identify if sensitive information, such as files containing keywords like 'password' or 'api_key', sensitive file types like '.pem' or '.sql', or internal hostnames, are publicly accessible and indexed by search engines. A direct match indicates an immediate data exposure risk that an adversary could exploit.
    answer_sources:
      - External Search Engine API Query Results
      - Public-facing websites and web applications, public code repositories (e.g., GitHub, GitLab), public cloud storage (e.g., S3 buckets, Azure blobs), and public paste sites (e.g., Pastebin) indexed by search engines.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "FOR each dork in watchlist, EXECUTE search_api_query(dork). IF results contain organizational domain, TRIGGER alert."
  - question: Are publicly discovered documents associated with the organization showing a statistically unusual frequency of sensitive keywords compared to a baseline?
    context: This question helps to quantify the risk of a potential data leak. By establishing a baseline for 'normal' public content and scoring new discoveries against it, analysts can prioritize review of documents that are statistical outliers, suggesting they contain an abnormally high concentration of sensitive terms.
    answer_sources:
      - External Search Engine API Query Results
      - Public-facing websites and web applications, public code repositories (e.g., GitHub, GitLab), public cloud storage (e.g., S3 buckets, Azure blobs), and public paste sites (e.g., Pastebin) indexed by search engines.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "FOR each document_url, CALCULATE risk_score based on keyword frequency. IF risk_score > baseline_95th_percentile, FLAG for review."
  - question: Can a machine learning model classify any discovered public documents as 'sensitive' with high confidence?
    context: This question leverages a text classification model to automate the initial assessment of discovered documents. By training a model on known examples of sensitive and benign data, it can provide a consistent and scalable method for flagging potential data leaks that require human investigation, reducing manual toil.
    answer_sources:
      - External Search Engine API Query Results
      - Public-facing websites and web applications, public code repositories (e.g., GitHub, GitLab), public cloud storage (e.g., S3 buckets, Azure blobs), and public paste sites (e.g., Pastebin) indexed by search engines.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "FOR each document, PREDICT classification using model. IF classification == 'sensitive' AND confidence > 0.90, TRIGGER alert."
  - question: Are internal hosts executing download utilities to retrieve content from known malicious domains?
    context: This question seeks to identify a potential follow-on action after reconnaissance. An adversary who discovers a resource may attempt to download tools or scripts onto a compromised host. Correlating downloads from specific utilities (curl, wget, bitsadmin) with threat intelligence feeds provides a high-confidence indicator of malicious activity.
    answer_sources:
      - Windows Event ID 4688
      - Zeek http.log
      - Zeek files.log
      - Zeek conn.log
      - Domain Controllers, database servers, application servers, non-developer user workstations, and DMZ-hosted servers.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "ON process_create event (4688), IF process_name in (curl, wget, bitsadmin), EXTRACT URL. IF domain(URL) in malicious_feed, TRIGGER alert."
  - question: Is there statistically rare usage of command-line download utilities on servers or by non-privileged users?
    context: This question uses behavioral analysis to detect anomalies. Legitimate use of command-line downloaders is often confined to specific roles (developers, admins) and systems. A rare execution on a server or by a regular user is a strong deviation from normal behavior and could indicate a compromised account or host being used for unauthorized downloads.
    answer_sources:
      - Windows Event ID 4688
      - Zeek http.log
      - Zeek files.log
      - Zeek conn.log
      - Domain Controllers, database servers, application servers, non-developer user workstations, and DMZ-hosted servers.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "FOR each download_utility_execution, CALCULATE rarity_score based on host/user baseline. IF rarity_score < 5th_percentile, FLAG for review."
  - question: Does a machine learning model predict a high probability of a file download being malicious based on its context?
    context: This question applies a predictive model to assess the risk of a download event. By considering multiple features like the user's role, the host type, and the reputation of the source domain, the model can identify high-risk downloads that may not trigger simpler rule-based alerts, providing a more nuanced detection capability.
    answer_sources:
      - Windows Event ID 4688
      - Zeek http.log
      - Zeek files.log
      - Zeek conn.log
      - Domain Controllers, database servers, application servers, non-developer user workstations, and DMZ-hosted servers.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "FOR each download_event, PREDICT probability_malicious using model. IF probability > 0.85, TRIGGER alert."
  - question: Are external IPs sending requests to our web servers with 'dorking' operators in the Referer header?
    context: This question aims to directly detect reconnaissance activity. When an adversary uses a search engine with advanced operators ('dorks') to find vulnerabilities, the browser may include the search query in the HTTP `Referer` header when clicking a link. Detecting these dorks in server logs is a direct indication that the organization's sites are being actively probed.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Network ingress points (firewalls, load balancers), public-facing web server farms, and reverse proxy servers.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "ON http_log event, PARSE referer_header. IF referer_query contains dorking_pattern AND source_ip is external, TRIGGER alert."
  - question: Are any external IPs exhibiting anomalous browsing behavior, such as high URI entropy and a high client error rate, indicative of automated scanning?
    context: This question looks for signs of automated scanning or enumeration tools. Unlike a human user, a tool will often request many different, non-sequential URIs (high entropy) and generate many 'Not Found' errors (4xx codes). A simultaneous spike in both metrics from a single IP, compared to a baseline, strongly suggests targeted reconnaissance.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Network ingress points (firewalls, load balancers), public-facing web server farms, and reverse proxy servers.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "FOR each source_ip, CALCULATE uri_entropy and error_ratio in 5min window. IF entropy > baseline_98th_percentile AND error_ratio > baseline_98th_percentile, TRIGGER alert."
  - question: Is traffic volume from a single IP with a search engine referrer significantly deviating from predicted levels?
    context: This question uses time-series analysis to detect large-scale reconnaissance campaigns. By modeling the expected traffic volume from search engine referrers, the system can automatically flag significant, unexpected spikes from a single source. This can indicate an adversary using automated tools to rapidly sift through search results related to the organization's web properties.
    answer_sources:
      - Zeek http.log
      - Zeek conn.log
      - Network ingress points (firewalls, load balancers), public-facing web server farms, and reverse proxy servers.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "FOR each ip_with_search_referrer, FORECAST expected_request_volume. IF actual_volume > predicted_99_ci, TRIGGER alert."
  - question: Is an internal host accessing a URL known to contain previously leaked organizational data?
    context: This question addresses the risk of internal actors (malicious or unwitting) or compromised systems accessing known data exposures. A direct match against a watchlist of leaked data URLs is a high-fidelity indicator of a security incident, signifying that leaked information is now being accessed from within the network.
    answer_sources:
      - Zeek http.log
      - Zeek dns.log
      - Zeek conn.log
      - Network egress points, forward proxy server logs, DNS resolver logs, and user workstations subnets.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "ON outbound http_request, IF destination_url in leaked_data_watchlist, TRIGGER high_severity_alert."
  - question: Are internal hosts accessing URLs that are highly similar, but not identical, to URLs on the leaked data watchlist?
    context: This question helps to find related exposures that may not be on the exact watchlist. An adversary might post leaked data in multiple locations on the same site. A high similarity score (e.g., a different file in the same directory) indicates a strong possibility that a user is accessing related leaked content, warranting further investigation.
    answer_sources:
      - Zeek http.log
      - Zeek dns.log
      - Zeek conn.log
      - Network egress points, forward proxy server logs, DNS resolver logs, and user workstations subnets.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "FOR each outbound_url, CALCULATE jaccard_similarity with watchlist_urls. IF similarity_score > 0.85, FLAG for investigation."
  - question: Is a machine learning model flagging outbound web requests as anomalous, potentially indicating access to a previously unknown data leak?
    context: This question provides a safety net for detecting access to new or unknown data leaks. By modeling a user's normal browsing behavior (common sites, typical domain reputation, etc.), an anomaly detection model can flag requests to unusual destinations. This can help identify access to a leaked data site even before that site has been added to a formal watchlist.
    answer_sources:
      - Zeek http.log
      - Zeek dns.log
      - Zeek conn.log
      - Network egress points, forward proxy server logs, DNS resolver logs, and user workstations subnets.
    range: last 90 days
    queries:
      - search: pseudocode
        query: "FOR each outbound_request, SCORE with anomaly_model. IF score indicates anomaly, FLAG for investigation."