name: T1578: Modify Cloud Compute Infrastructure
id: c1b0a9a8-3f1d-4c6e-932b-8a9d7e5f6c4d
description: This playbook helps investigate whether an adversary is attempting to evade defenses by modifying cloud compute infrastructure. It focuses on detecting the execution of malicious tools, suspicious network connections to cloud APIs, sequences of API calls matching known attack patterns, configuration of overly permissive security settings, API calls made in anomalous contexts (e.g., unusual time or location), spikes in resource modification activity, and anomalous outbound data transfers that are correlated with infrastructure changes.
type: technique
related:
- TA0005: Defense Evasion
contributors:
- Zachary Szewczyk
- Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
- question: Are any processes being created that match known malicious tools or scripts used for unauthorized cloud infrastructure modification?
  context: This question aims to detect the initial execution of adversary tools on endpoints. Adversaries often deploy specific malware or scripts (like Pacu or Cloud-Sniper) to interact with and modify cloud environments. Identifying these processes by name, hash, or command-line arguments is a direct method for uncovering malicious activity.
  answer_sources:
  - Windows Event ID 4688
  - Zeek conn.log
  - Administrator workstations
  - Developer endpoints
  - CI/CD pipeline servers
  - Bastion hosts
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH process_creation_events
      WHERE process_hash IN (threat_intel_hashes) OR process_name IN (threat_intel_names)
      RETURN hostname, process_name, command_line, hash
- question: Are there any rare or unusual command-line invocations of legitimate cloud CLI tools?
  context: Adversaries may use legitimate cloud command-line interface (CLI) tools to blend in with normal administrative activity. However, their specific command and argument combinations might be unique or rare within an organization. This question focuses on baselining normal CLI usage and flagging statistically rare invocations, which could indicate malicious or unauthorized use of these tools.
  answer_sources:
  - Windows Event ID 4688
  - Zeek conn.log
  - Administrator workstations
  - Developer endpoints
  - CI/CD pipeline servers
  - Bastion hosts
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH process_creation_events WHERE process_name IN ('aws.exe', 'az.cmd')
      STATS frequency(command_line) as command_freq
      WHERE command_freq is rare (e.g., < 1st percentile)
      RETURN hostname, command_line, command_freq
- question: Can machine learning models identify malicious cloud tool usage based on command-line features and correlate it with network activity?
  context: This question explores a more advanced, behavioral approach to detection. By extracting features from command-line arguments (like complexity, length, and specific keywords), a machine learning model can learn to distinguish between normal and malicious usage patterns, even for previously unseen commands. Correlating these findings with network logs adds a layer of confirmation.
  answer_sources:
  - Windows Event ID 4688
  - Zeek conn.log
  - Administrator workstations
  - Developer endpoints
  - CI/CD pipeline servers
  - Bastion hosts
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      APPLY ML model (Random Forest) on process_creation_events
      WHERE prediction == 'malicious_cloud_tool'
      JOIN with network_logs on (hostname, timestamp)
      RETURN hostname, process_name, command_line, destination_ip
- question: Are there any network connections to cloud APIs using User-Agent strings from a denylist of malicious or suspicious tools?
  context: The User-Agent string in an HTTP request identifies the client software. Malicious tools, outdated software development kits (SDKs), or generic command-line utilities like 'curl' often have distinctive User-Agent strings. Monitoring for these known-bad or suspicious strings in traffic to cloud API endpoints can reveal adversary activity.
  answer_sources:
  - Zeek http.log
  - Zeek ssl.log
  - Network egress points
  - Internet gateways
  - Forward proxy servers
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH network_http_logs WHERE destination_ip IN (cloud_api_ranges)
      WHERE user_agent IN (denylist_user_agents)
      RETURN source_ip, destination_ip, user_agent
- question: Are there any statistically rare User-Agent strings or TLS client versions being used to connect to cloud APIs?
  context: Beyond looking for known-bad signatures, this question seeks to find unknown or custom tools by identifying statistical outliers. Most legitimate traffic from an organization will use a common set of browsers and SDKs, resulting in a predictable distribution of User-Agents and TLS versions. A rare value could indicate a custom hacking tool or an unusual client.
  answer_sources:
  - Zeek http.log
  - Zeek ssl.log
  - Network egress points
  - Internet gateways
  - Forward proxy servers
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH network_http_logs WHERE destination_ip IN (cloud_api_ranges)
      STATS frequency(user_agent) as ua_freq
      WHERE ua_freq is rare (e.g., < 1% of total)
      RETURN user_agent, ua_freq
- question: Can machine learning identify anomalous clusters of User-Agent strings that may represent unknown malicious tools?
  context: This question applies unsupervised machine learning to group similar User-Agent strings. The DBSCAN algorithm is effective at identifying clusters and, more importantly, flagging data points that do not belong to any cluster (outliers). These outlier User-Agents are highly suspicious and warrant investigation as they may belong to novel adversary tools.
  answer_sources:
  - Zeek http.log
  - Zeek ssl.log
  - Network egress points
  - Internet gateways
  - Forward proxy servers
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      APPLY ML model (DBSCAN) on user_agent_vectors from network_http_logs
      WHERE cluster == 'outlier'
      RETURN user_agent, source_ip, destination_ip
- question: Has any user identity performed a known attack sequence for data exfiltration, such as creating a public snapshot and copying it to an external account?
  context: Adversaries often follow a specific chain of actions to achieve their objectives. This question looks for a well-known tactic, technique, and procedure (TTP) for exfiltrating data via cloud snapshots. Detecting this specific sequence of API calls in a short time frame from a single user is a high-fidelity indicator of an attack.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Windows Event ID 4688
  - Cloud provider IAM and audit logging services (e.g., AWS CloudTrail S3 bucket, Azure Monitor)
  - Administrator workstations
  - CI/CD servers
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH cloud_audit_logs
      SEQUENCE by user_identity within 30m
        [event_name='CreateSnapshot']
      then
        [event_name='ModifySnapshotAttribute' AND parameters.public=true]
      then
        [event_name='CopySnapshot' AND parameters.destination_account NOT IN (trusted_accounts)]
- question: Are there any sequences of cloud API calls that are statistically improbable compared to normal administrative workflows?
  context: This question uses a probabilistic model (Markov chain) to understand the normal 'flow' of operations for administrators. For example, a 'Create' event is often followed by a 'Modify' event. By modeling these transition probabilities, the system can detect sequences that are highly unusual and do not fit established patterns, which could indicate a novel attack chain.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Windows Event ID 4688
  - Cloud provider IAM and audit logging services (e.g., AWS CloudTrail S3 bucket, Azure Monitor)
  - Administrator workstations
  - CI/CD servers
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      APPLY ML model (Markov Chain) on sequences of cloud_audit_logs by user
      WHERE sequence_probability < threshold
      RETURN user_identity, event_sequence, probability
- question: Can a deep learning model detect anomalous sequences of API calls that deviate significantly from learned normal behavior?
  context: This question proposes using a sophisticated deep learning model (LSTM autoencoder) to learn the complex, long-term patterns of normal API call sequences. The model tries to 'reconstruct' new sequences it observes. If it fails to reconstruct a sequence accurately (high reconstruction error), it means the sequence is unlike anything seen in the training data of normal behavior, flagging it as a potential attack.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Windows Event ID 4688
  - Cloud provider IAM and audit logging services (e.g., AWS CloudTrail S3 bucket, Azure Monitor)
  - Administrator workstations
  - CI/CD servers
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      APPLY ML model (LSTM Autoencoder) on sequences of cloud_audit_logs by user
      WHERE reconstruction_error > threshold
      RETURN user_identity, event_sequence, error_score
- question: Are there any API calls or commands being executed that configure overly permissive settings, such as allowing public access?
  context: A common adversary technique is to weaken security controls to enable access or exfiltration. This question looks for specific, high-risk configuration changes, such as opening a firewall to the entire internet ('0.0.0.0/0') or making a resource publicly accessible. These are often done via specific parameters in API calls or CLI commands, which can be detected with pattern matching.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Windows Event ID 4688
  - Cloud provider IAM and audit logging services
  - Configuration Management Databases (CMDB)
  - Administrator workstations
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH cloud_audit_logs OR process_creation_events
      WHERE event_parameters MATCHES_REGEX ('0.0.0.0/0', 'allUsers', 'Principal: *')
      RETURN user, event_name, full_event_details
- question: Is any user executing an unusually high number of 'risky' API calls compared to the baseline for their role?
  context: While some users need to perform risky actions as part of their job, a sudden spike in this activity can be an indicator of compromise. This question involves defining a set of risky API calls, baselining the normal frequency of these calls for different user roles (e.g., network admin vs. developer), and alerting when an individual significantly exceeds the norm for their peer group.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Windows Event ID 4688
  - Cloud provider IAM and audit logging services
  - Configuration Management Databases (CMDB)
  - Administrator workstations
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH cloud_audit_logs WHERE event_name IN (risky_api_calls)
      STATS count by user, user_role, time_bucket(24h)
      WHERE count > (avg_for_role + 2 * stdev_for_role)
      RETURN user, count
- question: Can a machine learning model classify API calls as 'high-risk' based on their parameters, even for API calls not on a predefined list?
  context: This question seeks to automate and expand the concept of identifying 'risky' API calls. Instead of relying on a static list, a machine learning model can be trained to recognize the characteristics of a high-risk command based on its parameters (e.g., does it contain wildcards, does it affect a critical resource). This allows for the dynamic identification of risky behavior across a wide range of API calls.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Windows Event ID 4688
  - Cloud provider IAM and audit logging services
  - Configuration Management Databases (CMDB)
  - Administrator workstations
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      APPLY ML model (Logistic Regression) on cloud_audit_logs
      WHERE prediction == 'high-risk'
      RETURN user, event_name, event_parameters
- question: Has any sensitive cloud modification API call been executed without multi-factor authentication (MFA)?
  context: MFA is a critical security control. An adversary who has compromised a user's credentials may not have access to their MFA token. Therefore, any sensitive action performed without MFA is highly suspicious. This question targets these specific events, as they could indicate a compromised account is being used to modify the environment.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Zeek conn.log
  - VPN concentrators
  - Cloud provider IAM and audit logging services
  - Endpoints of privileged users
  - Geolocation databases
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH cloud_audit_logs WHERE event_name IN (sensitive_api_calls) AND mfa_authenticated == false
      RETURN user, event_name, source_ip
- question: Has a cloud administrator performed an action from an anomalous context, such as an unusual time, location, or network?
  context: Adversaries often operate at different times and from different locations than legitimate users. This question focuses on building a behavioral baseline for each privileged user, tracking their normal working hours, source IP addresses, and geographic locations. An alert is triggered when an action deviates from this established pattern across multiple factors, which strongly suggests the account may be compromised.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Zeek conn.log
  - VPN concentrators
  - Cloud provider IAM and audit logging services
  - Endpoints of privileged users
  - Geolocation databases
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH cloud_audit_logs
      WHERE user_activity deviates from baseline (e.g., unusual_time AND unusual_location)
      RETURN user, event_name, source_ip, time
- question: Can a machine learning model detect API calls that are outliers based on their combined context (user, time, location, MFA status)?
  context: This question uses an Isolation Forest model, which is efficient at detecting outliers in multi-dimensional data. By combining multiple contextual features (user, time, network, MFA status) into a single analysis, the model can identify events that are anomalous in their totality, even if each individual feature is not necessarily suspicious on its own. This provides a powerful way to detect sophisticated, contextually-aware attacks.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Zeek conn.log
  - VPN concentrators
  - Cloud provider IAM and audit logging services
  - Endpoints of privileged users
  - Geolocation databases
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      APPLY ML model (Isolation Forest) on contextual_features of cloud_audit_logs
      WHERE prediction == 'outlier'
      RETURN user, event_name, source_ip, time, mfa_status
- question: Has any single user or IP address generated a high volume of resource modification API calls in a short period?
  context: Automated scripts, whether used by adversaries for destructive purposes or by cryptominers to provision resources, often generate a large number of API calls very quickly. This question uses simple thresholding to detect such bursts of activity. A legitimate administrator is unlikely to manually create or delete 50 instances in 15 minutes, making this a good indicator of scripted activity.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Cloud provider audit logs (e.g., AWS CloudTrail, Azure Activity Log)
  - CI/CD servers
  - Automation service accounts
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH cloud_audit_logs WHERE event_name IN (modification_api_calls)
      STATS count by user, source_ip over 15m
      WHERE count > 50
      RETURN user, source_ip, count
- question: Has any user's rate of resource modification API calls significantly spiked above their normal baseline?
  context: This question moves beyond fixed thresholds to a more dynamic, user-specific approach. It establishes a 'normal' rate of activity for each user and alerts when they significantly deviate from their own past behavior. This is more effective than a single global threshold, as it can detect anomalies for users who are typically inactive while ignoring the high but normal volume from automation accounts.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Cloud provider audit logs (e.g., AWS CloudTrail, Azure Activity Log)
  - CI/CD servers
  - Automation service accounts
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH cloud_audit_logs WHERE event_name IN (modification_api_calls)
      CALCULATE moving_avg and stdev of count per hour by user
      WHERE current_count > (moving_avg + 3 * stdev)
      RETURN user, current_count
- question: Using time-series forecasting, are there any unexpected spikes in resource modification activity that deviate from predicted seasonal patterns?
  context: This question employs a sophisticated time-series model (SARIMA) that can account for trends and seasonality (e.g., higher activity during business hours or on weekdays). The model forecasts the expected level of activity for a given user at a given time. If the actual observed activity is significantly higher than the forecast, it suggests a burst of activity that cannot be explained by normal patterns.
  answer_sources:
  - AWS CloudTrail
  - Azure Activity Logs
  - Google Cloud Audit Logs
  - Cloud provider audit logs (e.g., AWS CloudTrail, Azure Activity Log)
  - CI/CD servers
  - Automation service accounts
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      APPLY ML model (SARIMA) on time_series of modification_api_calls by user
      WHERE observed_count > forecasted_count + confidence_interval
      RETURN user, observed_count, forecasted_count
- question: Has a large outbound data transfer occurred shortly after a resource's security was weakened, such as a snapshot being made public?
  context: This question directly correlates a suspicious infrastructure change with a potential data exfiltration event. Making a resource public is the setup; the large data transfer is the follow-through. By linking these two events—a control plane action and a data plane observation—in a tight time window, this rule creates a very high-fidelity alert for data theft.
  answer_sources:
  - AWS CloudTrail
  - AWS VPC Flow Logs
  - Azure Network Watcher flow logs
  - Zeek conn.log
  - Cloud provider network gateways (e.g., NAT Gateway, Internet Gateway)
  - VPC/VNet flow log collectors
  - Cloud storage buckets
  - Cloud provider audit logging services
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH cloud_audit_logs for event_name='ModifySnapshotAttribute' and public=true
      JOIN with network_flow_logs within 1h on resource_id
      WHERE bytes_out > 1GB AND destination_ip NOT IN (corporate_ranges)
      RETURN user, resource_id, bytes_out, destination_ip
- question: Following a high-risk infrastructure change, such as creating a VM in a new region, is there an anomalously large amount of outbound traffic from the new resource?
  context: Adversaries may create new resources in unsanctioned regions to stage data for exfiltration. This question focuses on the behavior of these new, suspiciously-created resources. It establishes a baseline for how much data a 'normal' new instance sends out in its first hour and alerts if a new, high-risk instance sends out a statistically unusual amount of data, suggesting it's being used for exfiltration.
  answer_sources:
  - AWS CloudTrail
  - AWS VPC Flow Logs
  - Azure Network Watcher flow logs
  - Zeek conn.log
  - Cloud provider network gateways (e.g., NAT Gateway, Internet Gateway)
  - VPC/VNet flow log collectors
  - Cloud storage buckets
  - Cloud provider audit logging services
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH high_risk_events (e.g., CreateInstance in new_region)
      GET new_resource_id
      SEARCH network_flow_logs for source_resource_id in first hour
      WHERE bytes_out > 99th_percentile_for_new_instances
      RETURN new_resource_id, bytes_out
- question: Can a graph-based model detect the entire chain of events, from user action to resource modification to data exfiltration?
  context: This question represents a holistic approach to threat detection by modeling relationships between entities (users, resources, IPs) and actions. Instead of looking at individual events or simple sequences, a graph database can represent the entire attack chain as a connected path. Detecting the formation of a known malicious path provides a comprehensive view of the adversary's actions and strong evidence of an attack.
  answer_sources:
  - AWS CloudTrail
  - AWS VPC Flow Logs
  - Azure Network Watcher flow logs
  - Zeek conn.log
  - Cloud provider network gateways (e.g., NAT Gateway, Internet Gateway)
  - VPC/VNet flow log collectors
  - Cloud storage buckets
  - Cloud provider audit logging services
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      APPLY graph_analysis_on (users, resources, IPs, events)
      MATCH path (user)-[creates]->(snapshot)-[modifies_public]->(snapshot)-[creates]->(instance)-[sends_data]->(external_ip)
      RETURN path