name: T1098.003: Additional Cloud Roles
id: 9a8b7c6d-5e4f-4a3b-2c1d-0e9f8a7b6c5d
description: This playbook focuses on detecting adversaries who add roles to a compromised cloud account to either maintain persistence or escalate privileges (MITRE ATT&CK T1098.003). It provides investigative questions to identify suspicious IAM modifications, such as those originating from anomalous IP addresses or user agents, the attachment of self-modifying policies, the assignment of high-privilege roles to new or dormant accounts, unusual bursts of IAM API activity, the creation of roles with names matching malicious tools, or the granting of permissions that create known privilege escalation paths.
type: technique
related:
- TA0003: Persistence
- TA0004: Privilege Escalation
contributors: Zachary Szewczyk, Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
- question: Are IAM modification events originating from source IPs or user agents known to be malicious?
  context: This question aims to identify policy changes made from suspicious network locations or with unusual client software. By continuously checking the source IP and user agent of IAM modification events against threat intelligence feeds, we can detect if a known adversary is attempting to add or change cloud roles. A match indicates a high probability of a compromised account being used for persistence.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Zeek conn.log, Cloud provider IAM API endpoints, Network egress points and VPN gateways, Threat intelligence platform feeds.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each IAM modification event
      IF event.sourceIPAddress IN threat_intel_feed OR event.userAgent IN threat_intel_feed
      THEN ALERT
- question: Are IAM modification events originating from statistically rare ASNs or user agents for a given user?
  context: This question helps detect anomalous behavior even when the source isn't on a known threat list. By baselining the typical source Autonomous System Numbers (ASNs) and user agents for each administrative user, we can flag modifications that deviate from their established patterns. An event from a source in the bottom 5th percentile of frequency is a strong indicator of unusual, and potentially malicious, activity.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Zeek conn.log, Cloud provider IAM API endpoints, Network egress points and VPN gateways, Threat intelligence platform feeds.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each administrative user
        BASELINE user.source_asns over last 90 days
        BASELINE user.user_agents over last 90 days
      FOR each new IAM modification event
        IF event.source_asn_frequency < 5th_percentile FOR event.user
        OR event.user_agent_frequency < 5th_percentile FOR event.user
        THEN ALERT
- question: Can we detect malicious IAM modification events by training a machine learning model on their contextual features?
  context: This question explores using a Random Forest classifier to provide a more nuanced detection capability. By training a model on features like source geolocation, ASN, user identity, User-Agent, and time-of-day, the system can learn complex patterns that signify malicious activity beyond simple rule-based checks, reducing false positives and detecting novel attacks. An alert is triggered for events scored as 'malicious' with high confidence.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Zeek conn.log, Cloud provider IAM API endpoints, Network egress points and VPN gateways, Threat intelligence platform feeds.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      MODEL = train_random_forest(historical_iam_events)
      FOR each new IAM modification event
        FEATURES = extract_features(event)
        SCORE = MODEL.predict_proba(FEATURES)
        IF SCORE['malicious'] > 0.85
        THEN ALERT
- question: Has a policy been attached to a principal that would allow it to modify its own permissions?
  context: This question seeks to uncover a common persistence technique where an adversary grants an identity the ability to control its own permissions. By maintaining a list of self-modification permissions (e.g., 'iam:CreatePolicyVersion') and alerting when they are granted, we can detect attempts to create a "god mode" user or role that cannot be easily de-privileged.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, Cloud Security Posture Management (CSPM) tool data repository.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each Attach*Policy or Put*Policy event
      IF event.policy_permissions contains ANY from self_modification_list
      THEN ALERT
- question: Is a newly attached policy statistically unusual in its breadth and power of permissions?
  context: This question aims to identify when a user or role is granted an unusually powerful set of permissions, which may indicate a misconfiguration or malicious intent. By calculating a 'permission entropy' score for all policies and establishing a baseline, we can alert when a newly attached policy has a score in the top percentile, flagging it for review as potentially excessive.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, Cloud Security Posture Management (CSPM) tool data repository.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      BASELINE = calculate_entropy_scores(all_existing_policies)
      FOR each new policy attachment event
        SCORE = calculate_entropy(new_policy)
        IF SCORE > 98th_percentile(BASELINE)
        THEN ALERT
- question: Does a new policy attachment create a path for a principal to modify its own permissions?
  context: This question uses graph theory to detect complex privilege escalation paths. The IAM environment can be modeled as a graph where a new policy attachment (an edge) might create a cycle, allowing a principal to modify itself. This method can uncover non-obvious self-modification paths that simple permission checks might miss.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, Cloud Security Posture Management (CSPM) tool data repository.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each new policy attachment event
        BUILD IAM graph with new attachment
        IF has_cycle_from_principal_to_itself(event.principal)
        THEN ALERT
- question: Is a high-privilege role being assigned to a very new account or an untrusted external account?
  context: This question focuses on identifying high-risk role assignments. Adversaries often create new accounts or use external accounts to assign privileges to. This rule checks if a high-privilege role is given to an account created within the last 72 hours or to a principal from a domain not on an approved federation list, which are strong indicators of malicious activity.
  answer_sources: AWS CloudTrail, Azure Activity Log, Windows Event ID 4624, Cloud provider IAM service endpoints, Identity Provider (IdP) authentication logs, Domain Controller security logs.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each role assignment event
      IF event.role IN high_privilege_list AND (event.principal.createDate < 72h ago OR event.principal.domain NOT IN allowlist)
      THEN ALERT
- question: Is a high-privilege role being assigned to an account that has been dormant?
  context: This question helps detect the hijacking of inactive accounts. An adversary might compromise a dormant account and then assign it privileges to fly under the radar. By tracking the last login time for all accounts, we can define 'dormancy' (e.g., no activity for 90 days) and alert whenever a dormant account is suddenly granted a powerful role.
  answer_sources: AWS CloudTrail, Azure Activity Log, Windows Event ID 4624, Cloud provider IAM service endpoints, Identity Provider (IdP) authentication logs, Domain Controller security logs.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each account
        IF last_login > 90 days ago
        THEN mark account as dormant
      FOR each role assignment event
        IF event.principal is dormant AND event.role IN high_privilege_list
        THEN ALERT
- question: Is a high-privilege role being assigned to an account whose activity pattern suggests it is dormant?
  context: This question uses time-series forecasting to more intelligently detect dormant account usage. Instead of a fixed threshold, a model like ARIMA predicts the expected login pattern for each user. An alert is triggered if a high-privilege role is assigned to a user whose recent activity is a significant negative outlier from their forecast, indicating a break from their normal behavior.
  answer_sources: AWS CloudTrail, Azure Activity Log, Windows Event ID 4624, Cloud provider IAM service endpoints, Identity Provider (IdP) authentication logs, Domain Controller security logs.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each user
        MODEL = train_arima_on_activity_log(user)
        FORECAST = MODEL.predict()
        IF actual_activity is significant_negative_outlier(FORECAST)
        THEN mark user as dormant
      FOR each role assignment to dormant user
      THEN ALERT
- question: Has any single user performed an excessive number of IAM modifications in a short time?
  context: This question aims to catch brute-force or scripted IAM activity by an adversary. A simple threshold rule can detect an unusual burst of activity, such as an attacker rapidly trying different policy combinations. An alert is triggered if a user exceeds a set number of IAM modification calls (e.g., more than 10) within a short window (e.g., 60 minutes).
  answer_sources: AWS CloudTrail, Azure Activity Log, Zeek conn.log, Windows Event ID 4624, Cloud provider IAM service endpoints, Administrator workstations, VPN and remote access gateways.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each 60-minute window
      COUNT IAM modification calls per user
      IF count > 10 for any user
      THEN ALERT
- question: Is an administrator's IAM modification activity statistically anomalous compared to their own baseline?
  context: This question provides a more tailored approach to detecting unusual activity by comparing an administrator's actions against their own historical behavior. By calculating a mean and standard deviation of activity for each hour of the day, we can alert when a user's activity exceeds their personal norm (e.g., by 3 standard deviations), indicating a potential compromise or insider threat.
  answer_sources: AWS CloudTrail, Azure Activity Log, Zeek conn.log, Windows Event ID 4624, Cloud provider IAM service endpoints, Administrator workstations, VPN and remote access gateways.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each admin
        CALCULATE hourly mean/std dev of IAM modifications from last 90 days
      FOR each hour
        IF admin.activity > (admin.mean + 3 * admin.std_dev)
        THEN ALERT
- question: Can we detect anomalous bursts of IAM activity that are not explained by normal user trends or seasonality?
  context: This question uses a more advanced time-series decomposition model to identify suspicious activity. This model separates a user's activity into trend, seasonal, and residual components. An alert is triggered when a burst of activity is detected in the residual component, meaning it's an anomaly that cannot be explained by the user's normal work patterns (e.g., time of day, day of week).
  answer_sources: AWS CloudTrail, Azure Activity Log, Zeek conn.log, Windows Event ID 4624, Cloud provider IAM service endpoints, Administrator workstations, VPN and remote access gateways.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each user
        MODEL = decompose_stl(user.activity_history)
        DETECT anomalies in model.residual
        IF anomaly_detected
        THEN ALERT
- question: Are newly created IAM roles or policies being named with terms associated with known malicious tools or actors?
  context: This question helps to identify blatant attempts by an adversary to create roles for privilege escalation. Adversaries sometimes use predictable or known-bad names for their malicious resources. By scanning the 'roleName' and 'policyName' fields in creation events against a watchlist of suspicious terms, we can catch these obvious indicators of compromise.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, Threat intelligence platform feeds.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each IAM creation event
      IF event.roleName IN known_bad_names_list OR event.policyName IN known_bad_names_list
      THEN ALERT
- question: Are newly created IAM roles or policies being named with terms that are a close misspelling or variation of malicious terms?
  context: This question aims to catch adversaries who try to evade simple name-based detection by slightly altering malicious tool or actor names. By calculating the Levenshtein distance between a new role/policy name and a threat intelligence watchlist, we can detect fuzzy matches (e.g., 'backdor_policy' instead of 'backdoor_policy') and alert on suspicious similarities.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, Threat intelligence platform feeds.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each new role/policy name
        FOR each name in watchlist
          DISTANCE = levenshtein_distance(new_name, watchlist_name)
          IF normalized_distance < 0.2
          THEN ALERT
- question: Can we classify newly created IAM role and policy names as malicious using a text classifier?
  context: This question leverages Natural Language Processing (NLP) to automate the detection of suspicious role and policy names. By training a classifier (like Naive Bayes) on thousands of known-good and known-bad examples, the model can learn to distinguish between benign names and those indicative of malicious intent, providing a scalable way to flag suspicious creations for review.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, Threat intelligence platform feeds.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      MODEL = train_text_classifier(good_names, bad_names)
      FOR each new role/policy name
        CLASSIFICATION = MODEL.predict(new_name)
        IF CLASSIFICATION is 'suspicious' or 'malicious'
        THEN ALERT
- question: Has an account been granted a specific combination of permissions known to create a privilege escalation path?
  context: This question seeks to detect privilege escalation by codifying known attack paths into detection rules. For example, in AWS, the combination of 'iam:PassRole' and 'ec2:RunInstances' can lead to privilege escalation. A SIEM rule can trigger when a policy modification results in a single principal possessing all permissions required to complete such a known path.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, Cloud Security Posture Management (CSPM) tools.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each policy modification event
        GET principal's effective permissions
        IF effective_permissions contain all_permissions_for(known_privesc_path)
        THEN ALERT
- question: Has a principal's cumulative risk score jumped to an anomalous level after a permission change?
  context: This question provides a quantitative way to assess the risk of a permission change. By assigning a risk score to each individual permission and summing them for a principal, we can establish a baseline risk profile for the environment. An alert is triggered if a policy modification causes a principal's score to jump into the 99th percentile, indicating a sudden and significant increase in their potential for impact.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, Cloud Security Posture Management (CSPM) tools.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      CALCULATE risk scores for all principals
      FOR each policy modification event
        RECALCULATE principal's risk score
        IF new_score > 99th_percentile(all_scores)
        THEN ALERT
- question: Does a policy change create a graph structure that a model recognizes as a high-risk escalation path?
  context: This question uses advanced graph-based machine learning to detect privilege escalation. By modeling the IAM environment as a graph, a Graph Neural Network (GNN) can be trained to recognize the specific sub-graph structures of known escalation paths. This allows for the detection of complex, multi-step privilege escalation opportunities as soon as they are created by a policy change.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, Cloud Security Posture Management (CSPM) tools.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      MODEL = train_gnn_on_iam_graphs(known_good_and_bad_graphs)
      FOR each policy change
        GENERATE new IAM graph
        SUBGRAPH = find_subgraph_around_change(new_graph)
        IF MODEL.predict(SUBGRAPH) is 'high-risk_escalation'
        THEN ALERT
- question: Has a non-administrative user been granted permissions to modify IAM configurations?
  context: This question enforces the principle of least privilege by monitoring for unauthorized grants of administrative power. A list of non-administrative users is maintained, and an alert is triggered any time an IAM write permission (like 'iam:PutUserPolicy' or 'Microsoft.Authorization/*/write') is granted to someone on that list, indicating a potential privilege escalation attempt.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, User and group definitions in Identity Provider (IdP).
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each permission grant event
      IF event.principal IN non_admin_list AND event.permission IN iam_write_list
      THEN ALERT
- question: Has a user been granted a permission set that significantly deviates from the norm for their job role?
  context: This question detects privilege escalation by identifying when a user's permissions diverge from their established role baseline. By calculating the Jaccard similarity between a user's new permissions and the typical set for their job role (e.g., 'Developer'), a low similarity score can indicate that an anomalous, and a possibly malicious, permission has been added.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, User and group definitions in Identity Provider (IdP).
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each job role
        BASELINE = find_common_permissions(users_in_role)
      FOR each permission grant to a user
        SIMILARITY = jaccard_similarity(user.permissions, BASELINE)
        IF SIMILARITY < 0.5
        THEN ALERT
- question: Has a permission grant caused a user to be re-classified into a higher-privilege group by a clustering algorithm?
  context: This question uses unsupervised machine learning to detect anomalous permission changes. Users are clustered based on their permission sets. An alert is triggered if a permission grant causes a user to move from a large, well-defined cluster (like 'developers') to a small, high-privilege cluster or to become an outlier, indicating their access profile has changed in a way that is abnormal for the organization.
  answer_sources: AWS CloudTrail, Azure Activity Log, Google Cloud Audit Log, Cloud provider IAM service endpoints, User and group definitions in Identity Provider (IdP).
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      CLUSTERS = dbscan(all_user_permission_vectors)
      FOR each permission grant
        OLD_CLUSTER = user.cluster
        NEW_CLUSTER = dbscan_predict(user.new_permission_vector)
        IF NEW_CLUSTER is outlier OR NEW_CLUSTER is higher_privilege
        THEN ALERT
- question: Did an account, immediately after receiving new permissions, successfully execute API calls that were previously failing with 'AccessDenied' errors?
  context: This question looks for the immediate exploitation of newly granted privileges. It correlates a permission change with subsequent successful high-impact API calls (e.g., 's3:GetObject') that were failing for that same user just before the change. This "permission granted, then used" sequence is a strong indicator of an adversary testing and then using a new privilege escalation.
  answer_sources: AWS CloudTrail, Azure Activity Log, AWS S3 access logs, Google Cloud Storage logs, Cloud provider IAM service endpoints, Cloud storage services (S3, GCS), Cloud compute and container services.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each IAM modification event
        STORE principal and timestamp
        WATCH for successful high-impact API calls from principal in next 15 mins
        IF successful_call.api had 'AccessDenied' for principal in last 24h
        THEN ALERT
- question: Did an account's rate of 'AccessDenied' errors drop significantly immediately after a policy modification?
  context: This question statistically identifies the successful acquisition of desired permissions. It monitors the rate of 'AccessDenied' errors for each principal. A significant drop in that error rate, especially when correlated with a spike in successful sensitive API calls immediately following a policy modification, suggests an adversary has successfully overcome a permission barrier.
  answer_sources: AWS CloudTrail, Azure Activity Log, AWS S3 access logs, Google Cloud Storage logs, Cloud provider IAM service endpoints, Cloud storage services (S3, GCS), Cloud compute and container services.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      MONITOR rate of 'AccessDenied' errors per principal
      FOR each policy modification event
        IF 'AccessDenied' rate drops > 3 std dev below mean
        AND sensitive_api_call rate spikes
        THEN ALERT
- question: Did an account's sequence of API calls become anomalous immediately following a permission grant?
  context: This question uses a sequence-to-sequence model to learn the normal "rhythm" of API calls for a user. A policy modification followed by a sequence of calls that the model finds difficult to reconstruct (i.e., has a high reconstruction error) is flagged as anomalous. This can detect when an attacker, after gaining new privileges, begins performing actions that are uncharacteristic for the compromised user.
  answer_sources: AWS CloudTrail, Azure Activity Log, AWS S3 access logs, Google Cloud Storage logs, Cloud provider IAM service endpoints, Cloud storage services (S3, GCS), Cloud compute and container services.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each user
        MODEL = train_lstm_autoencoder(user.api_call_sequences)
      FOR each new API call sequence after a permission grant
        RECONSTRUCTION_ERROR = MODEL.evaluate(sequence)
        IF RECONSTRUCTION_ERROR is high
        THEN ALERT