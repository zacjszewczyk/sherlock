name: T1547.013: XDG Autostart Entries
id: a8f9c1b2-d3e4-4f5a-6b7c-8d9e0f1a2b3c
description: This playbook helps investigate whether an adversary is using XDG Autostart entries for persistence or privilege escalation on Linux systems. It focuses on detecting the creation of malicious .desktop files in autostart directories (e.g., /etc/xdg/autostart/, ~/.config/autostart/). The playbook provides questions to identify autostart entries that leverage known-bad executables, suspicious or obfuscated command lines, masquerading techniques, and unauthorized modifications to system-wide autostart paths. It also covers detecting privilege escalation attempts, such as an autostart process executing privilege escalation commands, making suspicious network connections, or modifying sensitive system files. The overall goal is to identify and analyze anomalous autostart behavior that deviates from established baselines.
type: technique
related:
- TA0003: Persistence
- TA0004: Privilege Escalation
contributors:
- Zachary Szewczyk
- Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
- question: Are new or modified XDG autostart .desktop files or their referenced executables associated with known-bad hashes from threat intelligence?
  context: Adversaries often use known malware or malicious tools to establish persistence. By hashing newly created or modified .desktop files and the executables they point to, and comparing these hashes against a threat intelligence database, analysts can quickly identify the use of known malicious software. A match is a high-confidence indicator of compromise.
  answer_sources:
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Linux Auditd file monitoring rules
  - Linux endpoints (workstations and servers) with desktop environments; specifically, the contents of the /etc/xdg/autostart/ and ~/.config/autostart/ directories, and any directories specified by $XDG_CONFIG_DIRS.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH file_creation_events
      WHERE file_path MATCHES ('/etc/xdg/autostart/*.desktop', '~/.config/autostart/*.desktop')
      EXTRACT executable_path from 'Exec=' line in file_content
      CALCULATE sha256_hash_desktop = HASH(file_content)
      CALCULATE sha256_hash_executable = HASH(executable_path)
      LOOKUP sha256_hash_desktop, sha256_hash_executable IN threat_intel_database
      RETURN matches
- question: Are there any executables launched by XDG autostart entries that are unusually rare in the environment?
  context: Malware and custom adversary tools are often not widely distributed across an enterprise network, unlike legitimate software. By calculating the prevalence (the number of hosts an executable is found on) of all executables referenced in .desktop files, analysts can identify rare files. A low prevalence count, especially for an unsigned executable, is a strong indicator of a suspicious or malicious file that warrants further investigation.
  answer_sources:
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Linux Auditd file monitoring rules
  - Linux endpoints (workstations and servers) with desktop environments; specifically, the contents of the /etc/xdg/autostart/ and ~/.config/autostart/ directories, and any directories specified by $XDG_CONFIG_DIRS.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH process_creation_events OR file_inventory
      WHERE process_is_from_autostart_desktop_file
      GROUPBY executable_sha256
      CALCULATE host_count = DISTINCT_COUNT(hostname)
      FILTER host_count < 5 OR (host_count / total_hosts) < 0.01
      RETURN executable_sha256, host_count
- question: Can machine learning classify a new XDG autostart entry as malicious based on its file and executable features?
  context: This question moves beyond simple indicators to a predictive model. By training a classifier on features like file entropy, size, and executable properties (e.g., ELF header info), a model can learn the characteristics of malicious autostart entries. This allows for the detection of novel threats that may not have known-bad hashes or fit simple regex patterns, providing a more robust and proactive detection capability.
  answer_sources:
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Linux Auditd file monitoring rules
  - Linux endpoints (workstations and servers) with desktop environments; specifically, the contents of the /etc/xdg/autostart/ and ~/.config/autostart/ directories, and any directories specified by $XDG_CONFIG_DIRS.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      ON new_autostart_file_creation:
        EXTRACT features (file_entropy, file_size, executable_header_info, strings)
        INPUT features into pre-trained_classification_model
        IF model_prediction == 'malicious' AND confidence_score > 0.9
          ALERT "High-confidence malicious autostart entry detected"
- question: Does an XDG autostart entry's execution command contain patterns indicative of running scripts from temporary or world-writable directories, or use common obfuscation techniques?
  context: Adversaries frequently drop malicious scripts into temporary directories like /tmp or /dev/shm to execute their payloads. The 'Exec=' line in a .desktop file is a key place to spot this. This question aims to directly detect these common TTPs by using regular expressions to find command lines that invoke interpreters on scripts in suspicious locations or use simple obfuscation like base64 encoding.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd execve and file monitoring rules
  - Linux endpoints with desktop environments; specifically, the command line arguments of processes spawned by the desktop environment manager and the contents of .desktop files in autostart directories.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH process_creation_events
      WHERE parent_process is desktop_manager
      APPLY REGEX on command_line for patterns like '(sh|bash|python) /tmp/.*' OR 'base64 --decode'
      RETURN matching events
- question: Is the command line in an XDG autostart entry's 'Exec=' line abnormally long or complex compared to a baseline of legitimate entries?
  context: Legitimate autostart commands are typically simple and predictable. Adversaries often use complex, one-line commands or obfuscation to hide their activity, which increases the command's character length and Shannon entropy. By establishing a baseline for these metrics, analysts can flag new entries that are statistical outliers, providing a powerful way to detect obfuscated or unusual commands without relying on specific signatures.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd execve and file monitoring rules
  - Linux endpoints with desktop environments; specifically, the command line arguments of processes spawned by the desktop environment manager and the contents of .desktop files in autostart directories.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each new .desktop file 'Exec=' command:
        CALCULATE shannon_entropy and command_length
        COMPARE with pre-computed baseline (e.g., 98th percentile)
        IF entropy > baseline_entropy_threshold OR length > baseline_length_threshold
          ALERT "Anomalous autostart command complexity detected"
- question: Does an autostart command line have a high reconstruction error when processed by an NLP model trained on legitimate commands?
  context: This advanced technique treats command lines as a language. An autoencoder model trained on a vast corpus of normal commands learns their typical structure and syntax. When a malicious or heavily obfuscated command is fed to the model, it will struggle to reconstruct it, resulting in a high "reconstruction error." This method can detect novel and sophisticated obfuscation techniques that might evade regex or simple statistical analysis.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd execve and file monitoring rules
  - Linux endpoints with desktop environments; specifically, the command line arguments of processes spawned by the desktop environment manager and the contents of .desktop files in autostart directories.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each new .desktop file 'Exec=' command:
        INPUT command_string into NLP_autoencoder_model
        CALCULATE reconstruction_error
        IF reconstruction_error > anomaly_threshold (e.g., top 2%)
          ALERT "Anomalous command structure detected by NLP model"
- question: Is a new .desktop file attempting to masquerade as a legitimate application by using a known name but pointing to an incorrect or user-writable executable path?
  context: A common adversary technique is to name their malware after a legitimate application (e.g., "Chrome Update") to deceive users and analysts. This question aims to defeat this by maintaining an allow-list that maps legitimate application names to their expected, official executable paths. Any deviation, such as a "Firefox" entry pointing to an executable in a user's home directory instead of /usr/bin, is a strong signal of masquerading.
  answer_sources:
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd file monitoring rules
  - Linux endpoints with desktop environments; specifically, the metadata within .desktop files located in /etc/xdg/autostart/ and ~/.config/autostart/.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH file_creation_events WHERE file_path MATCHES '*.desktop'
      PARSE file_content to get 'Name=' and 'Exec=' values
      LOOKUP 'Name=' value in application_allow_list
      IF 'Name=' is in list AND 'Exec=' path is NOT in allowed_paths for that name
        ALERT "Potential application masquerading detected"
- question: Is a new .desktop file using a name that is a misspelling or slight variation of a known legitimate application?
  context: This is a form of masquerading known as typo-squatting. Adversaries create files with names that are visually similar to legitimate ones (e.g., "Chroem" instead of "Chrome") to fool casual inspection. By calculating the string edit distance (like Damerau-Levenshtein) between a new file's name and a dictionary of known-good names, analysts can programmatically flag these subtle misspellings for review.
  answer_sources:
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd file monitoring rules
  - Linux endpoints with desktop environments; specifically, the metadata within .desktop files located in /etc/xdg/autostart/ and ~/.config/autostart/.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each new .desktop file 'Name=' value:
        FOR each known_app_name in dictionary:
          CALCULATE distance = DamerauLevenshtein(new_name, known_app_name)
          IF 1 <= distance <= 3
            ALERT "Potential typo-squatting detected", new_name, known_app_name
- question: Does a new .desktop file appear as an outlier when its metadata is compared to clusters of known legitimate application entries?
  context: Legitimate applications from the same vendor or suite often share similar metadata patterns in their .desktop files. This question applies unsupervised machine learning (clustering) to group similar entries together based on features like their 'Name' and 'Comment' fields. A malicious entry attempting to masquerade is unlikely to fit neatly into these established clusters and will be flagged as a "noise point" or outlier, highlighting it as a high-priority anomaly.
  answer_sources:
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd file monitoring rules
  - Linux endpoints with desktop environments; specifically, the metadata within .desktop files located in /etc/xdg/autostart/ and ~/.config/autostart/.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      ON new .desktop file creation:
        EXTRACT features (TF-IDF of 'Name'/'Comment', parsed 'Exec=' path)
        INPUT features into pre-trained DBSCAN model
        IF model_classifies_as_noise_point
          ALERT "Anomalous .desktop file metadata detected via clustering"
- question: Did a process launched from an XDG autostart entry make a network connection to a known C2 server and then quickly delete its persistence file?
  context: This question looks for a classic "smash and grab" persistence pattern where malware establishes a connection to its command and control (C2) server and then removes its initial entry point (.desktop file) to cover its tracks. Correlating process creation, network connection to a malicious IP, and subsequent file deletion within a short time window (e.g., 2 minutes) creates a very high-fidelity alert for this specific behavior chain.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 3 (NetworkConnect)
  - Sysmon for Linux Event ID 23 (FileDelete)
  - Zeek conn.log
  - Zeek ssl.log
  - Zeek dns.log
  - Linux endpoints with desktop environments, focusing on process, network, and file event correlation. Network gateways and core switches where Zeek sensors monitor egress traffic.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      CORRELATE events within 120 seconds:
      1. ProcessCreate from desktop_manager (P1)
      2. NetworkConnect from P1 to IP in C2_threat_feed
      3. FileDelete where TargetFilename is the .desktop file that launched P1
      IF all three events occur for the same process
        ALERT "Suspicious autostart connect-then-delete behavior detected"
- question: Is a process launched from an autostart entry communicating over the network using a rare or previously unseen JA3/JA3S hash?
  context: JA3 and JA3S hashes are fingerprints of the way a client or server communicates during a TLS handshake. Standard applications (like Chrome, Firefox) have well-known, common fingerprints. Malware or custom adversary tools often use non-standard cryptographic libraries, resulting in unique or rare JA3/JA3S hashes. Detecting a network connection from an autostart process with a rare hash is a strong indicator that a non-standard, and therefore suspicious, application is running.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 3 (NetworkConnect)
  - Sysmon for Linux Event ID 23 (FileDelete)
  - Zeek conn.log
  - Zeek ssl.log
  - Zeek dns.log
  - Linux endpoints with desktop environments, focusing on process, network, and file event correlation. Network gateways and core switches where Zeek sensors monitor egress traffic.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH zeek_ssl_logs
      WHERE source_ip corresponds to host with autostart_process
      LOOKUP ja3_hash, ja3s_hash in enterprise_baseline_database
      IF ja3_hash is new OR prevalence < 0.1%
        ALERT "Rare JA3/JA3S hash from autostart process detected"
- question: Does the sequence of events following a user login (autostart process -> network connection -> file deletion) have a low probability according to a model of normal user activity?
  context: This question models user sessions as a sequence of states. A Hidden Markov Model (HMM) can be trained on millions of normal event sequences to learn what constitutes typical behavior. A malicious chain of events, like an autostart process immediately connecting to an external server and then deleting itself, is a sequence that would have a very low probability of occurring in the learned model of normal activity, thus flagging it as a high-confidence anomaly.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 3 (NetworkConnect)
  - Sysmon for Linux Event ID 23 (FileDelete)
  - Zeek conn.log
  - Zeek ssl.log
  - Zeek dns.log
  - Linux endpoints with desktop environments, focusing on process, network, and file event correlation. Network gateways and core switches where Zeek sensors monitor egress traffic.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR event_sequence ('AutostartProcess', 'ExternalNetworkConnection', 'FileDelete'):
        CALCULATE sequence_probability using trained HMM
        IF probability < anomaly_threshold
          ALERT "Anomalous user activity chain detected by HMM"
- question: Is a process launched from a system-wide autostart path (/etc/xdg/autostart) connecting to a known malicious IP or domain?
  context: The /etc/xdg/autostart directory is a privileged location for persistence that affects all users. A process launched from here should be a trusted system component. Any network connection from such a process to a destination on a threat intelligence feed is a critical indicator of a system-level compromise, as it implies an adversary has gained root access to plant the malicious .desktop file.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 3 (NetworkConnect)
  - Zeek conn.log
  - Zeek dns.log
  - System-wide autostart directory /etc/xdg/autostart on all Linux hosts; network egress points instrumented with Zeek sensors for traffic analysis.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH process_creation_events
      WHERE process_path contains '/etc/xdg/autostart'
      CORRELATE process_guid with network_connection_events
      LOOKUP destination_ip OR destination_domain in C2_threat_feed
      RETURN matches
- question: Is a process from a system-wide autostart path making network connections to a country or Autonomous System Number (ASN) never before seen for such processes?
  context: Legitimate system-level autostart processes typically have very predictable network behavior, connecting to a stable set of update servers or internal resources. By creating a baseline of the destination countries and ASNs they normally communicate with, analysts can detect significant deviations. A connection to a new or unusual ASN/country is a strong anomaly signal that could indicate a C2 channel or data exfiltration.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 3 (NetworkConnect)
  - Zeek conn.log
  - Zeek dns.log
  - System-wide autostart directory /etc/xdg/autostart on all Linux hosts; network egress points instrumented with Zeek sensors for traffic analysis.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH network_connections
      WHERE source_process originates from '/etc/xdg/autostart'
      GEOIP_LOOKUP destination_ip to get country
      ASN_LOOKUP destination_ip to get ASN
      IF country OR ASN not in baseline_for_system_autostart_processes
        ALERT "Anomalous network destination for system autostart process"
- question: Does the network traffic from a system-wide autostart process exhibit patterns (e.g., periodic, low-volume heartbeats) indicative of C2 communication?
  context: Command and control (C2) traffic often has distinct characteristics, such as small, regular "beacons" or "heartbeats" sent to the C2 server. A time-series anomaly detection model can be trained on normal network traffic features (like bytes sent/received) for legitimate autostart processes. The model can then monitor these processes in real-time and alert on deviations that match the profile of C2 traffic, providing a behavioral detection method.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 3 (NetworkConnect)
  - Zeek conn.log
  - Zeek dns.log
  - System-wide autostart directory /etc/xdg/autostart on all Linux hosts; network egress points instrumented with Zeek sensors for traffic analysis.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each system_autostart_process:
        COLLECT time_series_data (bytes_sent, bytes_received, duration)
        INPUT data into LSTM_autoencoder_model
        IF reconstruction_error > anomaly_threshold
          ALERT "Anomalous network traffic pattern detected for system process"
- question: Does the 'Exec=' command in a system-wide autostart file contain strings associated with privilege escalation techniques?
  context: If an adversary gains write access to /etc/xdg/autostart, they can execute commands as any user who logs into a graphical session. They may use this opportunity to run commands specifically designed to escalate privileges further, such as using `sudo` or `pkexec`, exploiting a local vulnerability, or manipulating SUID bits. This question uses regex to scan for these specific, high-risk command strings.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Linux Auditd execve rules
  - The /etc/xdg/autostart directory on all Linux hosts; specifically monitoring the command lines of processes spawned from entities within this directory.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH process_creation_events
      WHERE process_path contains '/etc/xdg/autostart'
      APPLY REGEX on command_line for patterns like 'sudo', 'pkexec', 'chmod [ug]+s', 'dirtyc0w'
      RETURN matching events
- question: Does a command line from a system-wide autostart file contain rare tokens or arguments not seen in a baseline of legitimate commands?
  context: This approach profiles the "vocabulary" of normal commands found in /etc/xdg/autostart. By calculating the rarity (Inverse Document Frequency) of each word or argument (token), analysts can flag commands that use unusual tokens. A command containing a word that has never or rarely been seen before is anomalous and could indicate a custom script or tool being used for privilege escalation.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Linux Auditd execve rules
  - The /etc/xdg/autostart directory on all Linux hosts; specifically monitoring the command lines of processes spawned from entities within this directory.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each new command_line from '/etc/xdg/autostart':
        TOKENIZE command_line
        FOR each token:
          CALCULATE IDF_score based on baseline_dictionary
          IF IDF_score is very low (token is rare)
            ALERT "Rare command line token detected in system autostart"
- question: Can a large language model (LLM) classify the command from a system-wide autostart file as malicious or indicative of privilege escalation?
  context: This question leverages the advanced pattern recognition capabilities of LLMs. By fine-tuning a model on a large dataset of benign and malicious shell commands, it can learn the subtle semantic and structural differences between them. This allows the model to classify a new command's intent, providing a powerful tool to detect novel or obfuscated privilege escalation attempts that might be missed by simpler methods.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Linux Auditd execve rules
  - The /etc/xdg/autostart directory on all Linux hosts; specifically monitoring the command lines of processes spawned from entities within this directory.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each new command_line from '/etc/xdg/autostart':
        INPUT command_line into fine_tuned_LLM
        IF model_classification is 'malicious' or 'privilege_escalation'
          ALERT "LLM classified system autostart command as malicious"
- question: Has a file in the system-wide autostart directory (/etc/xdg/autostart) been created or modified by a user other than root or by a process other than a legitimate package manager?
  context: The /etc/xdg/autostart directory is a system-level configuration path that should only be modified by the root user during software installation or system configuration. Any modification by a non-root user or a process that isn't a known package manager (like dpkg, rpm) is a high-fidelity indicator of a privilege escalation attempt, where an attacker who has gained some level of access is trying to establish root-level persistence.
  answer_sources:
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd file modification rules
  - File system audit logs for the /etc/xdg/autostart/ directory and its contents on all Linux hosts.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH file_modification_events
      WHERE file_path contains '/etc/xdg/autostart/'
      AND user is NOT 'root'
      AND process_name is NOT IN ('dpkg', 'rpm', 'yum', 'apt')
      ALERT "Unauthorized modification of system-wide autostart directory"
- question: Did a modification to the system-wide autostart directory occur at an anomalous time, such as outside of business hours or standard patching windows?
  context: Legitimate administrative activities, like software updates that modify /etc/xdg/autostart, typically occur during predictable time windows. Adversaries, however, may operate at any time. By baselining the timing of legitimate changes, analysts can flag modifications that occur at unusual times (e.g., 3 AM on a Sunday) as suspicious, even if the user and process appear legitimate, as it could indicate credential compromise.
  answer_sources:
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd file modification rules
  - File system audit logs for the /etc/xdg/autostart/ directory and its contents on all Linux hosts.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH file_modification_events
      WHERE file_path contains '/etc/xdg/autostart/'
      EXTRACT hour_of_day, day_of_week
      IF time is outside of baseline (e.g., not 9am-5pm on weekdays, not in patch window)
        ALERT "System autostart modification at anomalous time"
- question: Does a file modification event in the system-wide autostart directory have a high anomaly score from an Isolation Forest model?
  context: This question uses an unsupervised learning model to detect anomalous changes. An Isolation Forest can be trained on features of legitimate modification events (user, process, parent process, time of day). It learns the profile of normal activity and can then score new events based on how much they deviate from this profile. This allows for the detection of novel or subtle attack patterns that don't trigger specific rules.
  answer_sources:
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd file modification rules
  - File system audit logs for the /etc/xdg/autostart/ directory and its contents on all Linux hosts.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      ON file_modification in '/etc/xdg/autostart/':
        EXTRACT features (user, process, parent_process, time_of_day)
        INPUT features into trained_Isolation_Forest_model
        CALCULATE anomaly_score
        IF anomaly_score is high
          ALERT "Anomalous modification to system autostart detected by model"
- question: Did a process launched from the system-wide autostart directory write to or modify a sensitive system file like /etc/passwd or /etc/sudoers?
  context: A process originating from /etc/xdg/autostart should generally not be modifying core system configuration files. This question sets up a high-priority alert for when such a process attempts to write to critical files or protected directories (/etc, /bin, /sbin). This behavior is a strong indicator that an adversary is using their established persistence to further compromise the system, for example, by adding a new user or granting themselves sudo privileges.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd file modification rules
  - Sensitive system directories on all Linux hosts, including /etc, /bin, /sbin, /usr/bin, /usr/sbin, /boot, /root, and user profile/cron locations, correlating activity back to autostart processes.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      SEARCH process_creation from '/etc/xdg/autostart' (P1)
      CORRELATE P1 with subsequent file_write_events
      WHERE target_file_path IN ('/etc/passwd', '/etc/shadow', '/etc/sudoers')
      OR target_file_path MATCHES ('/etc/*', '/bin/*', '/sbin/*')
      ALERT "System autostart process wrote to sensitive file"
- question: Is a legitimate process launched from the system-wide autostart directory writing to a file in a location it has never written to before?
  context: Even legitimate processes have predictable behavior. By building a historical baseline of every directory that a specific autostart process normally writes to, analysts can detect behavioral changes. If a trusted process suddenly starts writing to a new, unexpected directory, it could indicate that the process has been hijacked, exploited, or is being used by an adversary as a living-off-the-land technique.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd file modification rules
  - Sensitive system directories on all Linux hosts, including /etc, /bin, /sbin, /usr/bin, /usr/sbin, /boot, /root, and user profile/cron locations, correlating activity back to autostart processes.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      FOR each file_write_event by system_autostart_process:
        EXTRACT parent_directory of target_file
        LOOKUP parent_directory in historical_baseline for that process
        IF parent_directory is not in baseline
          ALERT "Autostart process wrote to a novel directory"
- question: Does a graph-based model of system activity detect an anomalous interaction, such as a system autostart process modifying a sensitive SSH configuration file?
  context: This question represents the system as a graph of nodes (processes, files) and edges (interactions). A Graph Neural Network (GNN) can be trained on this graph to learn the patterns of normal interactions. An adversary's action, like using an autostart process to modify /etc/ssh/sshd_config, would create a new, anomalous edge in the graph. The GNN would flag this interaction as a high-confidence anomaly because it violates the learned patterns of legitimate system behavior.
  answer_sources:
  - Sysmon for Linux Event ID 1 (ProcessCreate)
  - Sysmon for Linux Event ID 11 (FileCreate)
  - Linux Auditd file modification rules
  - Sensitive system directories on all Linux hosts, including /etc, /bin, /sbin, /usr/bin, /usr/sbin, /boot, /root, and user profile/cron locations, correlating activity back to autostart processes.
  range: last 90 days
  queries:
  - technology: pseudocode
    query: |
      MODEL system activity as a graph G = (Processes, Files, Interactions)
      ON new interaction (process P from '/etc/xdg/autostart' writes to file F):
        CREATE new edge (P -> F) in graph
        INPUT edge into trained GNN model
        IF GNN flags edge as anomalous
          ALERT "Anomalous process-file interaction detected by GNN"