name: T1078.004: Cloud Accounts
id: 6e1a0b5a-4f1c-4b9d-8c1a-2e3f4d5b6c7d
description: This playbook focuses on detecting adversarial use of compromised cloud accounts (T1078.004) across multiple phases of an attack. It provides investigative questions to identify initial access via cloud accounts, such as logins from malicious IPs, impossible travel scenarios, brute-force attempts, and suspicious user agents. It also covers persistence techniques like the use of leaked credentials or the creation of new high-privilege keys. Furthermore, it addresses privilege escalation patterns, including policy modifications and role assumption, and defense evasion tactics like disabling security logs or modifying network security rules.
type: technique
related:
  - TA0001: Initial Access
  - TA0003: Persistence
  - TA0004: Privilege Escalation
  - TA0005: Defense Evasion
contributors:
  - Zachary Szewczyk
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Are there successful cloud logins from IP addresses present on a threat intelligence feed?
    context: A successful login from a source IP known to be malicious (e.g., C2 server, TOR exit node, anonymous proxy) is a high-confidence indicator of a compromised account. This check directly cross-references active threats with internal authentication activity to find evidence of initial access.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Zeek conn.log
      - Cloud provider IAM services (e.g., Azure AD, AWS IAM)
      - Network Egress/Ingress Points (e.g., Internet Gateway, VPN Concentrators)
      - Threat Intelligence Platforms
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_authentication_logs WHERE outcome = 'success' | JOIN source_ip WITH threat_intelligence_feed ON ip_address | ALERT on match
  - question: Have there been successful logins from statistically rare Autonomous System Numbers (ASNs) not associated with known partners?
    context: Adversaries often use infrastructure from uncommon or non-commercial cloud providers. Identifying logins from ASNs that are statistically rare for the organization can uncover attacker infrastructure that is not yet on a formal threat feed. This is a form of anomaly detection based on network origin.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Zeek conn.log
      - Cloud provider IAM services (e.g., Azure AD, AWS IAM)
      - Network Egress/Ingress Points (e.g., Internet Gateway, VPN Concentrators)
      - Threat Intelligence Platforms
    range: Last 30 days
    queries:
      - technology: pseudocode
        query: CALCULATE frequency of ASN for all logins over 30 days | FOR each new successful login, GET ASN | IF ASN_frequency is in bottom 5% AND ASN not in allowlist THEN ALERT
  - question: Can machine learning models identify successful logins that have a high probability of being malicious based on their features?
    context: A supervised machine learning model can learn complex patterns from historical data to identify malicious logins that simple rules might miss. By analyzing features like geolocation, ASN, time of day, and user agent together, the model can provide a risk score for each login, allowing analysts to focus on the most suspicious events.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Zeek conn.log
      - Cloud provider IAM services (e.g., Azure AD, AWS IAM)
      - Network Egress/Ingress Points (e.g., Internet Gateway, VPN Concentrators)
      - Threat Intelligence Platforms
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each new login | EXTRACT features (IP geo, ASN, time, user_agent) | INPUT features into trained_classification_model | IF model_score > 0.9 THEN ALERT
  - question: Are cloud API calls being made with User-Agent strings matching known offensive security tools or unusual scripting agents?
    context: Adversaries often use specialized tools (like PowerZure, Pacu) or generic scripting libraries (like curl, python-requests) to automate their actions. These tools leave distinct User-Agent strings in API logs. Detecting these strings, especially for users who do not normally use them, can indicate hands-on-keyboard activity by an attacker.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud API endpoints
      - Cloud Service Provider Management Consoles
      - Application and Web Server Logs
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH cloud_audit_logs | MATCH UserAgent against regex_list_of_malicious_tools | ALERT on match
  - question: Are users or service principals using User-Agent strings that deviate from their established baseline or have anomalous entropy?
    context: Every user and automated process typically uses a consistent set of User-Agent strings. A sudden deviation from this baseline, or a change in the complexity (entropy) of the string, can indicate that a different tool is being used, potentially by an adversary who has compromised the account.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud API endpoints
      - Cloud Service Provider Management Consoles
      - Application and Web Server Logs
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each user, BUILD baseline of normal UserAgents | FOR each new API call, GET UserAgent | IF UserAgent is not in user_baseline THEN ALERT
  - question: Are there sequences of API calls that deviate significantly from a user's normal, learned behavior patterns?
    context: Legitimate users and applications tend to perform API calls in predictable sequences. Sequence analysis models (like HMMs or LSTMs) can learn these patterns. An observed sequence that the model finds highly improbable suggests automated or manual activity that is out of character for the user or role, possibly indicating tool-driven adversarial actions.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud API endpoints
      - Cloud Service Provider Management Consoles
      - Application and Web Server Logs
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each user, TRAIN sequence_model on historical API call sequences | FOR each new API call sequence | IF model_anomaly_score is high THEN ALERT
  - question: Has a single source IP generated a high volume of failed logins against one account (brute-force) or many accounts (password spray)?
    context: Brute-force and password spraying attacks are common methods for gaining initial access. They are characterized by a high volume of failed authentication attempts from a small number of source IPs. This rule-based approach provides a direct method for detecting these noisy and obvious attack patterns.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Windows Event ID 4625 on ADFS servers
      - Cloud authentication endpoints
      - On-premises federation servers (e.g., ADFS)
      - VPN gateways
    range: Last 10 minutes
    queries:
      - technology: pseudocode
        query: AGGREGATE failed_logins by source_ip over 5 mins | IF count > 20 THEN ALERT (brute-force) | AGGREGATE distinct_accounts from failed_logins by source_ip over 10 mins | IF count > 15 THEN ALERT (password spray)
  - question: Is the ratio of failed-to-successful logins from a source IP, or the number of unique accounts targeted by an IP, statistically anomalous?
    context: Beyond simple thresholds, statistical analysis can identify more subtle brute-force or password spraying attempts. An IP address exhibiting a ratio of failed-to-successful logins or targeting a number of accounts that is a statistical outlier compared to all other source IPs is highly suspicious.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Windows Event ID 4625 on ADFS servers
      - Cloud authentication endpoints
      - On-premises federation servers (e.g., ADFS)
      - VPN gateways
    range: Last 60 minutes
    queries:
      - technology: pseudocode
        query: FOR each source_ip, CALCULATE failed_to_success_ratio over 1 hour | IF ratio > 99th_percentile THEN ALERT | CALCULATE unique_accounts_targeted | IF count > 3_std_dev_above_mean THEN ALERT
  - question: Does a time series model of global failed authentications show a sudden, anomalous spike?
    context: A large-scale, distributed attack might not trigger alerts based on a single source IP. By monitoring the total volume of failed logins across the entire organization over time, a time series anomaly detection model can identify sudden, statistically significant spikes that indicate a widespread attack is underway.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Windows Event ID 4625 on ADFS servers
      - Cloud authentication endpoints
      - On-premises federation servers (e.g., ADFS)
      - VPN gateways
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: MODEL global failed_login_counts per minute with time_series_model | IF new data point is flagged as an anomaly by model THEN ALERT
  - question: Has a successful login occurred from a geographic location that is physically impossible for the user to have reached since their last login?
    context: 'Impossible travel' is a classic and reliable indicator of a compromised account. By calculating the speed required to travel between two consecutive login locations, it's possible to identify scenarios where a user's credentials have been used in two places at once, which is a strong signal of unauthorized access.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Zeek conn.log
      - Cloud Identity and Access Management (IAM) Platforms
      - Geolocation IP Databases
      - Network Gateway Logs
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each successful login | GET user, timestamp, geo_location | LOOKUP previous login for user | CALCULATE distance / time_elapsed | IF speed > 1000 km/h THEN ALERT
  - question: Has a user logged in from a country, city, or ASN that is not part of their normal baseline of activity?
    context: Users typically log in from a predictable set of locations (office, home) and networks. A login from a location or ASN that is statistically rare or has never been seen for that user is a strong indicator of anomalous activity that could represent credential abuse.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Zeek conn.log
      - Cloud Identity and Access Management (IAM) Platforms
      - Geolocation IP Databases
      - Network Gateway Logs
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each user, MAINTAIN 90-day baseline of login countries/cities/ASNs | FOR each new login | IF location not in user's top 95% of locations THEN ALERT
  - question: Does a clustering model identify a user's login location as a spatial anomaly or outlier?
    context: Rather than relying on predefined rules, a clustering algorithm like DBSCAN can dynamically identify a user's normal 'clusters' of geographic activity. A new login that does not fall into any of these established clusters is flagged as a spatial outlier, providing a more flexible way to detect unusual travel.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Zeek conn.log
      - Cloud Identity and Access Management (IAM) Platforms
      - Geolocation IP Databases
      - Network Gateway Logs
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each user, CLUSTER historical login lat/long coordinates using DBSCAN | FOR each new login | IF new coordinates are flagged as noise by model THEN ALERT
  - question: Have any API calls been authenticated using credentials known to be compromised or leaked?
    context: Adversaries often use credentials found in public code repositories, paste sites, or previous breaches to maintain persistence. Actively monitoring for the use of any credential on a known-compromised watchlist is a high-fidelity detection method for an active compromise.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud API Endpoints
      - Internal Credential Watchlist Database
      - SIEM
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each API call, GET access_key_id | IF access_key_id in compromised_credential_watchlist THEN TRIGGER CRITICAL ALERT
  - question: Has a credential that has been dormant for an extended period suddenly become active?
    context: Attackers may use a compromised credential long after the initial breach. A credential that has been inactive for a long time (e.g., over 180 days) and then is suddenly used for API calls is highly suspicious. This indicates a potential 'sleeper' credential has been activated.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud API Endpoints
      - Internal Credential Watchlist Database
      - SIEM
    range: Last 180 days
    queries:
      - technology: pseudocode
        query: FOR each API call, CALCULATE time_since_last_use for that credential | IF time_since_last_use > 99th_percentile for that credential THEN ALERT
  - question: Is a machine learning model flagging credential usage as malicious based on patterns learned from known-compromised keys?
    context: If a credential is known to be compromised, its activity provides a perfect training example of 'malicious behavior'. A classification model can be trained on this data to learn the patterns of malicious API usage and then predict if other, previously unknown credentials are being used in a similarly malicious way.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud API Endpoints
      - Internal Credential Watchlist Database
      - SIEM
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: TRAIN classifier on features of API calls from known-compromised credentials | SCORE all API calls from other credentials using the model | ALERT on high probability scores
  - question: Has a new programmatic credential been created with high-privilege permissions, a suspicious name, or an overly long expiration?
    context: After gaining access, an adversary will often create new credentials for persistence. These 'backdoor' credentials may have overly permissive roles, suspicious names (e.g., 'bkup', 'temp'), or no expiration date. Monitoring for these attributes helps detect the creation of malicious persistence mechanisms.
    answer_sources:
      - AWS CloudTrail Logs (CreateAccessKey, CreateServicePrincipal)
      - Azure Monitor Audit Logs (Add-AzureADApplicationPasswordCredential)
      - Cloud Identity and Access Management (IAM) Platforms
      - Change Management Systems (e.g., ServiceNow)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: ON credential_creation_event | IF (permissions grant admin) OR (name matches suspicious_regex) AND (no approved change ticket) THEN ALERT
  - question: Was a new credential created with a statistically unusual number of permissions or a rare role?
    context: Rather than using a static list of 'bad' permissions, this approach profiles the normal creation of credentials. If a new key or principal is created with a number of permissions or a role that is a statistical outlier compared to what is normally created in the organization, it could be a sign of an adversary creating a powerful backdoor.
    answer_sources:
      - AWS CloudTrail Logs (CreateAccessKey, CreateServicePrincipal)
      - Azure Monitor Audit Logs (Add-AzureADApplicationPasswordCredential)
      - Cloud Identity and Access Management (IAM) Platforms
      - Change Management Systems (e.g., ServiceNow)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: PROFILE average permission counts and role rarity for new credentials | ON credential_creation_event | IF permission_count > 3_std_dev_above_mean OR role is statistically rare THEN ALERT
  - question: Does a graph-based model detect the creation of a new credential as a high-risk structural change to the identity-permission graph?
    context: An organization's identity and permissions can be viewed as a graph. A graph-based anomaly detection model can learn the normal structure of this graph. When an adversary adds a new credential with specific permissions, it may create a new, high-risk path to critical resources. The model can detect this structural change as an anomaly.
    answer_sources:
      - AWS CloudTrail Logs (CreateAccessKey, CreateServicePrincipal)
      - Azure Monitor Audit Logs (Add-AzureADApplicationPasswordCredential)
      - Cloud Identity and Access Management (IAM) Platforms
      - Change Management Systems (e.g., ServiceNow)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: MODEL principals and permissions as a graph | ON new_credential_creation (new node/edges) | IF graph_model flags the addition as a high-risk structural anomaly THEN ALERT
  - question: Has an account that has been dormant for over 90 days suddenly been used?
    context: Dormant accounts (e.g., from former employees or unused service accounts) are prime targets for adversaries, as their use is less likely to be noticed. An authentication from an account that has been inactive for an extended period is a strong indicator of potential compromise, especially if other factors like a new source IP are present.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Windows Event ID 4624
      - Cloud Identity and Access Management (IAM) Platforms
      - Asset and Identity Inventory Databases
      - Domain Controllers
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR every authentication | LOOKUP last_login timestamp for the principal | IF time_since_last_login > 90 days THEN ALERT | IF source_ip is also new THEN ESCALATE
  - question: Has an account authenticated after a period of inactivity that is statistically anomalous for that specific account?
    context: A fixed 90-day threshold for dormancy may not be appropriate for all accounts. A more tailored approach is to baseline the normal authentication frequency for each individual account. An authentication that occurs after a period of inactivity that is a statistical outlier (e.g., >3 standard deviations from the mean) for that specific user is a more precise indicator of anomalous activity.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Windows Event ID 4624
      - Cloud Identity and Access Management (IAM) Platforms
      - Asset and Identity Inventory Databases
      - Domain Controllers
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each principal, CALCULATE mean and std_dev of time between authentications | FOR each new authentication | IF time_since_last_login > (mean + 3*std_dev) THEN ALERT
  - question: Did a time series model forecasting a specific user's login activity predict a near-zero probability of a login at the time one occurred?
    context: This is the most dynamic method for detecting dormant account usage. A time series forecasting model can learn the unique rhythm of each user's activity, including periods of inactivity. If a login occurs during a time when the model confidently predicted no activity, it represents a strong anomaly that warrants investigation.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs
      - Windows Event ID 4624
      - Cloud Identity and Access Management (IAM) Platforms
      - Asset and Identity Inventory Databases
      - Domain Controllers
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each user, FORECAST login activity with a time_series_model | IF a login occurs when model_predicted_probability was near zero THEN ALERT
  - question: Have the identity federation settings been modified without authorization?
    context: A sophisticated adversary may attempt to establish persistence by adding their own malicious Identity Provider (IdP) or modifying a trust relationship. This would allow them to bypass normal authentication controls. Any change to federation settings is an extremely high-risk event that should be treated as a critical incident until proven benign.
    answer_sources:
      - AWS CloudTrail Logs (CreateSAMLProvider, UpdateSAMLProvider)
      - Azure Monitor Audit Logs (Set-MsolDomainFederationSettings)
      - Cloud Federation and Single Sign-On (SSO) configuration pages
      - On-premises Active Directory Federation Services (ADFS) servers
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: CREATE non-overridable alert for API calls like 'UpdateSAMLProvider', 'Set-MsolDomainFederationSettings' | TRIGGER IMMEDIATE INCIDENT RESPONSE
  - question: Has a periodic check of the federation configuration detected an unexpected change against the last known-good state?
    context: Since legitimate changes to federation settings are extremely rare, any change is a statistical anomaly. By periodically snapshotting the configuration and comparing it to a known-good baseline, any modification (which has a zero expected frequency) can be immediately detected as a high-confidence indicator of potential compromise.
    answer_sources:
      - AWS CloudTrail Logs (CreateSAMLProvider, UpdateSAMLProvider)
      - Azure Monitor Audit Logs (Set-MsolDomainFederationSettings)
      - Cloud Federation and Single Sign-On (SSO) configuration pages
      - On-premises Active Directory Federation Services (ADFS) servers
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: PERIODICALLY query federation config via API | DIFF against known-good state | IF any change is detected THEN ALERT
  - question: Was a modification to federation settings made by a principal whose behavior does not match the established profile for administrators?
    context: As a secondary control to rule-based alerts, behavioral modeling can add context. If a federation setting is changed by a user or service principal whose activity (source IP, time of day, preceding actions) does not align with the learned behavior of a legitimate administrator, the risk associated with the event is significantly higher.
    answer_sources:
      - AWS CloudTrail Logs (CreateSAMLProvider, UpdateSAMLProvider)
      - Azure Monitor Audit Logs (Set-MsolDomainFederationSettings)
      - Cloud Federation and Single Sign-On (SSO) configuration pages
      - On-premises Active Directory Federation Services (ADFS) servers
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: ON federation_modification_event | CHECK if actor's behavior (IP, time, etc.) matches 'admin_behavior_profile' | IF no match THEN ESCALATE ALERT
  - question: Was a permission-modifying API call executed using a suspicious User-Agent string?
    context: An adversary attempting to escalate privileges will often use automated tools or scripts. When an API call that modifies permissions (e.g., adding a user to a group) is performed with a User-Agent associated with a hacking tool or generic script, it is a strong indicator of malicious privilege escalation activity.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud Identity and Access Management (IAM) Platforms
      - Cloud API Gateways
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: SEARCH for API calls on a watchlist of privilege-modifying actions | IF User-Agent matches list of suspicious tool signatures THEN ALERT
  - question: Did a user make a privilege-modifying API call using a User-Agent that is statistically rare for their normal sensitive operations?
    context: Legitimate administrators typically use a consistent set of tools (e.g., the web console, a specific CLI) for sensitive tasks. If a user who always uses the web console to manage permissions suddenly makes a change via a scripting library like 'Boto3', this deviation from their baseline behavior for sensitive actions is highly suspicious.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud Identity and Access Management (IAM) Platforms
      - Cloud API Gateways
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: ON privilege-modifying API call | CHECK if User-Agent is statistically rare for that specific user's sensitive operations | IF true THEN ALERT
  - question: Does a machine learning model classify a permission-modifying API call as part of a likely privilege escalation chain?
    context: A classification model can be trained to recognize the characteristics of a privilege escalation attempt. By analyzing features like the API call name, User-Agent, source IP, and the identity's role, the model can assign a risk score. A high score for a permission-modifying call suggests it is part of a malicious sequence.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud Identity and Access Management (IAM) Platforms
      - Cloud API Gateways
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each API call | INPUT features (API_name, User-Agent, IP, role) into trained_privesc_model | IF model_score is high for a permission-modifying call THEN ALERT
  - question: Has a sequence of API calls matching a known IAM privilege escalation exploit pattern been observed?
    context: Many cloud privilege escalation techniques involve a specific, ordered sequence of API calls. By defining stateful rules that look for these exact sequences (e.g., listing policies, creating a new version, and setting it as default) from a single identity in a short time, you can detect the execution of a known exploit path with high confidence.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud Identity and Access Management (IAM) Platforms
    range: Last 15 minutes
    queries:
      - technology: pseudocode
        query: DETECT sequence 'iam:ListAttachedRolePolicies' -> 'iam:ListPolicyVersions' -> 'iam:CreatePolicyVersion' -> 'iam:SetDefaultPolicyVersion' from same identity within 15 mins | IF sequence completes THEN ALERT
  - question: Has a user executed a sequence of API calls with a very low joint probability based on their historical behavior?
    context: This is a more general form of sequence detection. By modeling the normal transition probabilities between API calls for each user, the system can identify sequences that are statistically improbable. An adversary exploring the environment or exploiting a misconfiguration is likely to execute a chain of commands that is highly unusual for the compromised user.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud Identity and Access Management (IAM) Platforms
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each user, CALCULATE transition probabilities between API calls | FOR a new sequence of calls, CALCULATE the joint probability | IF probability is anomalously low THEN ALERT
  - question: Does a sequence-aware model like an LSTM autoencoder flag an observed API call sequence as anomalous?
    context: An LSTM autoencoder can learn the deep patterns of normal API call sequences for a user or role. When presented with a new sequence, it attempts to reconstruct it. If the reconstruction error is high, it means the model has never seen anything like this sequence, indicating it is a significant anomaly that could be part of an exploit chain.
    answer_sources:
      - AWS CloudTrail Logs
      - Azure Monitor Audit Logs
      - Cloud Identity and Access Management (IAM) Platforms
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: TRAIN LSTM autoencoder on legitimate API sequences | FOR new observed sequence, calculate reconstruction_error | IF error is high THEN ALERT
  - question: Has an IAM policy or role been modified to include high-risk permissions like wildcards or sensitive actions?
    context: A common privilege escalation technique is to modify an existing policy to grant excessive permissions. This can be detected by parsing the policy document in the modification event and searching for high-risk patterns like `Action:*` on a resource or the inclusion of sensitive permissions like `iam:PassRole` or `sts:AssumeRole`.
    answer_sources:
      - AWS CloudTrail Logs (CreatePolicyVersion, PutRolePolicy)
      - Azure Monitor Audit Logs (Update-MgPolicy)
      - Cloud Identity and Access Management (IAM) Platforms
      - Configuration Management Database (CMDB)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: ON policy_modification_event | PARSE the new policy document | SEARCH for regex patterns like '\"Action\":\"*\"' or '\"sts:AssumeRole\"' | IF match THEN ALERT
  - question: Did a policy modification result in a significant increase in the policy's calculated 'privilege score'?
    context: Rather than relying on specific patterns, every IAM policy can be scored based on the risk of the permissions it contains. When a policy is modified, the before-and-after scores can be compared. A change that results in a statistically significant jump in the privilege score indicates a major escalation of permissions.
    answer_sources:
      - AWS CloudTrail Logs (CreatePolicyVersion, PutRolePolicy)
      - Azure Monitor Audit Logs (Update-MgPolicy)
      - Cloud Identity and Access Management (IAM) Platforms
      - Configuration Management Database (CMDB)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: ON policy_modification_event | CALCULATE privilege_score of old and new policy | IF (new_score - old_score) > risk_threshold THEN ALERT
  - question: Did a Natural Language Processing (NLP) model classify a modified policy as transitioning from 'safe' to 'risky'?
    context: This advanced technique uses an NLP model trained on thousands of policy documents to understand the semantic risk of a policy. When a policy is changed, the new version is passed to the model. If the model's classification changes from 'safe' to 'risky', it indicates a meaningful and potentially malicious increase in permissions.
    answer_sources:
      - AWS CloudTrail Logs (CreatePolicyVersion, PutRolePolicy)
      - Azure Monitor Audit Logs (Update-MgPolicy)
      - Cloud Identity and Access Management (IAM) Platforms
      - Configuration Management Database (CMDB)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: ON policy_modification_event | CLASSIFY old_policy and new_policy with NLP model | IF old_class is 'safe' and new_class is 'risky' THEN ALERT
  - question: Has an identity assumed an IAM role for the first time, and was it immediately followed by sensitive activity?
    context: Adversaries often escalate privileges by assuming a role with greater permissions. The first time a user or service assumes a particular role is inherently suspicious. If this 'first-time' role assumption is immediately followed by high-risk actions like accessing sensitive data or creating credentials, it strongly suggests privilege abuse.
    answer_sources:
      - AWS CloudTrail Logs (AssumeRole, and subsequent calls)
      - Azure Monitor Audit Logs (RoleAssignmentSucceeded)
      - Cloud Identity and Access Management (IAM) Platforms
      - Data stores containing sensitive information (e.g., S3 buckets, databases)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: MAINTAIN baseline of (identity, assumed_role) pairs | ON a new (identity, assumed_role) event, ALERT | IF followed by sensitive action within 5 mins, ESCALATE
  - question: Has an identity assumed a role that is statistically rare for that identity or for the organization as a whole?
    context: The risk of a role assumption can be weighted by its rarity. A 'first-time' role assumption is a zero-frequency event for that user and is therefore highly anomalous. The risk is even greater if the role itself is rarely used by anyone in the organization, as it may be a privileged, special-purpose role.
    answer_sources:
      - AWS CloudTrail Logs (AssumeRole, and subsequent calls)
      - Azure Monitor Audit Logs (RoleAssignmentSucceeded)
      - Cloud Identity and Access Management (IAM) Platforms
      - Data stores containing sensitive information (e.g., S3 buckets, databases)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: ON AssumeRole event | CHECK if (identity, role) pair is new | IF new, WEIGHT risk by the overall rarity of the assumed role | ALERT if risk is high
  - question: Does a link prediction model flag a new 'role assumption' as a highly unlikely event?
    context: The relationships between users and the roles they assume can be modeled as a graph. A link prediction model can learn which new connections (a user assuming a new role) are likely to form under normal circumstances. A successful role assumption that the model predicted was highly unlikely could represent an adversary exploiting an unintended privilege path.
    answer_sources:
      - AWS CloudTrail Logs (AssumeRole, and subsequent calls)
      - Azure Monitor Audit Logs (RoleAssignmentSucceeded)
      - Cloud Identity and Access Management (IAM) Platforms
      - Data stores containing sensitive information (e.g., S3 buckets, databases)
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: MODEL identity-role relationships in a graph | USE link prediction model to score likelihood of new 'AssumeRole' events | IF a successful assumption has a very low likelihood score THEN ALERT
  - question: Has an API call been made to stop, delete, or modify a critical security logging or monitoring service?
    context: A common defense evasion tactic is to disable security tools to cover tracks. Any API call that attempts to disable a service like AWS CloudTrail, GuardDuty, or Azure Sentinel is a critical red flag and should trigger an immediate incident response, as it indicates a deliberate attempt to evade detection.
    answer_sources:
      - AWS CloudTrail Logs (StopLogging, DeleteTrail, DeleteDetector)
      - Azure Monitor Audit Logs (delete on microsoft.security/automations)
      - Cloud Security Service configuration pages (e.g., CloudTrail, GuardDuty, Sentinel)
      - Centralized Log Aggregation Platform
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: CREATE non-overridable, critical alert for API calls like 'StopLogging', 'DeleteTrail', 'UpdateDetector' with 'Enable: false' | TRIGGER IMMEDIATE INCIDENT RESPONSE
  - question: Has a security-disabling API call occurred, which is a major statistical anomaly?
    context: Legitimate modifications to security services are extremely rare and should only occur during sanctioned change windows. Therefore, the expected frequency of these API calls is effectively zero. Any occurrence of such a call is a major statistical anomaly that constitutes a high-confidence alert.
    answer_sources:
      - AWS CloudTrail Logs (StopLogging, DeleteTrail, DeleteDetector)
      - Azure Monitor Audit Logs (delete on microsoft.security/automations)
      - Cloud Security Service configuration pages (e.g., CloudTrail, GuardDuty, Sentinel)
      - Centralized Log Aggregation Platform
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: MONITOR count of security-disabling API calls | IF count > 0 THEN ALERT
  - question: Was a security-disabling API call made by a principal whose behavior does not match the 'IT Security Admin' profile?
    context: As a contextual check, if a security service is disabled, the system can verify if the action was performed by a known administrator acting in a typical manner. If the call comes from an unexpected user or from a source IP/time of day that doesn't match the admin's normal behavior, it greatly increases the likelihood of malicious activity.
    answer_sources:
      - AWS CloudTrail Logs (StopLogging, DeleteTrail, DeleteDetector)
      - Azure Monitor Audit Logs (delete on microsoft.security/automations)
      - Cloud Security Service configuration pages (e.g., CloudTrail, GuardDuty, Sentinel)
      - Centralized Log Aggregation Platform
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: ON security-disabling_API_call | CHECK if actor's behavior matches 'IT_Security_Admin_profile' | IF no match THEN ESCALATE ALERT
  - question: Has a network security rule been modified to allow traffic from an overly broad source (e.g., 0.0.0.0/0) or to all ports?
    context: To exfiltrate data or establish C2 channels, an adversary may weaken firewall rules. Opening network security groups to the entire internet ('0.0.0.0/0') or to all ports is a common defense evasion tactic that creates a significant security risk. These changes should be alerted on unless they are part of a documented, approved process.
    answer_sources:
      - AWS CloudTrail Logs (AuthorizeSecurityGroupIngress, ModifySecurityGroupRules)
      - Azure Monitor Audit Logs (Microsoft.Network/networkSecurityGroups/write)
      - Zeek conn.log
      - Virtual Private Cloud (VPC) and Virtual Network (VNet) configurations
      - Network Security Group and Security Group configurations
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: ON network_config_change_event | PARSE request parameters | IF CidrIp is '0.0.0.0/0' or port_range is '1-65535' AND no approved change_ticket THEN ALERT
  - question: Has a network security rule change introduced a CIDR block or port range that is a statistical outlier in its breadth?
    context: This analytical approach flags risky rule changes without hardcoded values. It analyzes the distribution of network prefixes and port ranges in all rule changes. A change that introduces a very large network (small prefix length) or a very wide port range that is in the top/bottom percentile of all changes would be flagged as a statistical anomaly for review.
    answer_sources:
      - AWS CloudTrail Logs (AuthorizeSecurityGroupIngress, ModifySecurityGroupRules)
      - Azure Monitor Audit Logs (Microsoft.Network/networkSecurityGroups/write)
      - Zeek conn.log
      - Virtual Private Cloud (VPC) and Virtual Network (VNet) configurations
      - Network Security Group and Security Group configurations
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: ANALYZE distribution of CIDR prefix lengths and port ranges in rule changes | IF a new change has a prefix in the bottom 5th percentile OR port range in the top 5th percentile THEN ALERT
  - question: Does a classification model flag a new or modified network security rule as 'non-compliant' or 'risky'?
    context: A machine learning model can be trained on your organization's security policies to automatically classify network rules as 'compliant' or 'risky'. When a rule is changed, it can be passed to the model in real-time. If a rule transitions from 'compliant' to 'risky', it can trigger an alert for a potential policy violation or malicious change.
    answer_sources:
      - AWS CloudTrail Logs (AuthorizeSecurityGroupIngress, ModifySecurityGroupRules)
      - Azure Monitor Audit Logs (Microsoft.Network/networkSecurityGroups/write)
      - Zeek conn.log
      - Virtual Private Cloud (VPC) and Virtual Network (VNet) configurations
      - Network Security Group and Security Group configurations
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: TRAIN classifier on security rules labeled 'compliant' or 'risky' | ON rule modification, classify the new configuration | IF new classification is 'risky' THEN ALERT
  - question: Has an action been taken to delete or alter log data, such as deleting a log bucket or clearing an event log?
    context: After performing malicious actions, adversaries will often try to cover their tracks by deleting the evidence. Any action that deletes or modifies a resource known to store logs (like an S3 bucket or log stream) is a critical indicator of defense evasion and must be investigated immediately.
    answer_sources:
      - AWS CloudTrail Logs (DeleteBucket, PutBucketLifecycleConfiguration)
      - Windows Event ID 104 (Log file was cleared)
      - Centralized Log Storage (e.g., S3 Buckets, Azure Storage Accounts)
      - CloudTrail/Log Analytics configuration
      - Windows Event Forwarding servers
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: CREATE critical alert FOR destructive API calls (e.g. s3:DeleteObject) on resources tagged as 'log-archive' | ENSURE logs are replicated to an immutable account
  - question: Has a time series model detected an anomalous and sustained drop in log volume from a key source?
    context: An adversary might find a subtle way to stop logging that doesn't trigger a direct API alert. By monitoring the volume of logs being ingested over time, a time series model can detect a sudden, unexplained drop that deviates from the forecast. This could indicate that a log source has been disabled or tampered with.
    answer_sources:
      - AWS CloudTrail Logs (DeleteBucket, PutBucketLifecycleConfiguration)
      - Windows Event ID 104 (Log file was cleared)
      - Centralized Log Storage (e.g., S3 Buckets, Azure Storage Accounts)
      - CloudTrail/Log Analytics configuration
      - Windows Event Forwarding servers
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: MODEL log ingestion volume per source with a time series model | ALERT on any sustained drop in volume that deviates from the forecast
  - question: Has a sequence analysis model detected a pattern of suspicious activity followed by a log deletion action?
    context: A log deletion event is much more significant when it is preceded by other suspicious activity. A sequence analysis model can be trained to detect these multi-stage attack patterns, such as 'Anomalous Login -> Data Access -> DeleteBucket'. Alerting on the full sequence provides crucial context that an adversary is actively trying to cover their tracks.
    answer_sources:
      - AWS CloudTrail Logs (DeleteBucket, PutBucketLifecycleConfiguration)
      - Windows Event ID 104 (Log file was cleared)
      - Centralized Log Storage (e.g., S3 Buckets, Azure Storage Accounts)
      - CloudTrail/Log Analytics configuration
      - Windows Event Forwarding servers
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: USE a sequence model to detect patterns like 'Anomalous Activity -> Log Deletion Action' | ALERT on the full sequence match
  - question: Has a successful interactive login to a privileged account occurred without Multi-Factor Authentication (MFA)?
    context: MFA is a critical control for privileged accounts. A successful login to an administrative account without an MFA claim present in the logs is a major security failure and a significant indicator of compromise. This could be due to a misconfiguration or an attack that bypasses MFA, such as session token theft.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs (ConsoleLogin event)
      - Cloud Identity and Access Management (IAM) Platforms
      - Single Sign-On (SSO) provider logs
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR successful interactive logins to privileged accounts | PARSE event for MFA claim | IF (mfaAuthenticated: false) or (MFAUsed: No) THEN GENERATE HIGH SEVERITY ALERT
  - question: Has the percentage of non-MFA logins for a privileged user deviated from a 100% baseline?
    context: For any user enrolled in MFA, especially a privileged one, the percentage of logins that use MFA should be 100%. Any successful login that does not use MFA is a deviation from this baseline and a statistical anomaly that requires immediate investigation to rule out a configuration error or an active attack.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs (ConsoleLogin event)
      - Cloud Identity and Access Management (IAM) Platforms
      - Single Sign-On (SSO) provider logs
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: FOR each privileged user, MONITOR the percentage of logins with MFA | IF percentage drops below 100% THEN ALERT
  - question: Did a machine learning model assign a high risk score to a successful login session that lacked MFA?
    context: A machine learning model can evaluate the risk of a login session based on a combination of factors. The absence of MFA on a successful login would be a very strong feature indicating high risk. The model can use this, along with other features like IP reputation and location, to flag the session as potentially illegitimate even if it was successful.
    answer_sources:
      - Azure AD Sign-in Logs
      - AWS CloudTrail Logs (ConsoleLogin event)
      - Cloud Identity and Access Management (IAM) Platforms
      - Single Sign-On (SSO) provider logs
    range: Last 90 days
    queries:
      - technology: pseudocode
        query: TRAIN model to predict login legitimacy | USE absence of MFA as a strong negative feature | ALERT if model assigns a high risk score to a successful login session