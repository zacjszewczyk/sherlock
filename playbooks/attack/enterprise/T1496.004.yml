name: T1496.004: Cloud Service Hijacking
id: c4a1b8e0-3d5f-4f9a-8e7c-6b5d4a3c2b1a
description: This playbook helps determine if an adversary is causing negative impact by hijacking cloud services. It focuses on detecting anomalies in network traffic and authentication patterns that indicate compromised API keys or user accounts are being used for malicious purposes. These purposes can include sending spam, abusing computational resources, or exfiltrating data. Detections include identifying outbound requests with compromised keys or to malicious destinations, API call sequences matching abuse tool patterns, dramatic increases in a host's outbound data or API calls compared to its own baseline, anomalous access characteristics for a user or API key (such as impossible travel or proxy usage), and identifying hosts whose data transfer volume is an outlier compared to its peer group.
type: technique
related:
- TA0040: Impact
contributors:
- Zachary Szewczyk
- Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
- question: Are outbound network requests containing known-compromised API keys or destined for known malicious IPs or domains associated with cloud service hijacking?
  context: This question aims to detect the direct use of compromised credentials or communication with known adversary infrastructure. By joining network logs (HTTP, DNS, connection) and comparing them against threat intelligence feeds for both API keys and destination indicators, an analyst can quickly identify high-confidence signs of an ongoing cloud service hijack.
  answer_sources:
  - Zeek conn.log
  - Zeek dns.log
  - Zeek http.log
  - Network egress points (e.g., firewalls, proxies)
  - Internet gateway
  - API gateways
  range: last 90 days
  queries:
  - technology: pseudocode
    query: JOIN http_logs ON uid WITH conn_logs, dns_logs | SEARCH (destination_ip IN threat_feed_ips OR destination_domain IN threat_feed_domains) OR (http_uri CONTAINS known_compromised_api_key OR http_headers CONTAINS known_compromised_api_key OR http_body CONTAINS known_compromised_api_key)
- question: Are API keys observed in outbound traffic exhibiting unusually low entropy, potentially indicating weak or tool-generated keys used in hijacking attempts?
  context: This question seeks to identify weak or predictable API keys that might be used by adversary tools. Legitimate, programmatically generated keys typically have high entropy (randomness). By calculating the Shannon entropy for observed keys and comparing it to a baseline of known good keys, analysts can flag those with suspiciously low randomness, which could be an indicator of a brute-force attempt or the use of a non-standard, malicious client.
  answer_sources:
  - Zeek http.log
  - Network egress points (e.g., firewalls, proxies)
  - Internet gateway
  - API gateways
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM http_logs | PARSE api_key FROM http_traffic | CALCULATE shannon_entropy(api_key) | ALERT WHERE entropy < baseline_10th_percentile
- question: Do new API sessions exhibit characteristics (e.g., user-agent, URI structure, data volume) that a machine learning model, trained on past incidents, identifies as having a high probability of being a hijacking attempt?
  context: This question leverages a machine learning model to score API sessions based on a combination of features. Unlike simple rules, a model can learn complex, subtle patterns from historical data (both malicious and benign) to identify novel hijacking attempts. Features like the request method, user-agent, URI path, data volume, and destination ASN are used to assign a 'hijacking probability' score, allowing for the detection of activity that might not trigger specific symbolic or statistical rules.
  answer_sources:
  - Zeek conn.log
  - Zeek http.log
  - Network egress points (e.g., firewalls, proxies)
  - Internet gateway
  - API gateways
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM http_logs, conn_logs | EXTRACT_FEATURES (method, user_agent, uri, resp_bytes, dest_asn) | APPLY classification_model | ALERT WHERE hijacking_probability > threshold
- question: Is a single source IP address making an excessive number of API calls to a specific cloud service endpoint in a short time, matching patterns of resource abuse?
  context: This question aims to detect brute-force or automated resource abuse, a common tactic in cloud hijacking. Adversary tools often make a high-frequency burst of similar requests from a single source. By creating a stateful signature that counts API calls per source IP to a specific URI within a small time window (e.g., >100 requests in 5 minutes), analysts can identify this type of automated, scripted behavior.
  answer_sources:
  - Zeek http.log
  - Zeek conn.log
  - Cloud application gateways
  - API gateways
  - outbound web proxies
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM http_logs | GROUPBY source_ip, destination_uri | COUNT requests IN 5_minute_window | ALERT WHERE request_count > 100
- question: Is a source IP exhibiting an abnormally low inter-request time (time between API calls) to a cloud service endpoint, suggesting automated activity rather than human interaction?
  context: This question provides a statistical method for identifying automated abuse. Human-driven or legitimate application traffic has a certain rhythm, while malicious scripts often operate as fast as possible. By calculating the time between consecutive requests from a single IP to an endpoint and comparing it to a historical baseline, analysts can flag sources whose request frequency is a statistical outlier (e.g., in the bottom 5th percentile), indicating high-speed, non-human interaction.
  answer_sources:
  - Zeek http.log
  - Cloud application gateways
  - API gateways
  - outbound web proxies
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM http_logs | GROUPBY source_ip, destination_endpoint | CALCULATE time_delta_between_requests | ALERT WHERE time_delta < baseline_5th_percentile
- question: Are API call sequences from a session anomalous when compared to a machine learning model trained on legitimate user and application workflows?
  context: This question uses sequence analysis to detect deviations from normal behavior. Legitimate interactions with a cloud service follow predictable workflows (e.g., login, list resources, access resource). Adversary tools may use API calls in an unusual order or combination. A Recurrent Neural Network (RNN) or similar model can learn the "grammar" of normal API sequences and flag sessions that represent a significant deviation, indicating potential tool-based abuse.
  answer_sources:
  - Zeek http.log
  - Cloud application gateways
  - API gateways
  - outbound web proxies
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM http_logs | CREATE api_call_sequences_per_session | APPLY rnn_anomaly_detection_model | ALERT WHERE sequence_is_anomalous
- question: Is an internal host sending emails to an unusually high number of unique recipient domains, indicating a compromised account being used for a spam campaign?
  context: This is a very specific indicator of a common abuse pattern for hijacked cloud email services like AWS SES. A compromised account is often used to send spam or phishing emails at scale. Monitoring SMTP logs for a single source sending emails to a large number of distinct domains (e.g., >50 in an hour) is a simple but highly effective rule for detecting this type of abuse.
  answer_sources:
  - Zeek smtp.log
  - Mail gateways
  - servers hosting cloud service SDKs
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM smtp_logs | GROUPBY source_ip IN 1_hour_window | COUNT distinct recipient_domains | ALERT WHERE distinct_domain_count > 50
- question: Has an internal host's volume of outbound data to known cloud service IP ranges significantly increased compared to its own historical baseline?
  context: This question looks for changes in an individual host's behavior over time. A compromised host might be used for data exfiltration, crypto-mining communication, or other resource-intensive abuse, leading to a spike in traffic. By calculating a moving average and standard deviation for each host's hourly traffic to cloud services, analysts can use statistical methods (e.g., z-score) to detect when a host's behavior deviates significantly from its own established norm.
  answer_sources:
  - Zeek conn.log
  - Network egress points
  - servers hosting cloud service SDKs
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM conn_logs | AGGREGATE outbound_bytes per hour per host to cloud_ips | CALCULATE 30-day_moving_average and stdev | ALERT WHERE current_hour_bytes > (moving_average + 3 * stdev)
- question: Is the total API request volume for a critical cloud service anomalous when compared to a time-series forecasting model?
  context: This question analyzes the overall health of a cloud service's usage rather than individual hosts. A widespread hijacking campaign could cause a significant, unexpected spike in total API calls. A time-series model (like SARIMA or Prophet) can learn the normal daily, weekly, and seasonal patterns of API usage and predict the expected volume. An alert is generated when the actual observed volume significantly deviates from the prediction, indicating a potential service-wide issue.
  answer_sources:
  - Zeek http.log
  - Network egress points
  - servers hosting cloud service SDKs
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM http_logs | AGGREGATE api_requests_per_hour | APPLY time_series_forecasting_model | CALCULATE residual (observed - predicted) | ALERT WHERE standardized_residual > threshold
- question: Is a user account or API key being used to access a cloud service from a source IP associated with known malicious infrastructure, TOR exit nodes, or anonymous proxies?
  context: This question seeks to identify access attempts from inherently suspicious locations. Adversaries often use anonymizing services or previously compromised infrastructure to hide their true origin. By correlating the source IP of every cloud service authentication event against a threat intelligence feed of known bad IPs, analysts can generate high-severity alerts for logins that are almost certainly illegitimate.
  answer_sources:
  - Zeek http.log
  - Zeek conn.log
  - Windows Event ID 4624
  - Authentication servers (e.g., Active Directory)
  - VPN concentrators
  - Remote Desktop Gateways
  - Cloud IAM infrastructure
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM authentication_logs | GET source_ip | LOOKUP source_ip IN (threat_feed_ips, tor_nodes, proxy_list) | ALERT on match
- question: Is a user account logging into a cloud service from a location (Country, ASN) or at a time that is statistically rare for that specific user?
  context: This question focuses on user-level baselining to detect anomalous logins. Every user establishes a pattern of normal behavior (e.g., typical office hours, usual country/network). A login from a never-before-seen country or ASN, or at a time far outside their normal window (e.g., 3 AM), is a strong statistical indicator of a compromised account. This is the principle behind "impossible travel" and other user and entity behavior analytics (UEBA) detections.
  answer_sources:
  - Zeek conn.log
  - Windows Event ID 4624
  - Authentication servers (e.g., Active Directory)
  - VPN concentrators
  - Remote Desktop Gateways
  - Cloud IAM infrastructure
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FOR each new_login | COMPARE source_country, source_asn, login_time against user_historical_profile | ALERT WHERE country_is_new OR asn_is_new OR time_is_outside_95_percentile
- question: Does a user's login and subsequent API activity register as an outlier according to a machine learning model trained on that user's historical behavior?
  context: This question uses a more sophisticated, multi-featured approach to user-level anomaly detection. Instead of looking at single attributes in isolation, a model like a one-class SVM or Isolation Forest can consider a combination of features (time, location, ASN, etc.) simultaneously. This allows it to identify logins that are subtly anomalous across multiple dimensions, which might be missed by simpler statistical checks, providing a more robust method for detecting account takeovers.
  answer_sources:
  - Zeek http.log
  - Windows Event ID 4624
  - Authentication servers (e.g., Active Directory)
  - VPN concentrators
  - Remote Desktop Gateways
  - Cloud IAM infrastructure
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM login_and_api_logs | CREATE feature_vector (time, geo, asn) for user | APPLY user-specific_outlier_model | ALERT WHERE event_is_outlier
- question: Is an internal host maintaining an abnormally long-duration or high-volume connection to a cloud service, potentially indicating large-scale data transfer?
  context: This question uses simple thresholds to find extreme outliers in connection behavior. While statistical methods are more nuanced, a hard rule can catch blatant abuse, such as a host transferring terabytes of data in a single, long-lived session. This is a common pattern for bulk data exfiltration or unauthorized data synchronization and can be detected by monitoring connection logs for sessions that exceed predefined thresholds for duration and volume.
  answer_sources:
  - Zeek conn.log
  - Data center network core
  - servers hosting sensitive data
  - cloud synchronization clients
  - developer workstations
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM conn_logs | SEARCH destination in cloud_ip_ranges | ALERT WHERE connection_duration > 24_hours AND total_bytes > 50_GB
- question: Is an internal host's outbound data volume to cloud services a significant outlier when compared to the behavior of its peer group (e.g., other developer workstations)?
  context: This question uses peer group analysis to identify anomalous hosts. A single host's traffic might not violate its own historical baseline if it's a new compromise, but its behavior will likely stand out when compared to similar machines. By grouping hosts by role (e.g., via a CMDB) and establishing a traffic baseline for each group, analysts can flag any host that significantly exceeds the normal traffic volume of its peers, indicating it may be performing an unusual or unauthorized function.
  answer_sources:
  - Zeek conn.log
  - Windows Event ID 4624
  - Data center network core
  - servers hosting sensitive data
  - cloud synchronization clients
  - developer workstations
  range: last 90 days
  queries:
  - technology: pseudocode
    query: DEFINE peer_groups | For each group, CALCULATE 95th_percentile_daily_outbound_bytes | For each host, ALERT WHERE host_daily_bytes > (peer_95th_percentile * 1.5)
- question: Has a machine learning clustering algorithm identified a host that has shifted its network behavior from a low-traffic group to a high-traffic group, or become an outlier to its established cluster?
  context: This question applies unsupervised machine learning to automatically discover behavioral peer groups without manual definition. A clustering algorithm can analyze various network features (data volume, connection count, protocols) to group hosts with similar profiles. This dynamic approach can detect when a host's behavior fundamentally changes (e.g., a compromised web server starts acting like a high-traffic data transfer node), causing it to shift clusters or become an outlier, which is a strong signal of a potential compromise.
  answer_sources:
  - Zeek conn.log
  - Zeek http.log
  - Data center network core
  - servers hosting sensitive data
  - cloud synchronization clients
  - developer workstations
  range: last 90 days
  queries:
  - technology: pseudocode
    query: FROM conn_logs | CREATE feature_profile_per_host | APPLY clustering_algorithm | MONITOR for hosts that change clusters or become outliers