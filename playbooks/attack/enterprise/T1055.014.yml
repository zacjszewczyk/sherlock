name: T1055.014: VDSO Hijacking
id: 5e9c1f8a-2b3d-4c6e-8a1b-9d0e1f2a3b4c
description: |
  This playbook helps investigate whether an adversary has used VDSO hijacking (T1055.014) to achieve privilege escalation or defense evasion. It focuses on identifying evidence such as the execution of known malicious tools by hash, suspicious sequences of system calls like ptrace and mmap, unusual process behaviors following a ptrace event (e.g., spawning shells, accessing sensitive files, or making network connections), and direct evidence of syscall redirection like instruction pointers pointing to user-space memory. The playbook also addresses defense evasion tactics, including the injection of malicious code into security tools, tampering with logging daemons, and disrupting log shipping, which are often correlated with ptrace events targeting these critical processes.
type: technique
related:
  - TA0004: Privilege Escalation
  - TA0005: Defense Evasion
contributors:
  - Zachary Szewczyk
  - Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Have any executed binaries matched the hash of known VDSO hijacking tools from threat intelligence feeds?
    context: |
      VDSO hijacking often involves the use of specific malicious tools or malware. Comparing the file hashes of all executed binaries against a curated list of known malicious hashes is a high-fidelity method for detecting the presence of these tools. A match is a strong indicator of a VDSO hijacking attempt.
    answer_sources:
      - auditd execve records
      - osquery process_file_events
      - EDR process creation logs
      - Critical Linux servers (e.g., web servers, database servers, authentication servers)
      - Linux developer workstations
      - Production container environments
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each process_execution_event
          LET file_hash = event.file_hash
          IF file_hash IN threat_intel_feed_of_vdso_hashes
            ALERT High("Known VDSO hijacking tool executed")
  - question: Are there any newly executed files with very low prevalence across the environment?
    context: |
      Adversary tools are often not widely distributed across an environment like legitimate software. By calculating the prevalence of each executed file hash, we can identify rare or unique binaries. Executables seen on a small percentage of hosts or for the first time recently are statistically more likely to be suspicious and warrant investigation for techniques like VDSO hijacking.
    answer_sources:
      - auditd execve records
      - osquery process_file_events
      - EDR process creation logs
      - Critical Linux servers (e.g., web servers, database servers, authentication servers)
      - Linux developer workstations
      - Production container environments
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each unique file_hash executed today
          LET host_count = COUNT(DISTINCT hosts where hash was seen)
          LET total_hosts = COUNT(ALL hosts)
          LET prevalence = host_count / total_hosts
          IF prevalence < 0.01 OR first_seen_time is within last 24 hours
            ALERT Medium("Low prevalence binary executed")
  - question: Do any newly executed files have metadata features consistent with malicious process injection tools?
    context: |
      Malicious executables often have distinct characteristics in their file metadata (e.g., high string entropy due to packing, unusual imported functions, small file size). By training a machine learning model on these features from known good and bad files, we can predict the likelihood that a new, unseen executable is malicious, providing a proactive way to detect potential VDSO hijacking tools.
    answer_sources:
      - auditd execve records
      - osquery process_file_events
      - EDR process creation logs
      - Critical Linux servers (e.g., web servers, database servers, authentication servers)
      - Linux developer workstations
      - Production container environments
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each new_process_execution
          LET file_features = EXTRACT_METADATA(process.file)
          LET malicious_probability = ML_MODEL.PREDICT(file_features)
          IF malicious_probability > 0.9
            ALERT Medium("Binary predicted as malicious injection tool")
  - question: Has a lower-privileged process attached to a higher-privileged process using ptrace, then manipulated its memory?
    context: |
      A classic process injection and hijacking pattern involves one process attaching to another with ptrace, then using memory-writing syscalls to inject code. This question specifically looks for the privilege escalation scenario where a process with a lower user ID (UID) targets a process with a higher-privilege UID, which is a key signature of VDSO hijacking for privilege escalation. The sequence of ptrace(PTRACE_ATTACH) followed by mmap or ptrace(PTRACE_POKEDATA) is highly indicative.
    answer_sources:
      - auditd SYSCALL records
      - eBPF trace data
      - Falco logs
      - Critical Linux servers
      - Privileged user accounts
      - Core system daemons (e.g., sshd, cron, systemd)
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          WATCH for ptrace(PTRACE_ATTACH) syscall
          IF source_process.uid < target_process.uid
            TRACK source_pid and target_pid
            IF within 60s, source_pid performs mmap OR ptrace(PTRACE_POKEDATA) on target_pid
              ALERT High("Privilege escalation via ptrace memory injection detected")
  - question: Are there any processes exhibiting abnormal syscall sequences involving ptrace?
    context: |
      Legitimate processes have predictable patterns of system call usage. By modeling these normal sequences (e.g., with a Markov chain), we can detect significant deviations. A process suddenly using ptrace in a way that is statistically improbable for its baseline behavior is a strong anomaly signal that could indicate a hijacking attempt.
    answer_sources:
      - auditd SYSCALL records
      - eBPF trace data
      - Falco logs
      - Critical Linux servers
      - Privileged user accounts
      - Core system daemons (e.g., sshd, cron, systemd)
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each process_name
            BUILD baseline of syscall transition probabilities
          FOR each live_syscall_sequence
            CALCULATE joint probability of sequence based on baseline
            IF probability < 1st_percentile AND sequence includes 'ptrace'
              ALERT Medium("Anomalous syscall sequence involving ptrace")
  - question: Has a machine learning model detected an anomalous sequence of syscalls indicative of a hijacking attempt?
    context: |
      Advanced threats may use novel syscall sequences not caught by simple probabilistic models. A Recurrent Neural Network (RNN) can learn the complex, long-term temporal dependencies in a process's normal syscall activity. A sudden spike in the model's error when trying to predict the next syscall suggests the process has deviated from its learned behavior, a powerful indicator of potential compromise or hijacking.
    answer_sources:
      - auditd SYSCALL records
      - eBPF trace data
      - Falco logs
      - Critical Linux servers
      - Privileged user accounts
      - Core system daemons (e.g., sshd, cron, systemd)
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each critical_process
            FEED live_syscall_sequence to pre-trained RNN model
            LET prediction_error = MODEL.GET_ERROR()
            IF prediction_error spikes significantly
              ALERT Medium("RNN model detected anomalous syscall sequence")
  - question: Has a process, shortly after being targeted by ptrace, spawned a shell or modified a sensitive system file?
    context: |
      A common goal of process hijacking is to gain privileged execution. A strong indicator of success is when the compromised process, immediately after being attached to with ptrace, is used to spawn a shell (like /bin/bash) or write to critical configuration files like /etc/shadow or /etc/sudoers. This correlation directly links the ptrace event to a malicious outcome.
    answer_sources:
      - auditd SYSCALL records
      - auditd EXECVE records
      - osquery process_events
      - System configuration directories (e.g., /etc/, /root/)
      - Authentication-related files (e.g., /etc/shadow, /etc/sudoers)
      - Privileged processes on critical servers
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          ON ptrace_event(target_pid)
          MONITOR target_pid for 5 minutes
          IF target_pid spawns_shell() OR target_pid writes_to('/etc/shadow', '/etc/sudoers')
            ALERT High("Hijacked process spawned shell or modified sensitive file")
  - question: Following a ptrace event, did the targeted process exhibit statistically rare behavior, such as spawning an unusual child process or accessing an uncommon file?
    context: |
      Every process has a typical behavioral profile. High-privilege daemons, for example, rarely spawn interactive shells. By baselining the normal child processes and file accesses for each critical process, we can detect post-ptrace activity that is statistically rare (e.g., in the 99.9th percentile of rarity). This provides a data-driven way to spot abuse of a hijacked process.
    answer_sources:
      - auditd SYSCALL records
      - auditd EXECVE records
      - osquery process_events
      - System configuration directories (e.g., /etc/, /root/)
      - Authentication-related files (e.g., /etc/shadow, /etc/sudoers)
      - Privileged processes on critical servers
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          ON ptrace_event(target_pid, target_process_name)
          MONITOR subsequent activity from target_pid
          LET child_process = activity.child_process
          LET file_access = activity.file_access
          IF rarity_score(child_process FOR target_process_name) > 99.9 OR rarity_score(file_access FOR target_process_name) > 99.9
            ALERT Medium("Hijacked process exhibited rare post-ptrace behavior")
  - question: Did a behavioral modeling system (like One-Class SVM) flag a process's activity as an outlier immediately after it was targeted by ptrace?
    context: |
      Machine learning models like One-Class SVM or Isolation Forests can create a comprehensive "normal" profile for a process based on many features (child processes, files accessed, user context, etc.). Any activity that the model flags as a significant outlier, especially when temporally correlated with a ptrace event, is a strong signal that the process's behavior has been maliciously altered.
    answer_sources:
      - auditd SYSCALL records
      - auditd EXECVE records
      - osquery process_events
      - System configuration directories (e.g., /etc/, /root/)
      - Authentication-related files (e.g., /etc/shadow, /etc/sudoers)
      - Privileged processes on critical servers
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each critical_process_activity
            LET is_outlier = BEHAVIORAL_MODEL.PREDICT(activity_features)
            IF is_outlier AND process was recently targeted by ptrace
              ALERT Medium("Behavioral model flagged outlier activity post-ptrace")
  - question: Have any syscalls been executed from a user-space memory address instead of the kernel or vDSO?
    context: |
      This is a direct and high-fidelity indicator of VDSO hijacking. Normally, the instruction pointer for a syscall will point to a memory address within the kernel or the process's mapped virtual dynamic shared object (vDSO). If the pointer falls outside this range and into user-space memory, it means the syscall table or function has been hooked and redirected, which is the core mechanism of this technique.
    answer_sources:
      - eBPF trace data
      - Custom Kernel module logging
      - Kernel memory space on critical Linux hosts
      - vDSO memory region of running processes
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          ATTACH eBPF probe to sys_enter tracepoint
          FOR each syscall_event
            LET instruction_pointer = event.instruction_pointer
            LET process_memory_maps = GET_PROCESS_MAPS(event.pid)
            IF instruction_pointer NOT IN (kernel_range OR vdso_range from process_memory_maps)
              ALERT Critical("Syscall executed from user-space memory address")
  - question: Has the entropy of syscall handler instruction pointer addresses for a critical process suddenly increased?
    context: |
      Under normal operation, a process's syscalls are handled by a very small, stable set of addresses in the kernel and vDSO. The entropy of these addresses should be near zero. If an adversary hijacks the vDSO, they may redirect different syscalls to various locations in their injected code, causing a sudden and significant spike in the entropy of handler addresses. This change is a strong statistical indicator of hooking.
    answer_sources:
      - eBPF trace data
      - Custom Kernel module logging
      - Kernel memory space on critical Linux hosts
      - vDSO memory region of running processes
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each critical_process
            AGGREGATE syscall handler addresses over 1-minute windows
            CALCULATE entropy of address set
            IF current_entropy > (moving_avg_entropy + 3 * std_dev_entropy)
              ALERT High("Sudden increase in syscall handler address entropy")
  - question: Has a clustering algorithm identified any syscall handler addresses as anomalous noise points?
    context: |
      When viewed across an enterprise, the addresses of legitimate syscall handlers will form dense clusters corresponding to specific kernel and vDSO versions. Malicious, user-space hooks will be unique to a compromised machine and will not fall into these clusters. A density-based clustering algorithm like DBSCAN can automatically identify these outlier addresses as "noise," providing an effective way to hunt for hijacked processes.
    answer_sources:
      - eBPF trace data
      - Custom Kernel module logging
      - Kernel memory space on critical Linux hosts
      - vDSO memory region of running processes
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          GATHER all syscall handler addresses for process 'X' across all hosts
          RUN DBSCAN clustering on the set of addresses
          FOR each address classified as 'noise'
            ALERT High("Anomalous syscall handler address detected by clustering")
  - question: Have memory scans of security agent processes detected YARA signature matches for vDSO hooks or shellcode?
    context: |
      Adversaries may target security tools (like EDR or auditd) to evade detection. Periodically scanning the memory of these critical processes with YARA rules designed to find known vDSO hijacking patterns, generic shellcode, or other indicators of code injection is a direct way to uncover this defense evasion tactic. A match is a critical finding.
    answer_sources:
      - Live memory dumps via osquery
      - YARA scan results
      - osquery memory_map
      - Memory space of security tools (EDR, auditd, AV) on critical Linux hosts and developer workstations
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          SCHEDULE periodic job:
            FOR each security_process
              DUMP process memory
              SCAN memory with vDSO_hook_yara_rules
              IF yara_match
                ALERT Critical("VDSO hook signature found in security agent memory")
  - question: Is there an anomalous increase in executable memory segments that are not backed by a file on disk within security processes?
    context: |
      When code is injected into a process, it often resides in a private memory region that is marked as executable but does not correspond to any file on the filesystem. While some legitimate processes use this, security agents typically have a stable and predictable memory map. A sudden increase in the number of these "executable-unbacked" segments suggests that malicious code has been injected.
    answer_sources:
      - Live memory dumps via osquery
      - YARA scan results
      - osquery memory_map
      - Memory space of security tools (EDR, auditd, AV) on critical Linux hosts and developer workstations
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each security_process
            BASELINE count of executable-unbacked memory segments
            MONITOR for changes
            IF current_count > (baseline_avg + 2 * baseline_std_dev)
              ALERT High("Anomalous increase in unbacked executable memory in security agent")
  - question: Does a machine learning model classify any memory segments within security tools as malicious?
    context: |
      Beyond simple counts, machine learning can be used to analyze the features of each memory segment (entropy, size, permissions) to distinguish benign segments from maliciously injected code. Applying a trained classifier to the memory segments of security tools in real-time can detect sophisticated injection techniques that might otherwise be missed.
    answer_sources:
      - Live memory dumps via osquery
      - YARA scan results
      - osquery memory_map
      - Memory space of security tools (EDR, auditd, AV) on critical Linux hosts and developer workstations
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each memory_segment in security_process
            EXTRACT features (entropy, size, permissions)
            LET is_malicious = ML_MODEL.PREDICT(features)
            IF is_malicious
              ALERT High("ML model classified security agent memory segment as malicious")
  - question: Has a ptrace call targeting a security process been followed by attempts to modify or delete that tool's configuration or log files?
    context: |
      This is a highly specific and malicious pattern. An adversary first hijacks a security process (e.g., `auditd`) using `ptrace` and then uses that access or another process to tamper with its configuration or logs to cover their tracks or disable the tool. Correlating the `ptrace` event with subsequent file modifications in the tool's directories provides strong evidence of defense evasion.
    answer_sources:
      - auditd SYSCALL records
      - eBPF trace data
      - File system paths for security tool configurations and logs (e.g., /etc/audit/, /var/log/audit/, /opt/edr/)
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          ON ptrace_event(target_process) where target_process is a security_agent
          MONITOR for 60 seconds for file system events
          IF openat() or unlinkat() targets security_agent.config_dir or security_agent.log_dir
            ALERT Critical("Security agent targeted by ptrace, followed by file tampering")
  - question: Has a ptrace call targeting a security process been initiated by a statistically rare source process?
    context: |
      While debuggers like `gdb` might legitimately `ptrace` a process, it is extremely rare for a web server or other application to do so, especially against a security tool. By profiling which processes normally initiate `ptrace` calls, we can identify anomalous actors. A `ptrace` originating from a process that has never or rarely done so before is highly suspicious.
    answer_sources:
      - auditd SYSCALL records
      - eBPF trace data
      - File system paths for security tool configurations and logs (e.g., /etc/audit/, /var/log/audit/, /opt/edr/)
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          ON ptrace_event(source_process, target_process) where target_process is a security_agent
          CALCULATE historical frequency of source_process initiating ptrace
          IF frequency is in bottom 1st percentile
            ALERT High("Rare process initiated ptrace against security agent")
  - question: Has a graph-based anomaly detection model identified an unusual interaction, such as an unexpected process ptracing a security agent?
    context: |
      Visualizing system activity as a graph of interacting processes and files can reveal anomalous connections. In a normal graph, there would be no "edge" representing a `ptrace` call from, for example, a web application to the `auditd` process. A graph anomaly detection algorithm can automatically flag the creation of such an unusual edge as a structural anomaly, indicating a likely attack.
    answer_sources:
      - auditd SYSCALL records
      - eBPF trace data
      - File system paths for security tool configurations and logs (e.g., /etc/audit/, /var/log/audit/, /opt/edr/)
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          MODEL system activity as a graph (nodes=processes/files, edges=interactions)
          APPLY graph anomaly detection algorithm
          IF new edge `(process_A)-[ptrace]->(security_agent_B)` is flagged as structural anomaly
            ALERT High("Graph anomaly detected: unexpected ptrace of security agent")
  - question: After a process was targeted by ptrace, did it initiate a network connection to a known malicious C2 server?
    context: |
      A common post-compromise action is to establish a command and control (C2) channel. By correlating `ptrace` events with subsequent network connections from the host, we can look for high-fidelity indicators like communication with IP addresses on a threat intelligence feed. This directly links the hijacking event to malicious C2 activity.
    answer_sources:
      - Zeek conn.log
      - Zeek dns.log
      - auditd SYSCALL records
      - Network egress points (firewalls, proxies)
      - DNS servers
      - Critical Linux servers
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          ON ptrace_event(host_ip)
          MONITOR Zeek conn.log for outbound connections from host_ip
          IF connection.destination_ip IN c2_threat_intel_feed
            ALERT Critical("Post-ptrace C2 connection to known malicious IP")
  - question: Following a ptrace event, did the host exhibit periodic network beaconing or connect to a rare destination IP?
    context: |
      C2 channels often exhibit regular, periodic "beaconing" behavior. Analyzing the time intervals between connections to the same destination can reveal this pattern (low standard deviation). Additionally, connections to destinations that are rare or unique across the enterprise are suspicious. Finding either of these behaviors after a `ptrace` event suggests a C2 channel has been established.
    answer_sources:
      - Zeek conn.log
      - Zeek dns.log
      - auditd SYSCALL records
      - Network egress points (firewalls, proxies)
      - DNS servers
      - Critical Linux servers
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          ON ptrace_event(host_ip)
          ANALYZE subsequent connections from host_ip
          IF connections show periodic beaconing (low time_delta std dev) OR destination_ip is rare (<1% prevalence)
            ALERT High("Post-ptrace network beaconing or rare destination detected")
  - question: After a ptrace event, did a critical process's outbound data volume significantly exceed its forecasted baseline?
    context: |
      Time series forecasting can predict the normal outbound network traffic volume for a given process. If a process is hijacked and used for data exfiltration or heavy C2 communication, its actual data volume will significantly deviate from the predicted normal range. Correlating this anomaly with a preceding `ptrace` event provides strong evidence of compromise.
    answer_sources:
      - Zeek conn.log
      - Zeek dns.log
      - auditd SYSCALL records
      - Network egress points (firewalls, proxies)
      - DNS servers
      - Critical Linux servers
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          ON ptrace_event(target_process)
          LET forecast = ARIMA_MODEL.FORECAST(target_process.outbound_bytes)
          LET actual = GET_ACTUAL_BYTES(target_process)
          IF actual > forecast.upper_confidence_bound
            ALERT High("Anomalous outbound data volume from process post-ptrace")
  - question: Has a ptrace syscall ever been observed targeting a known logging daemon process?
    context: |
      There is virtually no legitimate reason to attach a debugger or use ptrace on a core logging daemon like `auditd`, `rsyslogd`, or `journald`. This action is almost certainly an attempt to disable or manipulate logging to evade detection. Any observation of this should be treated as a critical, unequivocal sign of tampering.
    answer_sources:
      - SIEM health monitoring logs
      - auditd SYSCALL records
      - Log forwarder agent heartbeats
      - Log aggregation platform (SIEM)
      - Logging daemons (auditd, rsyslogd, journald) on all Linux hosts
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          CREATE alert:
          ON ptrace_event(target_process)
          IF target_process.name IN ('auditd', 'rsyslogd', 'journald')
            ALERT Critical("Logging daemon targeted by ptrace")
  - question: Did a host's log shipping rate drop significantly below its established baseline?
    context: |
      If an adversary successfully disables a logging agent, the flow of events from that host to the central SIEM will stop or decrease dramatically. By monitoring the events-per-second (EPS) rate for each host and establishing a dynamic baseline, we can automatically detect a significant drop (e.g., more than 3 standard deviations) that indicates a sensor is offline or has been tampered with.
    answer_sources:
      - SIEM health monitoring logs
      - auditd SYSCALL records
      - Log forwarder agent heartbeats
      - Log aggregation platform (SIEM)
      - Logging daemons (auditd, rsyslogd, journald) on all Linux hosts
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each reporting_host
            MONITOR events_per_second (EPS)
            CALCULATE moving average and standard deviation of EPS
            IF current_EPS < (moving_avg - 3 * std_dev) for > 5 minutes
              ALERT High("Host log shipping rate has dropped significantly")
  - question: Has a time series anomaly detection model flagged an abnormal drop in a host's log volume?
    context: |
      Simple baselines may not account for normal daily or weekly fluctuations in log volume. A more advanced time series model (like an autoencoder) can learn a host's complex logging "rhythm." When the model flags a drop in volume as anomalous because it doesn't fit the learned pattern, it provides a higher-fidelity signal of potential tampering, especially when correlated with other suspicious activity on the host.
    answer_sources:
      - SIEM health monitoring logs
      - auditd SYSCALL records
      - Log forwarder agent heartbeats
      - Log aggregation platform (SIEM)
      - Logging daemons (auditd, rsyslogd, journald) on all Linux hosts
    range: last 90 days
    queries:
      - search_technology: pseudocode
        query: |
          FOR each host
            FEED log_volume_timeseries to autoencoder model
            LET reconstruction_error = MODEL.GET_ERROR()
            IF reconstruction_error is anomalously high (indicating a drop)
              ALERT Medium("Time series model detected anomalous drop in log volume")