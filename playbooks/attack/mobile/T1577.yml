name: T1577: Compromise Application Executable
id: d3a9b1d0-5e6f-4c3a-9e8d-7f6a5c4b3a2b
description: |
  This playbook helps determine if an adversary has established persistence by modifying a legitimate application executable on a mobile device. This can be detected by identifying discrepancies between an installed application's cryptographic hash and its known-good value from an official manifest, indicating unauthorized tampering [2]. It also addresses static analysis of Android Application Packages (APKs) to find artifacts of the Janus vulnerability (CVE-2017-13156), where data is appended between the ZIP central directory and the DEX file [1]. Furthermore, it covers the detection of anomalous network traffic from trusted applications, such as communication with malicious domains, use of high-entropy DNS queries characteristic of Domain Generation Algorithms (DGA), or unusual data transfer volumes, all of which suggest the application's behavior has been altered for malicious purposes.
type: technique
related:
  - TA0028: Persistence
contributors:
  - Zachary Szewczyk
  - Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Are there any installed applications on managed mobile devices whose file hash does not match the known-good hash listed in the organizational application manifest?
    context: |
      This check is crucial for detecting unauthorized modifications or tampering with legitimate applications. A mismatch indicates that the application binary on the device is different from the officially sanctioned version, which could be the result of an adversary injecting malicious code to achieve persistence. Detecting such a discrepancy is a strong indicator of compromise [2].
    answer_sources:
      - MDM application inventory report
      - Mobile EDR agent logs
      - Organizational Application Manifest
      - Managed mobile device fleet (iOS, Android)
      - Mobile Device Management (MDM) or Unified Endpoint Management (UEM) server
      - Organizational application manifest repository
    range: last 90 days
    queries:
      - pseudocode: |
          // For each device in MDM inventory
          FOREACH app IN device.installed_apps:
            // Find corresponding app in official manifest
            manifest_app = manifest.find(id: app.id, version: app.version)
            // Compare hashes
            IF manifest_app AND app.hash != manifest_app.hash:
              ALERT(
                device: device.id,
                app: app.id,
                details: "Application hash mismatch detected."
              )

  - question: Are there any devices running rare or non-standard versions of applications that are uncommon across the entire fleet?
    context: |
      Adversaries might patch or modify an application, resulting in a unique version number or build that differs from standard, widespread deployments. By calculating the prevalence of each application version across the fleet, this question helps surface these statistical outliers. A version installed on a very small percentage of devices could represent a targeted compromise or a non-standard build that warrants investigation.
    answer_sources:
      - MDM application inventory report
      - Mobile EDR agent logs
      - Organizational Application Manifest
      - Managed mobile device fleet (iOS, Android)
      - Mobile Device Management (MDM) or Unified Endpoint Management (UEM) server
      - Organizational application manifest repository
    range: last 90 days
    queries:
      - pseudocode: |
          // Aggregate counts of all app versions across the fleet
          app_version_counts = aggregate_counts(all_devices.installed_apps)
          total_devices = count(all_devices)
          
          // Calculate prevalence and identify rare versions
          FOREACH version, count IN app_version_counts:
            prevalence = count / total_devices
            IF prevalence < 0.005: // Rarity threshold (e.g., 0.5%)
              ALERT(
                app_version: version,
                prevalence: prevalence,
                details: "Statistically rare application version detected."
              )

  - question: Do any devices exhibit an unusual combination of installed applications when compared to the baseline profile of the entire fleet?
    context: |
      While individual applications may be legitimate, a specific combination of apps on a single device could be anomalous and indicative of a compromised state or preparation for an attack. This question aims to use unsupervised anomaly detection models (like an Isolation Forest) to learn the normal patterns of application installations across the organization and flag devices that deviate significantly from this baseline.
    answer_sources:
      - MDM application inventory report
      - Mobile EDR agent logs
      - Organizational Application Manifest
      - Managed mobile device fleet (iOS, Android)
      - Mobile Device Management (MDM) or Unified Endpoint Management (UEM) server
      - Organizational application manifest repository
    range: last 90 days
    queries:
      - pseudocode: |
          // Generate feature vectors for each device's app profile
          device_vectors = create_feature_vectors(all_devices.installed_apps)
          
          // Train an anomaly detection model
          model = IsolationForest.train(device_vectors)
          
          // Score each device
          FOREACH device, vector IN device_vectors:
            anomaly_score = model.predict(vector)
            IF anomaly_score > threshold:
              ALERT(
                device: device.id,
                score: anomaly_score,
                details: "Anomalous combination of installed applications detected."
              )

  - question: Have any scanned Android Application Packages (APKs) shown evidence of the Janus vulnerability (CVE-2017-13156) by having data injected between the ZIP central directory and the DEX file?
    context: |
      This question directly targets a known exploitation technique. The Janus vulnerability allows an attacker to add malicious code to a legitimate Android application without breaking its cryptographic signature [1]. A static analysis rule that parses the APK file structure and finds data in this specific, unexpected location is a high-fidelity indicator that an application has been tampered with using this method.
    answer_sources:
      - Raw APK files from endpoints
      - Mobile App Vetting (MAV) static analysis reports
      - Digital forensic image of device storage
      - Managed Android device fleet
      - Application sandbox environment
      - Mobile security analysis platforms
    range: last 90 days
    queries:
      - pseudocode: |
          // For each APK submitted for analysis
          FOREACH apk IN new_apks:
            // Parse APK as a ZIP file
            zip_structure = parse_zip(apk)
            dex_offset = find_dex_offset(apk)
            
            // Check for data between central directory and DEX file
            end_of_central_dir = zip_structure.central_dir_offset + zip_structure.central_dir_size
            IF dex_offset > end_of_central_dir:
              ALERT(
                apk: apk.name,
                details: "Janus vulnerability (CVE-2017-13156) artifact detected."
              )

  - question: Are there any APKs with an anomalously large amount of data appended after the ZIP central directory, suggesting file tampering?
    context: |
      This question provides a broader, statistical approach to detecting file modification beyond just the Janus vulnerability. By calculating the size difference ($$ \Delta $$) between the actual file size and the expected size based on its ZIP structure, we can identify outliers. A significantly large $$ \Delta $$ value, where $$ \Delta = FileSize_{OnDisk} - (Offset_{CentralDirectory} + Size_{CentralDirectory}) $$, indicates that unexpected data has been appended to the file, which is a common sign of repacking or other forms of tampering.
    answer_sources:
      - Raw APK files from endpoints
      - Mobile App Vetting (MAV) static analysis reports
      - Digital forensic image of device storage
      - Managed Android device fleet
      - Application sandbox environment
      - Mobile security analysis platforms
    range: last 90 days
    queries:
      - pseudocode: |
          // Establish historical distribution of Delta values
          historical_deltas = get_historical_deltas()
          threshold = percentile(historical_deltas, 99.9)
          
          // Analyze each new APK
          FOREACH apk IN new_apks:
            zip_structure = parse_zip(apk)
            delta = apk.file_size - (zip_structure.central_dir_offset + zip_structure.central_dir_size)
            
            IF delta > threshold:
              ALERT(
                apk: apk.name,
                delta: delta,
                details: "Anomalous data size appended to APK."
              )

  - question: Can a machine learning model, trained on APK structural features, classify any new or updated applications as high-risk or potentially malicious?
    context: |
      This proactive approach uses a supervised machine learning model to generalize beyond specific, known indicators of compromise. By training a model on features like header flags, section entropy, and file size discrepancies from a labeled dataset of benign and malicious APKs, the system can automatically score and classify new applications. This enables the detection of novel or unknown variants of compromised executables that might not match predefined rules.
    answer_sources:
      - Raw APK files from endpoints
      - Mobile App Vetting (MAV) static analysis reports
      - Digital forensic image of device storage
      - Managed Android device fleet
      - Application sandbox environment
      - Mobile security analysis platforms
    range: last 90 days
    queries:
      - pseudocode: |
          // Load pre-trained classification model
          model = load_model("apk_classifier.model")
          
          // Analyze each new APK
          FOREACH apk IN new_apks:
            // Extract features like entropy, section counts, size delta
            features = extract_features(apk)
            
            // Classify and get risk score
            risk_score = model.predict(features)
            IF risk_score > risk_threshold:
              ALERT(
                apk: apk.name,
                score: risk_score,
                details: "High-risk APK detected by ML classifier."
              )

  - question: Is any trusted, whitelisted mobile application communicating with known malicious domains or IP addresses?
    context: |
      This is a high-confidence indicator of compromise. A legitimate, trusted application should not be communicating with known command-and-control (C2) servers or other malicious infrastructure. By enriching network logs with application context and correlating destinations against a threat intelligence feed, we can detect if a whitelisted app has been compromised and is being used by an adversary.
    answer_sources:
      - Zeek conn.log
      - Zeek dns.log
      - CASB logs
      - Mobile EDR network logs
      - Threat Intelligence Feed
      - Corporate Wi-Fi network gateways
      - VPN egress points
      - DNS resolvers
      - Cloud Access Security Broker (CASB)
    range: last 90 days
    queries:
      - pseudocode: |
          // Join network logs with app context and threat intel
          FOREACH flow IN network_logs:
            app = get_app_from_flow(flow)
            is_malicious = threat_intel.check(flow.destination_ip)
            
            // Alert if a trusted app communicates with a malicious host
            IF app.is_trusted AND is_malicious:
              ALERT(
                device: flow.device_id,
                app: app.name,
                destination: flow.destination_ip,
                details: "Trusted application communicating with known C2."
              )

  - question: Has any application exhibited anomalous network behavior, such as transferring an unusually large amount of data or making high-entropy DNS queries indicative of DGA?
    context: |
      Adversaries often use compromised applications for data exfiltration or command-and-control, which can manifest as statistical anomalies in network traffic. This question aims to detect such activity by establishing a baseline of normal network behavior for each application. Alerting on deviations, such as data transfers exceeding the 95th percentile ($$ orig_bytes + resp_bytes $$) or DNS queries with entropy scores suggesting Domain Generation Algorithm (DGA) activity, can uncover this covert usage.
    answer_sources:
      - Zeek conn.log
      - Zeek dns.log
      - CASB logs
      - Mobile EDR network logs
      - Threat Intelligence Feed
      - Corporate Wi-Fi network gateways
      - VPN egress points
      - DNS resolvers
      - Cloud Access Security Broker (CASB)
    range: last 90 days
    queries:
      - pseudocode: |
          // For each application, check against its established baseline
          FOREACH flow IN network_logs:
            app_baseline = get_baseline(flow.app_id)
            
            // Check for unusual data volume
            IF flow.total_bytes > app_baseline.bytes_95th_percentile:
              ALERT(app: flow.app_id, details: "Anomalous data transfer volume.")
              
            // Check for DGA-like DNS queries
            IF flow.is_dns_query AND entropy(flow.dns_query) > app_baseline.dns_entropy_avg + (3 * app_baseline.dns_entropy_stddev):
              ALERT(app: flow.app_id, details: "High entropy DNS query detected.")

  - question: Does the time-series pattern of an application's network activity deviate significantly from its own learned historical baseline, as identified by an LSTM autoencoder?
    context: |
      This advanced question uses a machine learning model (an LSTM Autoencoder) to learn the normal temporal patterns of an application's network behavior, such as bytes sent per minute or new connections over time. When the live network activity no longer matches the learned pattern, the model will have a high reconstruction error. This signals a significant behavioral anomaly that might be missed by simpler statistical methods, indicating a potential compromise.
    answer_sources:
      - Zeek conn.log
      - Zeek dns.log
      - CASB logs
      - Mobile EDR network logs
      - Threat Intelligence Feed
      - Corporate Wi-Fi network gateways
      - VPN egress points
      - DNS resolvers
      - Cloud Access Security Broker (CASB)
    range: last 90 days
    queries:
      - pseudocode: |
          // For each device-app pair, load its trained LSTM model
          FOREACH timeslice IN live_network_data:
            device_app_pair = get_device_app(timeslice)
            model = load_lstm_model(device_app_pair)
            
            // Get reconstruction error from the model
            reconstruction = model.predict(timeslice)
            error = calculate_reconstruction_error(timeslice, reconstruction)
            
            // Alert if error exceeds dynamic threshold
            IF error > get_dynamic_threshold(device_app_pair):
              ALERT(
                pair: device_app_pair,
                error: error,
                details: "Anomalous network behavior pattern detected by LSTM."
              )