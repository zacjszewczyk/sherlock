name: T1575: Native API
id: b1a2c3d4-e5f6-4a7b-8c9d-0e1f2a3b4c5d
description: This playbook investigates the use of native APIs on mobile devices for defense evasion and execution. It aims to answer whether an adversary is using native code to obscure malicious activity or execute malicious commands. This is achieved by detecting packed or obfuscated native libraries using entropy analysis and JNI export patterns; identifying dynamic loading of libraries from non-standard, world-writable directories; uncovering the use of Java Reflection to execute hidden code from native libraries; performing static analysis to find command execution functions (e.g., 'system', 'popen') or embedded shell command strings; analyzing network traffic for C2-like beaconing from applications with native code; and monitoring for anomalous process creation (e.g., '/system/bin/sh', 'su') by these applications.
type: technique
related:
  - TA0030: Defense Evasion
  - TA0041: Execution
contributors:
  - Zachary Szewczyk
  - Ask Sage
created: 2025-10-01
modified: 2025-10-01
version: 1.0
tags: none
questions:
  - question: Are any applications in our MDM inventory using native libraries (.so files) with hashes that match known malicious or packed libraries from threat intelligence feeds?
    context: This question aims to quickly identify known threats by leveraging threat intelligence. Adversaries often reuse malicious or packed code. Matching the hashes of native libraries found in our applications against a database of known bad hashes is a highly efficient way to detect and alert on potentially compromised applications on managed devices. This is a primary step in identifying obfuscated or malicious native code.
    answer_sources:
      - APK static analysis reports (JSON/XML)
      - MDM application inventory logs
      - Static analysis tool raw output
      - Corporate application vetting system (static analysis sandbox)
      - MDM server application inventory database
      - File systems of enrolled mobile devices
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR app IN mdm_inventory:
            hashes = get_native_library_hashes(app.static_analysis_report)
            FOR hash IN hashes:
              IF is_known_malicious(hash, threat_intel_feed):
                ALERT(app, device, user)
  - question: Do any native libraries in our environment exhibit signs of packing or obfuscation, such as unusually high entropy or a suspicious JNI export pattern?
    context: This question helps detect unknown or zero-day threats that use common obfuscation techniques. High Shannon entropy often indicates packed or encrypted code, a hallmark of malware trying to evade static analysis. Similarly, exporting only a few JNI functions, especially 'JNI_OnLoad', is a technique used to hide the true functionality by registering native methods dynamically at runtime. Flagging libraries with these characteristics, especially in combination, helps uncover sophisticated evasion tactics.
    answer_sources:
      - APK static analysis reports (JSON/XML)
      - MDM application inventory logs
      - Static analysis tool raw output
      - Corporate application vetting system (static analysis sandbox)
      - MDM server application inventory database
      - File systems of enrolled mobile devices
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          entropy_threshold = 99th_percentile_entropy()
          FOR lib IN all_native_libraries:
            IF lib.entropy > entropy_threshold OR (lib.export_count <= 3 AND 'JNI_OnLoad' IN lib.exports):
              ALERT(lib, app)
  - question: Can we use a machine learning model to predict which new or updated native libraries are likely malicious based on their static features?
    context: This question leverages machine learning to automate the detection of suspicious native libraries at scale. By training a model on features associated with maliciousness (e.g., high entropy, dynamic symbol resolution, specific JNI function usage), we can score and prioritize libraries for deeper investigation. This approach is more robust than single-indicator checks and can identify novel threats that share characteristics with known malware. A high probability score serves as a strong signal for escalation to a reverse engineering team.
    answer_sources:
      - APK static analysis reports (JSON/XML)
      - MDM application inventory logs
      - Static analysis tool raw output
      - Corporate application vetting system (static analysis sandbox)
      - MDM server application inventory database
      - File systems of enrolled mobile devices
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR lib IN new_or_updated_libraries:
            features = extract_features(lib)
            score = ml_model.predict_proba(features)
            IF score > 0.85:
              ESCALATE(lib, app) for manual analysis
  - question: Are any mobile devices downloading executable files (.so, .dex, .jar) from known malicious domains and then loading them from non-standard directories?
    context: This question seeks to identify the full chain of a dynamic code loading attack. Adversaries often use a dropper application that downloads a malicious payload from a C2 server and then loads it into memory. By correlating network activity (DNS queries, file downloads) with on-device actions (library loading from unusual paths), we can detect this behavior with high confidence. This sequence of events is a strong indicator of compromise.
    answer_sources:
      - Android Logcat streams from MDM
      - Zeek conn.log
      - Zeek files.log
      - Zeek dns.log
      - Mobile EDR file modification events
      - Enterprise wireless and VPN network traffic inspection points
      - DNS resolvers
      - Real-time log streams from enrolled mobile endpoints
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          JOIN dns_logs, file_logs, android_logs ON device_ip within 120s
          IF dns_log.domain IN blocklist AND file_log.extension IN ['.so', '.dex', '.jar'] AND android_log.event == 'System.load' AND android_log.path NOT LIKE '/data/app/%':
            ALERT(device, app, domain)
  - question: Is any application loading native libraries from non-standard, world-writable directories at a rate that is anomalous compared to its historical behavior?
    context: This question uses behavioral analytics to detect deviations from normal application activity. While some legitimate applications might load libraries from odd locations, a sudden increase in this behavior or a 'first-of-its-kind' event for a specific app is highly suspicious. This anomaly detection approach can uncover when a benign application has been compromised or has updated with malicious functionality, even if the library itself is not yet known to be malicious.
    answer_sources:
      - Android Logcat streams from MDM
      - Zeek conn.log
      - Zeek files.log
      - Zeek dns.log
      - Mobile EDR file modification events
      - Enterprise wireless and VPN network traffic inspection points
      - DNS resolvers
      - Real-time log streams from enrolled mobile endpoints
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR each app:
            baseline = build_baseline(app.library_load_paths, 30_days)
            current_rate = calculate_rate_of_nonstandard_loads(app)
            IF current_rate > (baseline.mean + 3*baseline.std_dev) OR is_first_time_event(app):
              ALERT(app, device)
  - question: Can we use a sequence analysis model to detect chains of events on mobile devices that match known malicious attack patterns?
    context: This question applies advanced machine learning to recognize complex attack sequences that simple correlation rules might miss. Malicious activity is often a series of steps (e.g., connect to suspicious domain, download payload, execute payload). By training a model like an HMM or RNN on labeled sequences, we can identify and flag new event chains that are statistically similar to known attack patterns, allowing for the detection of sophisticated, multi-stage threats.
    answer_sources:
      - Android Logcat streams from MDM
      - Zeek conn.log
      - Zeek files.log
      - Zeek dns.log
      - Mobile EDR file modification events
      - Enterprise wireless and VPN network traffic inspection points
      - DNS resolvers
      - Real-time log streams from enrolled mobile endpoints
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR each device:
            event_sequence = get_events(device)
            probability = sequence_model.predict(event_sequence)
            IF probability > threshold:
              ALERT(device, event_sequence)
  - question: Are any applications dynamically loading a native library and then immediately using Java Reflection to execute a method whose name is not found in the original application package?
    context: This question targets a specific and highly suspicious technique for hiding malicious code. An adversary loads a native library and then uses Java Reflection to call a function within it. If the name of the function being called was not present in the original code but was constructed or decrypted at runtime, it strongly implies an attempt to hide the malicious logic from static analysis tools. Correlating these events in a tight time window provides a high-confidence indicator of compromise.
    answer_sources:
      - Mobile EDR API monitoring logs
      - Android Logcat streams from MDM
      - Dynamic analysis sandbox logs (e.g., Frida traces)
      - Mobile EDR/MTP agent data feeds
      - Real-time log streams from enrolled mobile endpoints
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          JOIN edr_logs ON thread_id within 100ms
          IF event1 == 'System.loadLibrary' AND event2 == 'Method.invoke':
            method_name = event2.argument
            IF method_name NOT IN app.strings:
              ALERT(app, device)
  - question: Are any applications using Java Reflection with method or class names that appear to be obfuscated, based on high string entropy?
    context: This question provides another way to detect the use of reflection for malicious purposes. Instead of plain text names like "com.example.MyClass", malware may use encrypted or encoded strings that are deobfuscated just before the reflection call. These deobfuscated strings often have high entropy (appear random). By baselining normal reflection usage for an app and alerting on high-entropy outliers, we can detect attempts to hide the true targets of reflective calls.
    answer_sources:
      - Mobile EDR API monitoring logs
      - Android Logcat streams from MDM
      - Dynamic analysis sandbox logs (e.g., Frida traces)
      - Mobile EDR/MTP agent data feeds
      - Real-time log streams from enrolled mobile endpoints
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR each app:
            baseline_entropy = 98th_percentile_entropy(app.reflection_args)
            FOR each reflection_call IN app.logs:
              arg_entropy = calculate_entropy(call.argument)
              IF arg_entropy > baseline_entropy:
                ALERT(app, device, call)
  - question: Can we use a machine learning model on dynamic API call traces to classify application behavior as benign or suspicious, specifically looking for malicious use of reflection and native code?
    context: This question proposes using machine learning on dynamic analysis data to identify malicious behavior in action. Static analysis can be bypassed, but the actual sequence of API calls at runtime is harder to hide. By training a classifier on features from these runtime traces (e.g., API call sequences, argument entropy), we can build a powerful detection mechanism that identifies suspicious patterns involving reflection and native code, even if the specific implementation is novel.
    answer_sources:
      - Mobile EDR API monitoring logs
      - Android Logcat streams from MDM
      - Dynamic analysis sandbox logs (e.g., Frida traces)
      - Mobile EDR/MTP agent data feeds
      - Real-time log streams from enrolled mobile endpoints
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR each app_trace IN sandbox_logs:
            features = extract_features_from_trace(trace)
            classification = ml_model.predict(features)
            IF classification == 'suspicious':
              ALERT(app, trace)
  - question: Do any non-allowlisted applications contain native libraries that import command execution functions or contain shell-related strings?
    context: This question focuses on statically identifying applications with the potential to execute arbitrary commands. The presence of C functions like 'system' or strings like '/bin/sh' and 'su' in a native library is a strong indicator of this capability. By checking for these indicators and filtering out legitimate tools (e.g., terminal emulators) via an allowlist, we can efficiently find unauthorized applications that could be used to run malicious commands on a device.
    answer_sources:
      - APK static analysis reports (JSON/XML)
      - MDM application inventory logs
      - Corporate application vetting system (static analysis sandbox)
      - MDM application inventory database
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR app IN all_apps:
            IF app NOT IN allowlist:
              FOR lib IN app.native_libraries:
                IF lib.imports IN ['system', 'execve'] OR lib.strings IN ['/bin/sh', 'su']:
                  ALERT(app, device)
  - question: Can we create a risk score for native libraries based on the rarity of suspicious indicators they contain, to prioritize the riskiest applications for review?
    context: This question aims to move beyond simple blocklisting by using risk scoring to surface the most unusual and therefore most suspicious libraries. An indicator (like the import of 'system') that is rare across the entire fleet of applications is more likely to be malicious than one that is common. By assigning scores based on rarity and summing them, we can rank libraries by risk and focus analyst attention on those that exceed a high percentile, improving the efficiency of manual review.
    answer_sources:
      - APK static analysis reports (JSON/XML)
      - MDM application inventory logs
      - Corporate application vetting system (static analysis sandbox)
      - MDM application inventory database
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          indicator_prevalence = calculate_prevalence_of_all_indicators()
          FOR lib IN all_libraries:
            score = 0
            FOR indicator IN lib.indicators:
              score += 1 / indicator_prevalence[indicator]
            lib.risk_score = score
          IF lib.risk_score > 98th_percentile_score():
            FLAG_FOR_REVIEW(lib.app)
  - question: Can a machine learning model be trained to classify applications as 'potential native executors' based on a combination of static features?
    context: This question proposes a more holistic, machine-learning-based approach to static analysis. Instead of relying on one or two indicators, a model can learn the complex interplay between many features (suspicious imports, string counts, Android permissions, file structure) that characterize an application capable of malicious execution. This allows for more accurate classification and automated escalation of high-confidence candidates to a dynamic sandbox for behavioral confirmation.
    answer_sources:
      - APK static analysis reports (JSON/XML)
      - MDM application inventory logs
      - Corporate application vetting system (static analysis sandbox)
      - MDM application inventory database
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR app IN new_apps:
            features = extract_static_features(app)
            classification, confidence = ml_model.predict(features)
            IF classification == 'potential_executor' AND confidence > 0.90:
              ESCALATE_TO_SANDBOX(app)
  - question: Are any mobile devices communicating with known command and control (C2) infrastructure, and can we identify the responsible application?
    context: This question addresses the critical task of detecting active C2 communication using threat intelligence. By matching network connection logs (IPs, domains, TLS fingerprints) against known C2 indicators, we can identify compromised devices. Correlating this network alert with endpoint EDR data is crucial to pinpoint the specific malicious application or process responsible for the communication, enabling rapid response and remediation.
    answer_sources:
      - Zeek conn.log
      - Zeek ssl.log
      - Zeek dns.log
      - MDM application inventory logs
      - Mobile EDR network connection logs
      - Network egress points (Firewall/Proxy)
      - Enterprise DNS servers
      - VPN concentrators
      - Mobile endpoint network logs
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR conn in network_logs:
            IF conn.dest_ip OR conn.domain OR conn.ja3 IN c2_blocklist:
              app = correlate_with_edr(conn.src_ip, conn.timestamp)
              ALERT(device, app, conn.destination)
  - question: Are there any network connections from mobile devices that exhibit C2-like beaconing behavior, characterized by highly regular time intervals and consistent packet sizes?
    context: This question seeks to uncover unknown C2 channels by looking for their characteristic behavior rather than specific indicators. C2 beacons are often automated and thus exhibit very low variance in their timing ('jitter') and size. By analyzing network flows for this periodicity and consistency, and filtering out known good services, we can detect potential C2 activity even when the destination IP or domain is not yet on a threat intelligence list.
    answer_sources:
      - Zeek conn.log
      - Zeek ssl.log
      - Zeek dns.log
      - MDM application inventory logs
      - Mobile EDR network connection logs
      - Network egress points (Firewall/Proxy)
      - Enterprise DNS servers
      - VPN concentrators
      - Mobile endpoint network logs
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          GROUP conns by 4-tuple over 24h
          FOR each group:
            time_stddev = stddev(group.time_deltas)
            size_stddev = stddev(group.payload_sizes)
            IF time_stddev < 2s AND size_stddev < 100b AND group.dest NOT IN allowlist:
              ALERT(group.src_ip, group.dest)
  - question: Can we use unsupervised machine learning to cluster network traffic and identify small, anomalous groups of connections that may represent C2 channels?
    context: This question leverages unsupervised learning to find the 'needles in the haystack'. The vast majority of network traffic is benign and forms large, predictable clusters. Malicious C2 traffic, however, often forms its own small, distinct clusters based on its unique features (e.g., unusual port, periodic timing, random-looking domain). Using an algorithm like DBSCAN can automatically isolate these anomalous clusters for analyst investigation, providing a powerful method for discovering novel threats.
    answer_sources:
      - Zeek conn.log
      - Zeek ssl.log
      - Zeek dns.log
      - MDM application inventory logs
      - Mobile EDR network connection logs
      - Network egress points (Firewall/Proxy)
      - Enterprise DNS servers
      - VPN concentrators
      - Mobile endpoint network logs
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          features = extract_features_from_flows(network_logs)
          clusters = DBSCAN(features)
          FOR cluster in clusters:
            IF cluster.is_small_and_dense_outlier:
              INVESTIGATE(cluster.flows)
  - question: Are any non-allowlisted mobile applications spawning suspicious child processes like a shell ('sh'), superuser ('su'), or package manager ('pm')?
    context: This question targets a direct and unambiguous indicator of command execution. When a typical mobile application (e.g., a game, a productivity app) spawns a shell or a superuser process, it is almost always a sign of malicious activity, such as an attempt to gain root access, install other packages, or run arbitrary commands. By alerting on these specific process creation events and excluding known-good tools, we can detect active exploitation with high fidelity.
    answer_sources:
      - Mobile EDR process event logs
      - Android SELinux audit logs
      - Android Logcat
      - Mobile EDR/MTP agent data feeds
      - Real-time log streams from enrolled mobile endpoints
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR event IN process_creation_logs:
            IF event.parent.type == 'mobile_app' AND event.parent.name NOT IN allowlist AND event.child.name IN ['sh', 'su', 'pm']:
              ALERT(event.parent.name, event.child.name)
  - question: Is any application executing commands or spawning child processes that are completely new and have never been seen for that application across our entire fleet?
    context: This question uses fleet-wide behavioral baselining to detect 'first of its kind' anomalies. An application might have a predictable set of child processes it runs. If it suddenly spawns a new process or runs a command that has never been observed for that application on any device, it is a powerful signal of a potential compromise or a malicious update. This 'first seen in fleet' logic is highly effective at catching emerging threats.
    answer_sources:
      - Mobile EDR process event logs
      - Android SELinux audit logs
      - Android Logcat
      - Mobile EDR/MTP agent data feeds
      - Real-time log streams from enrolled mobile endpoints
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR event IN process_creation_logs:
            baseline = get_fleet_baseline(event.parent_app)
            IF event.child_process NOT IN baseline.known_children OR event.command_line NOT IN baseline.known_commands:
              ALERT(event, 'First seen in fleet')
  - question: Can an anomaly detection model identify suspicious process creation events based on features like parent/child names and command-line arguments?
    context: This question proposes using an unsupervised anomaly detection model, like Isolation Forest, to find unusual process events without pre-existing labels. The model learns what 'normal' process creation looks like across the fleet based on features like the parent-child relationship and command-line characteristics. It can then flag events that deviate significantly from this norm, which might represent malicious activity that doesn't trigger specific rules but is nonetheless abnormal.
    answer_sources:
      - Mobile EDR process event logs
      - Android SELinux audit logs
      - Android Logcat
      - Mobile EDR/MTP agent data feeds
      - Real-time log streams from enrolled mobile endpoints
    range: last 90 days
    queries:
      - technology: Pseudocode
        query: |
          FOR event IN process_creation_logs:
            features = extract_features(event)
            anomaly_score = isolation_forest_model.predict(features)
            IF anomaly_score is abnormal:
              FLAG_FOR_INVESTIGATION(event)